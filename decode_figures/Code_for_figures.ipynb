{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  The code in this script can be used to replicate the publication figures from the decode pipeline output files (provided in https://drive.google.com/open?id=15YoTBTZh4MdtAqHbibkYieEqyLyFi5hb&usp=drive_fs)  and the Supplemental Data Files.\n",
    "\n",
    "Most analysis required for replicating the figures is computed here. Data compiled elsewhere (e.g. abundances of tRNA ligases) and required for plots, is provided as a table in the google drive folder 2024_Tsour/pipeline_output/analysis_dependencies/.\n",
    "\n",
    "A subset of analyses and figures that are not present here were generated in an independent script and can be accessed with other scripts in the repository, found in decode_analysis. These include Figure 2j; Figure 3b,c,e; Figure 4c,d,e; Figure 5a,b,c,d; Extndede Data Figure 3k; Extended Data Figure 4; Extended Data Figure 5a,c,f; Extended Data Figure 7; Extended Data Figure 8; Extended Data Figure 9b,c,d; Extended Data Figure 10a,b,c.\n",
    "\n",
    "There is a lot of code in this script. It is organized and labeled by references to figures in the manuscript. It is recommended to find and run the analyses of interest, rather than running the entire script at once. E.g. search page for \"Figure 3a\" to find code to replicate that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in packages needed\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "import scipy as sp\n",
    "from copy import deepcopy\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from adjustText import adjust_text\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import os\n",
    "import ast\n",
    "from scipy.odr import Model, RealData, ODR\n",
    "from scipy.stats import gaussian_kde\n",
    "from matplotlib import gridspec\n",
    "import milkviz as mv\n",
    "from matplotlib_venn import venn3\n",
    "import zipfile\n",
    "from glob import glob\n",
    "import gzip\n",
    "import tarfile\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.ticker import AutoMinorLocator, FixedLocator\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting directories and reading in data.\n",
    "\n",
    "All of these directories should be updated by the user to reflect where their output data from the decode pipeline st stored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = '/Users/shiri/Google Drive/My Drive/MS/SuppData/2024_Tsour/'\n",
    "\n",
    "ccrcc_proj_dir = proj_dir+'pipeline_output/CCRCC/'\n",
    "ccrcc_aa_subs_dir = ccrcc_proj_dir+'AA_subs_pipeline/'# aa_subs_dir is the output folder\n",
    "ccrcc_sample_map = pd.read_excel(ccrcc_aa_subs_dir+'sample_map.xlsx')\n",
    "ccrcc_samples = ['S'+str(i) for i in list(set(ccrcc_sample_map['TMT plex']))]\n",
    "\n",
    "ucec_proj_dir = proj_dir+'pipeline_output/UCEC/'\n",
    "ucec_aa_subs_dir = ucec_proj_dir+'AA_subs_pipeline/'# aa_subs_dir is the output folder\n",
    "ucec_sample_map = pd.read_excel(ucec_aa_subs_dir+'sample_map.xlsx')\n",
    "ucec_samples = ['S'+str(i) for i in list(set(ucec_sample_map['TMT plex']))]\n",
    "\n",
    "brca_proj_dir = proj_dir+'pipeline_output/BRCA/'\n",
    "brca_aa_subs_dir = brca_proj_dir+'AA_subs_pipeline/'# aa_subs_dir is the output folder\n",
    "brca_sample_map = pd.read_excel(brca_aa_subs_dir+'sample_map.xlsx')\n",
    "brca_samples = ['S'+str(i) for i in list(set(brca_sample_map['TMT plex']))]\n",
    "\n",
    "luad_proj_dir = proj_dir+'pipeline_output/LUAD/'\n",
    "luad_aa_subs_dir = luad_proj_dir+'AA_subs_pipeline/'# aa_subs_dir is the output folder\n",
    "luad_sample_map = pd.read_excel(luad_aa_subs_dir+'sample_map.xlsx')\n",
    "luad_samples = ['S'+str(i) for i in list(set(luad_sample_map['TMT plex']))]\n",
    "\n",
    "pdac_proj_dir = proj_dir+'pipeline_output/PDAC/'\n",
    "pdac_aa_subs_dir = pdac_proj_dir+'AA_subs_pipeline/'# aa_subs_dir is the output folder\n",
    "pdac_sample_map = pd.read_excel(pdac_aa_subs_dir+'sample_map.xlsx')\n",
    "pdac_samples = ['S'+str(i) for i in list(set(pdac_sample_map['TMT plex']))]\n",
    "\n",
    "lscc_proj_dir = proj_dir+'pipeline_output/LSCC/'\n",
    "lscc_aa_subs_dir = lscc_proj_dir+'AA_subs_pipeline/'# aa_subs_dir is the output folder\n",
    "lscc_sample_map = pd.read_excel(lscc_aa_subs_dir+'sample_map.xlsx')\n",
    "lscc_samples = ['S'+str(i) for i in list(set(lscc_sample_map['TMT plex']))]\n",
    "\n",
    "wang_proj_dir = proj_dir+'pipeline_output/HealthyTissues/'\n",
    "wang_data_dir = wang_proj_dir+'AA_subs_pipeline/'# aa_subs_dir is the output folder\n",
    "wang_samples = open(wang_data_dir+'proteomic_tissue_list.txt', 'r').read().split('\\n')\n",
    "wang_samples = [x for x in wang_samples if x!='rectum']\n",
    "\n",
    "# lists used to quickly index dataset-specific sample maps (e.g.) from just the dataset name\n",
    "datasets = ['CCRCC', 'UCEC', 'BRCA', 'LUAD', 'PDAC', 'LSCC', 'Healthy']\n",
    "data_dir_list = [ccrcc_aa_subs_dir, ucec_aa_subs_dir, brca_aa_subs_dir, luad_aa_subs_dir, pdac_aa_subs_dir, lscc_aa_subs_dir, wang_data_dir]\n",
    "samples_list = [ccrcc_samples, ucec_samples, brca_samples, luad_samples, pdac_samples, lscc_samples, wang_samples]\n",
    "sample_map_list = [ccrcc_sample_map, ucec_sample_map, brca_sample_map, luad_sample_map, pdac_sample_map, lscc_sample_map]\n",
    "proj_dir_list = [ccrcc_proj_dir, ucec_proj_dir, brca_proj_dir, luad_proj_dir, pdac_proj_dir, lscc_proj_dir, wang_proj_dir]\n",
    "\n",
    "outdir = 'figures/' # output directory where to save figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridShader():\n",
    "    \"\"\"\n",
    "    function used to create alternating vertical gray and white background in plots\n",
    "    \"\"\"\n",
    "    def __init__(self, ax, first=True, **kwargs):\n",
    "        self.spans = []\n",
    "        self.sf = first\n",
    "        self.ax = ax\n",
    "        self.kw = kwargs\n",
    "        self.ax.autoscale(False, axis=\"x\")\n",
    "        self.cid = self.ax.callbacks.connect('xlim_changed', self.shade)\n",
    "        self.shade()\n",
    "    def clear(self):\n",
    "        for span in self.spans:\n",
    "            try:\n",
    "                span.remove()\n",
    "            except:\n",
    "                pass\n",
    "    def shade(self, evt=None):\n",
    "        self.clear()\n",
    "        xticks = self.ax.get_xticks()\n",
    "        xlim = self.ax.get_xlim()\n",
    "        xticks = xticks[(xticks > xlim[0]) & (xticks < xlim[-1])]\n",
    "        locs = np.concatenate(([[xlim[0]], xticks, [xlim[-1]]]))\n",
    "\n",
    "        start = [x-0.5 for x in locs[1-int(self.sf)::2]]\n",
    "        end = [x-0.5 for x in locs[2-int(self.sf)::2]]\n",
    "\n",
    "        for s, e in zip(start, end):\n",
    "            self.spans.append(self.ax.axvspan(s, e, zorder=0, **self.kw))\n",
    "\n",
    "\n",
    "def bihist(y1, y2, nbins=10, h=None):\n",
    "    '''\n",
    "    Function used to create violin plots as bihistograms with no smoothing.\n",
    "    h is an axis handle. If not present, a new figure is created.\n",
    "    '''\n",
    "    if h is None: h = plt.figure().add_subplot(111)\n",
    "    ymin = np.floor(np.minimum(min(y1), min(y2)))\n",
    "    ymax = np.ceil(np.maximum(max(y1), max(y2)))\n",
    "    bins = np.linspace(ymin, ymax, nbins)\n",
    "    n1, bins1, patch1 = h.hist(y1, bins, orientation='horizontal', color='#AAAAAA', edgecolor=None, linewidth=0,rwidth=1)\n",
    "    n2, bins2, patch2 = h.hist(y2, bins, orientation='horizontal', color='#AAAAAA', edgecolor=None, linewidth=0,rwidth=1)\n",
    "    # set xmax:\n",
    "    xmax = 0\n",
    "    for i in patch1:\n",
    "        i.set_edgecolor(None)\n",
    "        width = i.get_width()\n",
    "        if width > xmax: xmax = width\n",
    "    # invert second histogram and set xmin:\n",
    "    xmin = 0\n",
    "    for i in patch2:\n",
    "        i.set_edgecolor(None)\n",
    "        width = i.get_width()\n",
    "        width = -width\n",
    "        i.set_width(width)\n",
    "        if width < xmin: xmin = width\n",
    "    h.set_xlim(xmin*1.1, xmax*1.1)          \n",
    "    h.figure.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1. SAAP detection\n",
    "\n",
    "#### Incl. Extended Data Figure 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig1a. N peptide IDs through filtering steps, from all DP to validated SAAP. Data used in generating Fig1a in biorender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get number of samples in each dataset\n",
    "n_samples_data = []\n",
    "total = 0\n",
    "for ds in datasets:\n",
    "    if ds!='Healthy':\n",
    "        sample_map = sample_map_list[datasets.index(ds)]\n",
    "        samples = sample_map['sample_name'].values\n",
    "    else:\n",
    "        samples = samples_list[datasets.index(ds)] \n",
    "    n_samples = len(samples)\n",
    "    total += n_samples\n",
    "    n_samples_data.append([ds, n_samples])\n",
    "    print(ds, n_samples)\n",
    "print(total)\n",
    "n_samples_df = pd.DataFrame(n_samples_data, columns=['Dataset', 'N samples'])\n",
    "n_samples_df.to_excel(outdir+'N_samples_in_datasets.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filter_df(data_dir, samples):\n",
    "    \"\"\" function that reads in output from decode pipeline to get number of peptides in each category\n",
    "    Input: directory with output files for dataset, dataset samples/TMT set names\n",
    "    output: dataframe with the number of peptides in each category used to create fig 1a, c\n",
    "    \"\"\"\n",
    "    dp_ev_dict = pickle.load(open(data_dir+'DP_search_evidence_dict.p', 'rb'))\n",
    "    dp_dict = pickle.load(open(data_dir+'DP_dict.p', 'rb'))\n",
    "    mtp_dict = pickle.load(open(data_dir+'MTP_dict.p', 'rb'))\n",
    "    ptm_dict = pickle.load(open(data_dir+'PTM_dict.p', 'rb'))\n",
    "    hc_mtp_dict = pickle.load(open(data_dir+'qMTP_dict.p', 'rb'))\n",
    "    substr_dict = pickle.load(open(data_dir+'genome_substr_dict.p', 'rb'))\n",
    "    val_mtp_dict = pickle.load(open(data_dir+'Ion_validated_MTP_dict.p','rb'))\n",
    "    \n",
    "    rows = []\n",
    "    for s in samples:\n",
    "        seqs = [[x for y in list(mtp_dict[s]['mistranslated sequence'].values()) for x in y] for s in samples]\n",
    "        seqs = [x for y in seqs for x in y]\n",
    "        homolog_seqs = substr_dict['all_6frame_seqs']\n",
    "        seqs_hom = [x for x in seqs if x in homolog_seqs]\n",
    "        \n",
    "        n_main = len(dp_ev_dict[s]['Raw file'])\n",
    "        n_dp = len(dp_dict[s]['Raw file'])\n",
    "        n_ptm = len(ptm_dict[s]['Raw file'])\n",
    "        n_aas = len(mtp_dict[s]['Raw file'])\n",
    "        n_nohom = len([i for i,x in mtp_dict[s]['mistranslated sequence'].items() if all(y not in seqs_hom for y in x)])\n",
    "        n_hc = len([i for i,x in hc_mtp_dict[s]['mistranslated sequence'].items() if all(y not in seqs_hom for y in x)])\n",
    "        n_val = len(val_mtp_dict[s]['Raw file'])\n",
    "\n",
    "        rows.append([s, n_main, n_dp, n_ptm, n_aas, n_nohom, n_hc, n_val])\n",
    "    df = pd.DataFrame(rows, columns=['TMT set', 'Main peptides', 'DP', 'PTM', 'AAS', 'Non-homologous', 'High-confidence', 'Validated'])\n",
    "\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary containing the dataframes generated with the above function for each dataset\n",
    "filter_dict = {}\n",
    "for ds in datasets:\n",
    "    print(ds)\n",
    "    data_dir = data_dir_list[datasets.index(ds)]\n",
    "    samples = samples_list[datasets.index(ds)]\n",
    "    filter_dict[ds] = get_filter_df(data_dir, samples)\n",
    "pickle.dump(filter_dict, open(outdir+'Modified_peptide_filter_dict_DP2valSAAP.p', 'wb'))\n",
    "#filter_dict = pickle.load(open(outdir+'Modified_peptide_filter_dict_DP2valSAAP.p', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print numbers needed for figure 1A - all datasets\n",
    "1. Total N DP \n",
    "2. Total N match to AAS\n",
    "3. Total N match to AAS and not genome\n",
    "4. Total N match to AAS, not genome and high confidence\n",
    "5. Total N validated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([filter_dict[ds] for ds in datasets])\n",
    "\n",
    "sum_dict = {}\n",
    "for col in all_df.columns:\n",
    "    if col not in ['TMT set', 'Dataset', 'Tissue']:\n",
    "        sum_dict[col] = np.nansum(all_df[col].values)\n",
    "        \n",
    "print(sum_dict) # these values are used in 1a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1c. Filtering modified peptides to candidate SAAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_rows = []\n",
    "for i,row in all_df.iterrows():\n",
    "    boxplot_rows.append([row['Dataset'], row['Main peptides'], 'Main peptides', row['TMT set']])\n",
    "    boxplot_rows.append([row['Dataset'], row['DP'], 'Dependent peptides', row['TMT set']])\n",
    "    boxplot_rows.append([row['Dataset'], row['PTM'], 'Peptides with PTM', row['TMT set']])\n",
    "    #boxplot_rows.append([row['Dataset'], row['AAS'], 'Peptides with AAS', row['TMT set']])\n",
    "    #boxplot_rows.append([row['Dataset'], row['Non-homologous'], 'Non-homologous AAS', row['TMT set']])\n",
    "    boxplot_rows.append([row['Dataset'], row['High-confidence'], 'High-confidence AAS', row['TMT set']])\n",
    "    \n",
    "boxplot_df = pd.DataFrame(boxplot_rows, columns=['Dataset','N peptide IDs', 'Peptide type', 'TMT set'])\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(4,3.5))\n",
    "sns.set_style('whitegrid')\n",
    "plt.grid(True,which=\"major\",c='gray')  \n",
    "plt.grid(True,which=\"minor\",ls=\"--\",c='gray', linewidth=0.3)  \n",
    "\n",
    "sns.stripplot(data= boxplot_df, x='Dataset', y='N peptide IDs', hue='Peptide type',dodge=False,s=3, linewidth=0.4, edgecolor='k')\n",
    "sns.boxplot(data= boxplot_df, x='Dataset', y='N peptide IDs', hue='Peptide type', dodge=False, linewidth=0.5, fliersize=0.7, saturation=1)\n",
    "plt.yscale('log')\n",
    "plt.ylim([100,10**6])\n",
    "plt.xticks(rotation=45, fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.ylabel('# peptides$/$sample', fontsize=15)\n",
    "plt.xlabel('')\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "custom_labels = ['Main peptides', 'Modified peptides', 'Peptides with PTM','Candidate SAAP']\n",
    "plt.legend(handles=handles[0:], labels=custom_labels, bbox_to_anchor=(0.5,1.1), fontsize=11, ncol=2, labelspacing=0.3, handletextpad=0, frameon=False, columnspacing=0.3, loc='center');\n",
    "plt.savefig(outdir+'Dataset_filtering_boxplot_wmainpeptides.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 1D. PTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ptm_df(ptm_dict):\n",
    "\"\"\"\n",
    "function to get a dataframe of PTMS x datasets from the datasets' PTM_dict.p\n",
    "\"\"\"\n",
    "    master_ptm_list = []\n",
    "    for s,v in ptm_dict.items():\n",
    "        s_ptm_dict = v['PTM']\n",
    "        for ptm_list in s_ptm_dict.values():\n",
    "            new_ptm_list = [x for x in ptm_list if x not in master_ptm_list]\n",
    "            new_ptm_list = list(set(new_ptm_list))\n",
    "            master_ptm_list = master_ptm_list + new_ptm_list\n",
    "\n",
    "    heatmap_df = pd.DataFrame(index=master_ptm_list, columns=list(range(1,24)))\n",
    "    for s, v in ptm_dict.items():\n",
    "        s_int = int(s[1:])\n",
    "        ptm_list = list(v['PTM'].values())\n",
    "        ptm_list = [x for y in ptm_list for x in y]\n",
    "        ptm_count = Counter(ptm_list)\n",
    "        for ptm, count in ptm_count.items():\n",
    "            heatmap_df.loc[ptm, s_int] = count\n",
    "            #heatmap_df.loc[ptm, s_int] = np.log10(count)\n",
    "    heatmap_df.fillna(0, inplace=True)\n",
    "    return(heatmap_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get PTM dataframe for each dataset\n",
    "for i in range(len(datasets)):\n",
    "    print(datasets[i])\n",
    "    data_dir =  data_dir_list[i]\n",
    "    ptm_dict = pickle.load(open(data_dir+'PTM_dict.p', 'rb'))\n",
    "    heatmap_df = get_ptm_df(ptm_dict)\n",
    "    heatmap_df.to_excel(data_dir+'PTM_heatmap_df.xlsx')\n",
    "    \n",
    "# create a dictionary with the PTM dataframes for each dataset\n",
    "ptm_heatmap_dict = {}\n",
    "for i,ds in enumerate(datasets):\n",
    "    data_dir = data_dir_list[i]\n",
    "    ptm_df = pd.read_excel(data_dir + 'PTM_heatmap_df.xlsx', index_col=0)\n",
    "    ptm_df['avg'] = [np.mean(row.values) for i,row in ptm_df.iterrows()]\n",
    "    ptm_df.sort_values('avg', ascending=False, inplace=True) # sort by frequency to extract top PTMs for plot\n",
    "    \n",
    "    ptm_df.index = [x[0].upper()+x[1:] for x in ptm_df.index]\n",
    "    ptm_heatmap_dict[ds] = ptm_df\n",
    "    \n",
    "pickle.dump(ptm_heatmap_dict, open(outdir+'PTM_heatmap_dict.p', 'wb'))\n",
    "#ptm_heatmap_dict = pickle.load(open(nofilter_outdir+'PTM_heatmap_dict.p', 'rb'))\n",
    "\n",
    "\n",
    "# extract the top PTMs by frequency into a dataframe for plotting\n",
    "top20 = []\n",
    "for ds, ds_df in ptm_heatmap_dict.items():\n",
    "    if len(top20)==0:\n",
    "        top20 = ds_df.index.values[0:40]\n",
    "    else:\n",
    "        top20new = ds_df.index.values[0:40]\n",
    "        top20 = [x for x in top20 if x in top20new]\n",
    "plot_df = pd.DataFrame(index=top20, columns=datasets)\n",
    "for ptm in top20:\n",
    "    for ds in datasets:\n",
    "        heatmap_df = ptm_heatmap_dict[ds]\n",
    "        plot_df.loc[ptm,ds] = heatmap_df.loc[ptm,'avg']\n",
    "plot_df = plot_df.astype(float)\n",
    "\n",
    "# need number of peptides IDd to normalize N each PTM per 1000 peptides\n",
    "ds_metrics= pd.read_excel(outdir+'Dataset_metrics.xlsx', index_col=0) # dataframe created externally with number of peptides identified in the main seach of each dataset\n",
    "n_peptides_list = []\n",
    "for ds in datasets:\n",
    "    n_peptides = ds_metrics.loc[ds_metrics['Dataset']==ds, 'Peptides (evidence)'].values[0]\n",
    "    n_peptides_list.append(n_peptides)\n",
    "\n",
    "# normalize PTM plot df by per thousand peptides\n",
    "scaled_plot_df = deepcopy(plot_df)\n",
    "for i,ds in enumerate(datasets):\n",
    "    scaled_plot_df[ds] = [x/(n_peptides_list[i]/1000) for x in scaled_plot_df[ds]]\n",
    "scaled_plot_df.to_excel(outdir+'PTM_heatmap_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot PTM heatmap\n",
    "cg = sns.clustermap(data=scaled_plot_df, yticklabels=True,norm=LogNorm(), cbar_kws={'orientation':'horizontal', 'ticks':[0.01,0.1,1,10]},\n",
    "                    figsize=(5,5.5), cmap=sns.color_palette('rocket', as_cmap=True), method='ward', col_cluster=False, row_cluster=True)\n",
    "cg.ax_cbar.set_title(r'PTMs per thousand peptides')\n",
    "plt.setp(cg.ax_heatmap.xaxis.get_majorticklabels(), rotation=90, fontsize=12)\n",
    "plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), fontsize=11)\n",
    "x0, y0, w, h = cg.cbar_pos\n",
    "cg.ax_cbar.set_position([0.5, 0.04, 0.4, 0.04])\n",
    "cg.ax_row_dendrogram.set_visible(False)\n",
    "plt.savefig(outdir+'PTM_heatmap_top20.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exteded data figure 1e.  Types of modifications identified (PTM, chemical, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_PTMs = []\n",
    "for ds, ptm_df in ptm_heatmap_dict.items():\n",
    "    ds_ptms = list(ptm_df.index)\n",
    "    all_PTMs = all_PTMs + ds_ptms\n",
    "set_PTMs = list(set(all_PTMs))\n",
    "\n",
    "# create a dictionary with the classification of each modification type\n",
    "mod_class_dict = {}\n",
    "mod_list =  pickle.load(open(outdir+'Modifications_dict.p', 'rb')) # derived from Unimod database\n",
    "for mod_dict in mod_list:\n",
    "    mod_name = mod_dict['Description']\n",
    "    class_keys = [x for x in mod_dict if 'classification' in x]\n",
    "    classes = [mod_dict[k] for k in class_keys if mod_dict[k]!=['Multiple']]\n",
    "    classes = list(set([x if 'glycosylation' not in x else 'Post-translational' for x in classes]))\n",
    "    mod_class_dict[mod_name.lower()] = classes\n",
    "\n",
    "# get the number of modifications pertaining to each class\n",
    "ptm_ptms = []\n",
    "chemical_ptms = []\n",
    "artifact_ptms = []\n",
    "ptm_or_chemical_ptms = []\n",
    "chem_or_artifact_ptms = []\n",
    "ptm_or_artifact_ptms = []\n",
    "alltypes_ptms = []\n",
    "\n",
    "for i,ptm in enumerate(set_PTMs):\n",
    "    if 'TMT' not in ptm:\n",
    "        ptm = ptm.lower()\n",
    "        ptm_class = mod_class_dict[ptm]\n",
    "        if 'Post-translational' in ptm_class:\n",
    "            if len(ptm_class)==1:\n",
    "                ptm_ptms.append(ptm)\n",
    "            elif 'Chemical derivative' in ptm_class and 'Artefact' in ptm_class:\n",
    "                alltypes_ptms.append(ptm)\n",
    "            elif 'Chemical derivative' in ptm_class:\n",
    "                ptm_or_chemical_ptms.append(ptm)\n",
    "            elif 'Artefact' in ptm_class:\n",
    "                ptm_or_artifact_ptms.append(ptm)\n",
    "\n",
    "        elif 'Chemical derivative' in ptm_class:\n",
    "            if len(ptm_class)==1:\n",
    "                chemical_ptms.append(ptm)\n",
    "            elif 'Artefact' in ptm_class:\n",
    "                chem_or_artifact_ptms.append(ptm)\n",
    "        elif 'Artefact' in ptm_class:\n",
    "            artifact_ptms.append(ptm)\n",
    "    else:\n",
    "        chemical_ptms.append(ptm)\n",
    "\n",
    "n_ptms = len(ptm_ptms)\n",
    "n_chemical_dervs = len(chemical_ptms)\n",
    "n_artifacts = len(artifact_ptms)\n",
    "n_ptm_chem = len(ptm_or_chemical_ptms)\n",
    "n_chem_artifact = len(chem_or_artifact_ptms)\n",
    "n_ptm_artifact = len(ptm_or_artifact_ptms)\n",
    "n_any = len(alltypes_ptms)\n",
    "\n",
    "# plot the Venn diagram\n",
    "fig,ax = plt.subplots(figsize=(3,2))\n",
    "v = venn3(subsets = (n_ptms, n_chemical_dervs, n_ptm_chem, n_artifacts, n_ptm_artifact, n_chem_artifact, n_any),\n",
    "         set_labels = ('Post-\\ntranslational', 'Chemical\\nderivative', 'Artifact'), ax=ax)\n",
    "plt.savefig(outdir+'PTM_source.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data Figure 1a,b. N samples per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of samples in each CPTAC dataset and plot\n",
    "\n",
    "plot_rows = []\n",
    "plot_cols = ['Dataset', 'N samples', 'Sample type']\n",
    "for ds in datasets[:-1]:\n",
    "    sample_map = sample_map_list[datasets.index(ds)]\n",
    "    n_t_samples = len(sample_map.loc[sample_map['Group']=='Tumor'])\n",
    "    n_n_samples = len(sample_map.loc[sample_map['Group']=='Normal'])\n",
    "    plot_rows.append([ds, n_t_samples, 'Tumor'])\n",
    "    plot_rows.append([ds, n_n_samples, 'Normal adjacent tissue'])\n",
    "\n",
    "plot_df = pd.DataFrame(plot_rows, columns=plot_cols)\n",
    "sns.set_style('whitegrid')\n",
    "fig,ax = plt.subplots(figsize=(4.5,3))\n",
    "sns.barplot(data=plot_df, x='Dataset', y='N samples', hue='Sample type', palette=sns.color_palette(palette='Greys', n_colors=2))\n",
    "ax.tick_params('both', labelsize=12)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('# samples', fontsize=14)\n",
    "plt.ylim([0,155])\n",
    "plt.yticks([0,25,50,75,100,125,150])\n",
    "plt.bar_label(plt.gca().containers[0])\n",
    "plt.bar_label(plt.gca().containers[1])\n",
    "plt.legend(ncol=2, bbox_to_anchor=(1.04,1.15), frameon=False, fontsize=13, handletextpad=0.1)\n",
    "plt.savefig(outdir+'CPTAC_N_samples_per_dataset.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of samples in each healthy tissue and plot\n",
    "\n",
    "plot_rows = []\n",
    "plot_cols = ['Tissue', 'N samples', 'Protease']\n",
    "for sample in wang_samples:\n",
    "    n = 1\n",
    "    protease = 'trypsin'\n",
    "    if sample == 'liver':\n",
    "        n = 4\n",
    "    elif sample == 'colon' or sample == 'placenta' or sample == 'lung' or sample == 'stomach' :\n",
    "        n = 2\n",
    "    plot_rows.append([sample, n, protease])\n",
    "    plot_rows.append(['tonsil', 5, 'trypsin'])\n",
    "    plot_rows.append(['tonsil', 2, 'chymotrypsin'])\n",
    "    plot_rows.append(['tonsil', 1, 'LysN/ArgC/GluC'])\n",
    "    #plot_rows.append(['tonsil', 1, 'GluC'])\n",
    "    #plot_rows.append(['tonsil', 1, 'ArgC'])\n",
    "\n",
    "plot_df = pd.DataFrame(plot_rows, columns=plot_cols)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "fig,ax = plt.subplots(figsize=(6,2))\n",
    "#fig,axes = plt.subplots(1,2, figsize=(8,3), sharey=True, gridspec_kw={'width_ratios':[4,1]})\n",
    "plt.subplots_adjust(wspace=0.03)\n",
    "\n",
    "sns.barplot(data=plot_df, x='Tissue', y='N samples', hue='Protease', dodge=False, palette=sns.color_palette(palette='Greys', n_colors=4)[1:])\n",
    "ax.tick_params('both', labelsize=12)\n",
    "ax.tick_params('x', rotation=90)\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('# samples', fontsize=14)\n",
    "ax.set_ylim([0,5])\n",
    "plt.legend(ncol=3, bbox_to_anchor=(0.5,1.05), frameon=False, fontsize=13, loc='center', handletextpad=0.1)\n",
    "\n",
    "    \n",
    "plt.savefig(outdir+'Healthy_N_samples_per_dataset.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data Figure 1i. Mass errors of SAAP and main peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a dictionary with mass error data\n",
    "mass_err_dict = {ds:{'Main peptide mass error':[], 'SAAP mass error':[]} for ds in datasets}\n",
    "for ds in datasets:\n",
    "    print(ds)\n",
    "    data_dir = data_dir_list[datasets.index(ds)]\n",
    "    mainpep_dict = pickle.load(open(data_dir+'DP_search_evidence_dict.p','rb'))\n",
    "    samples = samples_list[datasets.index(ds)]\n",
    "    for s in samples:\n",
    "        print(s)\n",
    "        errs = mainpep_dict[s]['Mass error [ppm]']\n",
    "        errs = [x for x in errs if np.abs(x)<10000]\n",
    "        mass_err_dict[ds]['Main peptide mass error'] = mass_err_dict[ds]['Main peptide mass error']+errs\n",
    "\n",
    "pickle.dump(mass_err_dict, open(outdir+'Main_peptide_mass_error_ppm.p','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mass_err_dict = pickle.load(open(outdir+'Main_peptide_mass_error_ppm.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mass error boxplots\n",
    "plot_df_list = []\n",
    "for ds in datasets:\n",
    "    print(ds)\n",
    "    ds_me_dict = mass_err_dict[ds]\n",
    "    main_pep_errs = ds_me_dict['Main peptide mass error']\n",
    "    #if ds!='UCEC':\n",
    "    saap_errs = [np.abs(x) for x in ds_me_dict['SAAP mass error']]\n",
    "    saap_errs = saap_errs + [-x for x in saap_errs]\n",
    "    ds_list = [ds]*len(main_pep_errs+saap_errs)\n",
    "    main_str_list = ['Main peptide']*len(main_pep_errs)\n",
    "    saap_str_list = ['SAAP']*len(saap_errs)\n",
    "    \n",
    "    ds_plot_df = pd.DataFrame(zip(ds_list, main_pep_errs+saap_errs, main_str_list+saap_str_list), columns=['Dataset', 'Mass error (ppm)', 'Peptide type'])\n",
    "    plot_df_list.append(ds_plot_df)\n",
    "plot_df = pd.concat(plot_df_list)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(3,4))\n",
    "sns.boxplot(data=plot_df, y='Dataset', hue='Peptide type', x='Mass error (ppm)', linewidth=1, fliersize=0, palette='Greys')\n",
    "plt.xlabel('Mass error (ppm)', fontsize=15)\n",
    "ax.tick_params('both', labelsize=14)\n",
    "plt.ylabel('')\n",
    "plt.xlim([-2.5,2.5])\n",
    "plt.legend(loc='lower left', fontsize=14, bbox_to_anchor=(-0.2,0.97), frameon=False, ncol=2, handletextpad=0.1, columnspacing=0.8)\n",
    "plt.savefig(outdir+'Mass_error_boxplots.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1f. Number of fragments covering site of substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_frags_over_MTP(frag_match, mtp, sub_idx):\n",
    "    \"\"\"\n",
    "    Input: fragment matches for peptide from msms.txt (MQ output file), peptide sequence, index of AAS on sequence\n",
    "    Output: number of fragment ions covering site of AAS\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for f, frag in enumerate(frag_match):\n",
    "        mtp_frag=0\n",
    "        if ('NH3' not in frag) and ('H2O' not in frag) and ('(' not in frag) and ('a' not in frag):\n",
    "            if 'b' in frag:\n",
    "                frag_start = 0\n",
    "                frag_end = int(frag[1:])\n",
    "                frag_seq = mtp[frag_start:frag_end]\n",
    "                if frag_end>sub_idx:\n",
    "                    mtp_frag = 1\n",
    "            elif 'y' in frag:\n",
    "                frag_start = -int(frag[1:])\n",
    "                frag_seq = mtp[frag_start:]\n",
    "                if len(mtp)+frag_start <= sub_idx:\n",
    "                    mtp_frag=1\n",
    "            count+=mtp_frag\n",
    "        \n",
    "    return(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add fragment evidence data to Validation_MTP_dict.p for each dataset\n",
    "\n",
    "for ds in datasets:\n",
    "    print(ds)\n",
    "    data_dir = data_dir_list[datasets.index(ds)]\n",
    "    mtp_dict = pickle.load(open(data_dir+'Validated_MTP_dict.p','rb'))\n",
    "    val_evidence_dict = pickle.load(open(data_dir+'Validation_search_evidence_dict.p', 'rb'))\n",
    "    MQ_dir = data_dir+'MQ_output/Validation_search'\n",
    "    samples = samples_list[datasets.index(ds)]\n",
    "\n",
    "    for s in samples:\n",
    "        print(s)\n",
    "       # if s not in done:\n",
    "        ev = val_evidence_dict[s]\n",
    "        with open(MQ_dir+'/'+s+'/txt/msms.txt') as msms_file:\n",
    "            msms = pd.read_csv(msms_file, '\\t', low_memory=False)\n",
    "            msms_vals = msms.values\n",
    "\n",
    "            mtp_dict[s]['fragment_evidence'] = {}\n",
    "            for k,v in mtp_dict[s]['aa subs'].items():\n",
    "                seq = mtp_dict[s]['mistranslated sequence'][k]\n",
    "                bp = mtp_dict[s]['DP Base Sequence'][k]\n",
    "                sub_idx = [i for i,x in enumerate(bp) if seq[i]!=x][0]\n",
    "\n",
    "                ev_idx = mtp_dict[s]['idx_val_evidence'][k]\n",
    "                mtp_dict[s]['fragment_evidence'][k] = 0\n",
    "                for idx in ev_idx:\n",
    "                    row = ev.iloc[idx,:]\n",
    "                    raw_file = row['Raw file']\n",
    "                    scan = row['MS/MS scan number']\n",
    "                    scan_row_idx = [i for i in range(len(msms_vals)) if (msms_vals[i][0]==raw_file) and (msms_vals[i][1]==scan)]\n",
    "                    #scan_row = msms.loc[(msms['Raw file']==raw_file) & (msms['Scan number']==scan),:]\n",
    "                    if len(scan_row_idx)>0:\n",
    "                        scan_row = msms.iloc[scan_row_idx[0]]\n",
    "                        frag_match = scan_row['Matches'].split(';')\n",
    "                        count_frags = n_frags_over_MTP(frag_match, seq, sub_idx)\n",
    "                        if count_frags>mtp_dict[s]['fragment_evidence'][k]:\n",
    "                            mtp_dict[s]['fragment_evidence'][k] = count_frags\n",
    "        msms_file.close()\n",
    "    pickle.dump(mtp_dict, open(data_dir+'Validated_MTP_dict.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataframe with fragment ion data\n",
    "cats = ['0', '1','2-5','6-10','>10']\n",
    "scan_counts = [0,0,0,0,0]\n",
    "pep_counts = [0,0,0,0,0]\n",
    "\n",
    "for ds in datasets:\n",
    "    print(ds)\n",
    "    data_dir = data_dir_list[datasets.index(ds)]\n",
    "    samples = samples_list[datasets.index(ds)]\n",
    "    mtp_dict = pickle.load(open(data_dir+'Validated_MTP_dict.p','rb'))\n",
    "\n",
    "    for s in samples:\n",
    "        s_dict = mtp_dict[s]\n",
    "        for i,n in s_dict['fragment_evidence'].items():\n",
    "            if n ==0:\n",
    "                scan_counts[0]+=1\n",
    "            elif n ==1:\n",
    "                scan_counts[1]+=1\n",
    "            elif (n >1) and (n <=5):\n",
    "                scan_counts[2]+=1\n",
    "            elif (n>5) and (n <=10):\n",
    "                scan_counts[3]+=1\n",
    "            else:\n",
    "                scan_counts[4]+=1\n",
    "\n",
    "plot_df = pd.DataFrame(zip(cats,scan_counts), columns=['Bin', 'Count'])\n",
    "plot_df['Used'] = ['Yes' if row['Bin'] not in ['0','1'] else 'No' for i,row in plot_df.iterrows()]\n",
    "plot_df.to_excel(outdir+'by_fragments_per_saap_4barplot_allDS.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_df = pd.read_excel(outdir+'by_fragments_per_saap_4barplot_allDS.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot n fragments barplots\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "fig,ax = plt.subplots(figsize=(4,4))\n",
    "sns.barplot(data = plot_df, x='Bin', y='Count', hue='Used',dodge=False, palette=['#aaaaaa',colors[0]])   \n",
    "ax.tick_params('both',labelsize=14)\n",
    "\n",
    "plt.ylabel('# peptides', fontsize=15)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles=handles,loc='upper left', labels=['Excluded', 'Included'], fontsize=13)\n",
    "plt.xlabel('# peptide fragments supporting\\nsubstitution site', fontsize=15)\n",
    "plt.savefig(outdir+'fragment_ion_evidence_barplot_allDS.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 1e. % genome homology/% validated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_unq_seqs(data_dir, s):\n",
    "    \"\"\" input: dataset directory, sample\n",
    "        output: number of unique candidate substituted peptides\n",
    "    \"\"\"\n",
    "    hc_mtp_dict = pickle.load(open(data_dir+'qMTP_dict.p', 'rb'))\n",
    "    s_seqs = [x for y in hc_mtp_dict[s]['mistranslated sequence'].values() for x in y]\n",
    "    s_seqs = list(set(s_seqs))\n",
    "    n_seqs = len(s_seqs)\n",
    "    return(n_seqs)\n",
    "\n",
    "def get_n_unq_val(data_dir, s):\n",
    "    \"\"\" input: dataset directory, sample\n",
    "        output: number of unique validated substituted peptides\n",
    "    \"\"\"\n",
    "    val_mtp_dict = pickle.load(open(data_dir+'Ion_validated_MTP_dict.p', 'rb'))\n",
    "    s_seqs = list(val_mtp_dict[s]['mistranslated sequence'].values())\n",
    "    s_seqs = list(set(s_seqs))\n",
    "    n_seqs = len(s_seqs)\n",
    "    return(n_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe with number of unique substituted peptides, candidate and validated\n",
    "rows = []\n",
    "cols = ['Dataset', 'N SAAP sequences', 'SAAP sequence type', 'TMT set']\n",
    "\n",
    "for i,ds in enumerate(datasets):\n",
    "    print(ds)\n",
    "    samples = samples_list[i]\n",
    "    data_dir = data_dir_list[i]\n",
    "    for s in samples:\n",
    "        n_seqs = get_n_unq_seqs(data_dir, s)\n",
    "        n_val_seqs = get_n_unq_val(data_dir, s)\n",
    "        rows.append([ds, n_seqs, 'Candidate', s])\n",
    "        rows.append([ds, n_val_seqs, 'Validated', s])\n",
    "plt_df = pd.DataFrame(rows, columns=cols)\n",
    "\n",
    "# get dataframe with percentage of peptides validated and percentage of peptides with no genome homology (from ds_filter_dict.p generated above)\n",
    "pcnt_rows = []\n",
    "for i,ds in enumerate(datasets):\n",
    "    print(ds)\n",
    "    data_dir = data_dir_list[i]\n",
    "    samples = samples_list[i]\n",
    "    ds_plt_df = plt_df.loc[plt_df['Dataset']==ds,:]\n",
    "    ds_filter_dict = filter_dict[ds]\n",
    "    for j,s in enumerate(samples):\n",
    "        s_df = ds_plt_df.loc[ds_plt_df['TMT set']==s,:]\n",
    "        n_cand = s_df.loc[s_df['AASP sequence type']=='Candidate', 'N AASP sequences'].values[0]\n",
    "        n_val = s_df.loc[s_df['AASP sequence type']=='Validated', 'N AASP sequences'].values[0]\n",
    "        val_pcnt = 100*(n_val/n_cand)\n",
    "        n_aas = ds_filter_dict['AAS'][j]\n",
    "        n_nonhom = ds_filter_dict['Non-homologous'][j]\n",
    "        hom_pcnt = 100*(n_aas - n_nonhom)/n_aas\n",
    "        pcnt_rows.append([ds,s, val_pcnt, 'Validated SAAP'])\n",
    "        pcnt_rows.append([ds,s, hom_pcnt, '6-frame + UTR translation'])\n",
    "pcnt_df = pd.DataFrame(pcnt_rows, columns=['Dataset', 'TMT set', '% peptides', '% type'])\n",
    "nonrectum_row = [i for i,row in pcnt_df.iterrows() if (row['TMT set']!='rectum') and (row['TMT set']!='bonemarrow')] # too little data, removed these tissues from analysis\n",
    "pcnt_df = pcnt_df.loc[nonrectum_row]\n",
    "pcnt_df.to_excel(outdir+'percent_validated_genomehomol_SAAP.xlsx')\n",
    "#pcnt_df = pd.read_excel(outdir+'percent_validated_genomehomol_SAAP.xlsx', index_col=0)\n",
    "\n",
    "# plot figure 1e\n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(3,4.5))\n",
    "sns.boxplot(data=pcnt_df, x='Dataset', y='% peptides', linewidth=0.8, hue='% type', fliersize=0.8, dodge=False)\n",
    "plt.ylim([-0.5,52])\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(rotation=45, fontsize=14)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('% candidate SAAP', fontsize=15)\n",
    "plt.legend(bbox_to_anchor=(-0.2,0.98), frameon=False, loc='lower left', fontsize=13, markerscale=0.5, handletextpad=0.2)\n",
    "plt.savefig(outdir+'percent_validated_genomehom_allDS_boxplot.pdf', bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 1g. Prosit rescoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in results from prosit rescoring\n",
    "rescoring_data = pd.read_csv(rescoring_data_dir+'Rescoring.csv')\n",
    "\n",
    "# plot rescoring data\n",
    "MTP_only = rescoring_data\n",
    "sns.set(style=\"whitegrid\")\n",
    "vect1 = MTP_only['log10PEP_A'].values\n",
    "vect2 = MTP_only['log10PEP_P'].values\n",
    "kde = sp.stats.gaussian_kde(np.vstack([vect1, vect2]))\n",
    "densities = kde(np.vstack([vect1, vect2]))\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.xlabel('-log10(PEP) Andromeda')\n",
    "plt.ylabel('-log10(PEP) Prosit')\n",
    "\n",
    "plt.scatter(\n",
    "    x=MTP_only['log10PEP_A'],\n",
    "    y=MTP_only['log10PEP_P'],\n",
    "    c=densities,  \n",
    "    cmap='viridis', s = 25, alpha=0.75, edgecolor='w', linewidth=0.3)\n",
    "\n",
    "plt.plot(\n",
    "    [0, 15], [0, 15],  \n",
    "    color='red',           \n",
    "    linewidth=2 \n",
    ")\n",
    "\n",
    "plt.xlim(0, 15)\n",
    "plt.ylim(0, 15)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks([0,2,4,6,8,10,12,14])\n",
    "plt.yticks([0,2,4,6,8,10,12,14])\n",
    "plt.xlabel('-log$_{10}$(error prob.), identification', fontsize=15)\n",
    "plt.ylabel('-log$_{10}$(error prob.), rescoring', fontsize=15)\n",
    "\n",
    "plt.savefig(outdir+'Prosit_Rescoring.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1h. Detection of SAAP in multiple digests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the same substitutions in different protease digest from the tonsil data (part of healthy tissues dataset).\n",
    "\n",
    "Two new dictionaries generated here, 'Tonsil_SAAP_dict.p' and 'Tonsil_BP_dict.p' are provided in the shared google drive folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directories and read in files needed to analyze the tonsil data from multiple digests\n",
    "\n",
    "aa_subs_dir = wang_data_dir + 'AA_subs_pipeline/'\n",
    "pub_dir = wang_data_dir+'Publication/'\n",
    "enzymes = ['Trypsin', 'LysC','ArgC', 'GluC','Chymotrypsin']\n",
    "\n",
    "# need the fasta for protein sequences - to match the substitutions across different peptides \n",
    "fasta = open(wang_data_dir+'databases/tonsil_MTP.fasta', 'r').readlines()\n",
    "fasta = [x for x in fasta if x!='\\n' and len(x)>0]\n",
    "fasta_headers = [x for x in fasta if x[0]=='>']\n",
    "fasta_header_lines = [i for i,x in enumerate(fasta) if x[0]=='>']\n",
    "fasta_seqs = [fasta[header_idx+1] for header_idx in fasta_header_lines]\n",
    "\n",
    "\n",
    "mtp_quant_dict = pickle.load(open(aa_subs_dir+'tonsil_MTP_quant_dict_newvalsearch.p', 'rb'))\n",
    "val_mtp_dict = pickle.load(aa_subs_dir+ open('tonsil_Ion_validated_MTP_dict_newvalsearch.p', 'rb'))\n",
    "val_ev_dict = pickle.load(open('tonsil_Validation_search_evidence_dict.p', 'rb'))\n",
    "trypsin_dict = val_mtp_dict['Trypsin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_range_of_pep_in_prot(pep_seq, prot_seq):\n",
    "    \"\"\"\n",
    "    function to get the positions of a peptide sequence in a protein sequence\n",
    "    \"\"\"\n",
    "    start_idx = [x.start() for x in re.finditer(pep_seq, prot_seq)][0]\n",
    "    end_idx = [x.end() for x in re.finditer(pep_seq, prot_seq)][0]\n",
    "    \n",
    "    idx_range = list(range(start_idx,end_idx))\n",
    "    return(idx_range)\n",
    "\n",
    "def get_aa_idx_in_prot(pep_range, aa_idx):\n",
    "    \"\"\"\n",
    "    function to get the position of an AAS in a protein, given the peptide sequence and the index of the AAS in the peptide\n",
    "    \"\"\"\n",
    "    saap_idx = pep_range[0]+aa_idx\n",
    "    return(saap_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionaries for SAAP and BP with protein index position of the AAS annotated tonsil_saap_dict = {}\n",
    "\n",
    "tonsil_saap_dict = {}\n",
    "for s, s_dict in mtp_quant_dict.items():\n",
    "    saap = s_dict['MTP_seq']\n",
    "    bp = s_dict['BP_seq']\n",
    "    aas = s_dict['aa_sub']\n",
    "    aas_idx = s_dict['sub_index'][0]\n",
    "    saap_abund_dict = {k:v for k,v in s_dict['MTP_PrecInt'].items() if ~np.isnan(s_dict['Prec_ratio'][k])}\n",
    "    bp_abund_dict = {k:v for k,v in s_dict['BP_PrecInt'].items() if ~np.isnan(s_dict['Prec_ratio'][k])}\n",
    "    raas_dict = {k:v for k,v in s_dict['Prec_ratio'].items() if ~np.isnan(s_dict['Prec_ratio'][k])}\n",
    "    digests = list(raas_dict.keys())\n",
    "    \n",
    "    tonsil_saap_dict[s] = {'SAAP':saap, 'BP':bp, 'AAS':aas, 'AAS_index':aas_idx, \n",
    "                           'SAAP abundance':saap_abund_dict, 'BP abundance':bp_abund_dict, 'RAAS':raas_dict,\n",
    "                          'Digests':digests, 'Peptide IDs':{}}\n",
    "\n",
    "    prots_w_saap = [i for i,seq in enumerate(fasta_seqs) if re.search(saap, seq)]\n",
    "    for i,prot_idx in enumerate(prots_w_saap):\n",
    "        seq = fasta_seqs[prot_idx]\n",
    "        saap_idx_range = get_idx_range_of_pep_in_prot(saap, seq)\n",
    "        saap_prot_idx = get_aa_idx_in_prot(saap_idx_range, aas_idx)\n",
    "        tonsil_saap_dict[s]['Peptide IDs'][i] = {'saap_prot_fasta_idx':prot_idx, 'saap_prot_range':saap_idx_range, 'saap_prot_idx':saap_prot_idx}\n",
    "\n",
    "pickle.dump(tonsil_saap_dict, open('Tonsil_SAAP_dict.p','wb'))\n",
    "\n",
    "\n",
    "tonsil_bp_dict = {}\n",
    "for s, s_dict in mtp_quant_dict.items():\n",
    "    if s%100==0:\n",
    "        print(s)\n",
    "    bp = s_dict['BP_seq']\n",
    "    rand_idx = random.sample(list(range(len(bp))), 1)[0]\n",
    "    bp_abund_dict = {k:v for k,v in s_dict['BP_PrecInt'].items() if ~np.isnan(s_dict['Prec_ratio'][k])}\n",
    "    digests = list(bp_abund_dict.keys())\n",
    "        \n",
    "    tonsil_bp_dict[s] = {'BP':bp, 'random_index':rand_idx, 'BP abundance':bp_abund_dict, \n",
    "                         'Digests':digests, 'Peptide IDs':{}}\n",
    "    \n",
    "    prots_w_bp = [i for i,seq in enumerate(fasta_seqs) if re.search(bp, seq)]\n",
    "    \n",
    "    for i,prot_idx in enumerate(prots_w_bp):\n",
    "        seq = fasta_seqs[prot_idx]\n",
    "        bp_idx_range = get_idx_range_of_pep_in_prot(bp, seq)\n",
    "        rand_prot_idx = get_aa_idx_in_prot(bp_idx_range, rand_idx)\n",
    "        \n",
    "        tonsil_bp_dict[s]['Peptide IDs'][i] = {'prot_fasta_idx':prot_idx, 'bp_prot_range':bp_idx_range, 'random_prot_idx':rand_prot_idx}\n",
    "pickle.dump(tonsil_bp_dict, open('Tonsil_BP_dict.p','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get proteins and peptide range for all main peptides\n",
    "This chunk was computationally intensive and was run on HPC for each enzyme separately and then combined. But the code is here if want to run locally. The output is also shared in the google drive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_enz_mainpep_prot_idx = {}\n",
    "\n",
    "for enz in enzymes:\n",
    "    print(enz)\n",
    "    all_enz_mainpep_prot_idx[enz] = {}\n",
    "    ev_data = val_ev_dict[enz]\n",
    "    ev_data = ev_data.loc[ev_data['PEP']<=0.01]\n",
    "    set_peps = list(set(ev_data['Sequence'].values))\n",
    "    print(len(set_peps))\n",
    "\n",
    "    for p,pep in enumerate(set_peps):\n",
    "        if p%1000==0:\n",
    "            print(p)\n",
    "\n",
    "        all_enz_mainpep_prot_idx[enz][p] = {'Peptide':pep, 'Peptide IDs':{}}    \n",
    "        prots_w_pep = [i for i,seq in enumerate(fasta_seqs) if re.search(pep, seq)]    \n",
    "\n",
    "        for i,prot_idx in enumerate(prots_w_pep):\n",
    "            seq = fasta_seqs[prot_idx]\n",
    "            pep_idx_range = get_idx_range_of_pep_in_prot(pep, seq)\n",
    "            rand_prot_idx = random.sample(pep_idx_range,1)\n",
    "\n",
    "            all_enz_mainpep_prot_idx[enz][p]['Peptide IDs'][i] = {'prot_fasta_idx':prot_idx, 'pep_prot_range':pep_idx_range, 'random_prot_idx':rand_prot_idx}\n",
    "\n",
    "pickle.dump(all_enz_mainpep_prot_idx, open(aa_subs_dir+'all_tonsil_mainpeps_in_prots_newval_search.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate tonsil_saap_dict and tonsil_bp_dict \n",
    "# with information about if the same substitution site (or random position for bp) is found in other digests\n",
    "\n",
    "tonsil_same_saap_mult_dig = {k:v for k,v in tonsil_saap_dict.items() if len(v['Digests'])>1}\n",
    "for s, sdict in tonsil_saap_dict.items():\n",
    "    if s%100==0:\n",
    "        print(s)\n",
    "    s_prot_dict = sdict['Peptide IDs']\n",
    "    saap = sdict['SAAP']\n",
    "    saap_idx = sdict['AAS_index'] # index of AAS in peptide\n",
    "\n",
    "    digests = sdict['Digests']\n",
    "    all_digests = copy.deepcopy(digests) \n",
    "    alt_peps = {}\n",
    "    for enz in enzymes:\n",
    "        if enz not in digests:\n",
    "            enz_dict = all_enz_mainpep_prot_idx[enz]\n",
    "            for p,prot_dict in s_prot_dict.items():\n",
    "                prot_idx = prot_dict['saap_prot_fasta_idx']\n",
    "                aas_idx = prot_dict['saap_prot_idx'] # index of AAS in protein\n",
    "                \n",
    "                main_peps = []\n",
    "                for k,v in enz_dict.items():\n",
    "                    pep = v['Peptide']\n",
    "                    pep_ids = v['Peptide IDs']\n",
    "                    for i in pep_ids:\n",
    "                        pep_prot_idx = pep_ids[i]['prot_fasta_idx']\n",
    "                        pep_range = pep_ids[i]['pep_prot_range']\n",
    "                        if (pep_prot_idx==prot_idx) and (aas_idx in pep_range):\n",
    "                            if pep[pep_range.index(aas_idx)]==saap[saap_idx]:\n",
    "                                main_peps.append(k)\n",
    "                                alt_peps[enz] = pep\n",
    "                                break\n",
    "                \n",
    "                if len(main_peps)>0:\n",
    "                    all_digests.append(enz)\n",
    "                    break\n",
    "    sdict['Same_seq_digests'] = digests\n",
    "    sdict['All_digests'] = all_digests\n",
    "    sdict['Alternative_peptides'] = alt_peps\n",
    "pickle.dump(tonsil_saap_dict, open(aa_subs_dir+'Tonsil_SAAP_dict.p','wb'))\n",
    "\n",
    "\n",
    "tonsil_same_bp_mult_dig = {k:v for k,v in tonsil_bp_dict.items() if len(v['Digests'])>1}\n",
    "for s, sdict in tonsil_bp_dict.items():\n",
    "    if s%100==0:\n",
    "        print(s)\n",
    "    s_prot_dict = sdict['Peptide IDs']\n",
    "    bp = sdict['BP']\n",
    "    bp_rand_idx = sdict['random_index'] # index of random position on BP\n",
    "    digests = sdict['Digests']\n",
    "    all_digests = copy.deepcopy(digests)\n",
    "\n",
    "    for enz in enzymes:\n",
    "        if enz not in digests:\n",
    "            enz_dict = all_enz_mainpep_prot_idx[enz]\n",
    "\n",
    "            for p,prot_dict in s_prot_dict.items():\n",
    "                prot_idx = prot_dict['prot_fasta_idx']\n",
    "                rand_idx = prot_dict['random_prot_idx'] # index of random position on BP in protein\n",
    "\n",
    "                main_peps = []\n",
    "                for k,v in enz_dict.items():\n",
    "                    pep = v['Peptide']\n",
    "                    pep_ids = v['Peptide IDs']\n",
    "                    for i in pep_ids:\n",
    "                        pep_prot_idx = pep_ids[i]['prot_fasta_idx']\n",
    "                        pep_range = pep_ids[i]['pep_prot_range']\n",
    "                        if (pep_prot_idx==prot_idx) and (rand_idx in pep_range):\n",
    "                            if pep[pep_range.index(rand_idx)]==bp[bp_rand_idx]:\n",
    "                                main_peps.append(k)\n",
    "                                break\n",
    "                if len(main_peps)>0:\n",
    "                    all_digests.append(enz)\n",
    "                    break\n",
    "    sdict['Same_seq_digests'] = digests\n",
    "    sdict['All_digests'] = all_digests\n",
    "pickle.dump(tonsil_bp_dict, open(aa_subs_dir+'Tonsil_BP_dict_Dec2023_newvalsearch.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract metrics for plot from tonsil_saap_dict and tonsil_bp_dict\n",
    "\n",
    "saap_1dig = {k:v for k,v in tonsil_saap_dict.items() if len(v['All_digests'])==1}\n",
    "saap_2dig = {k:v for k,v in tonsil_saap_dict.items() if len(v['All_digests'])==2}\n",
    "saap_2dig_sameseq = {k:v for k,v in tonsil_saap_dict.items() if len(v['All_digests'])==2 and len(v['Digests'])==2}\n",
    "saap_2dig_diffseq = {k:v for k,v in tonsil_saap_dict.items() if len(v['All_digests'])==2 and len(v['Digests'])!=2}\n",
    "saap_3dig = {k:v for k,v in tonsil_saap_dict.items() if len(v['All_digests'])==3}\n",
    "saap_4dig = {k:v for k,v in tonsil_saap_dict.items() if len(v['All_digests'])==4}\n",
    "saap_5dig = {k:v for k,v in tonsil_saap_dict.items() if len(v['All_digests'])==5}\n",
    "saap_gr3dig = {k:v for k,v in tonsil_saap_dict.items() if len(v['All_digests'])>=3}\n",
    "total = len(tonsil_saap_dict)\n",
    "\n",
    "saap_thresh = 1e9\n",
    "e9_saap_1dig = {k:v for k,v in tonsil_saap_dict.items() if len(v['All_digests'])==1 and np.nanmean(list(v['SAAP abundance'].values()))>=saap_thresh}\n",
    "e9_saap_2dig_sameseq = {k:v for k,v in tonsil_saap_dict.items() if len(v['All_digests'])==2 and len(v['Digests'])==2 and np.nanmean(list(v['SAAP abundance'].values()))>=saap_thresh}\n",
    "e9_saap_2dig_diffseq = {k:v for k,v in tonsil_saap_dict.items() if len(v['All_digests'])==2 and len(v['Digests'])!=2 and np.nanmean(list(v['SAAP abundance'].values()))>=saap_thresh}\n",
    "e9_saap_gr3dig = {k:v for k,v in tonsil_saap_dict.items() if len(v['All_digests'])>=3 and np.nanmean(list(v['SAAP abundance'].values()))>=saap_thresh}\n",
    "e9_total = len({k:v for k,v in tonsil_saap_dict.items() if np.nanmean(list(v['SAAP abundance'].values()))>=saap_thresh})\n",
    "\n",
    "saap_thresh = 1e8\n",
    "e8_saap_1dig = {k:v for k,v in tonsil_saap_dict.items() if len(v['All_digests'])==1 and np.nanmean(list(v['SAAP abundance'].values()))>=saap_thresh}\n",
    "e8_saap_2dig_sameseq = {k:v for k,v in tonsil_saap_dict.items() if len(v['All_digests'])==2 and len(v['Digests'])==2 and np.nanmean(list(v['SAAP abundance'].values()))>=saap_thresh}\n",
    "e8_saap_2dig_diffseq = {k:v for k,v in tonsil_saap_dict.items() if len(v['All_digests'])==2 and len(v['Digests'])!=2 and np.nanmean(list(v['SAAP abundance'].values()))>=saap_thresh}\n",
    "e8_saap_gr3dig = {k:v for k,v in tonsil_saap_dict.items() if len(v['All_digests'])>=3 and np.nanmean(list(v['SAAP abundance'].values()))>=saap_thresh}\n",
    "e8_total = len({k:v for k,v in tonsil_saap_dict.items() if np.nanmean(list(v['SAAP abundance'].values()))>=saap_thresh})\n",
    "\n",
    "saap_thresh = 1e7\n",
    "e7_saap_1dig = {k:v for k,v in tonsil_saap_dict.items() if len(v['All_digests'])==1 and np.nanmean(list(v['SAAP abundance'].values()))>=saap_thresh}\n",
    "e7_saap_2dig_sameseq = {k:v for k,v in tonsil_saap_dict.items() if len(v['All_digests'])==2 and len(v['Digests'])==2 and np.nanmean(list(v['SAAP abundance'].values()))>=saap_thresh}\n",
    "e7_saap_2dig_diffseq = {k:v for k,v in tonsil_saap_dict.items() if len(v['All_digests'])==2 and len(v['Digests'])!=2 and np.nanmean(list(v['SAAP abundance'].values()))>=saap_thresh}\n",
    "e7_saap_gr3dig = {k:v for k,v in tonsil_saap_dict.items() if len(v['All_digests'])>=3 and np.nanmean(list(v['SAAP abundance'].values()))>=saap_thresh}\n",
    "e7_total = len({k:v for k,v in tonsil_saap_dict.items() if np.nanmean(list(v['SAAP abundance'].values()))>=saap_thresh})\n",
    "\n",
    "bp_1dig = {k:v for k,v in tonsil_bp_dict.items() if len(v['All_digests'])==1}\n",
    "bp_2dig_sameseq = {k:v for k,v in tonsil_bp_dict.items() if len(v['All_digests'])==2 and len(v['Digests'])==2}\n",
    "bp_2dig_diffseq = {k:v for k,v in tonsil_bp_dict.items() if len(v['All_digests'])==2 and len(v['Digests'])!=2}\n",
    "bp_gr3dig = {k:v for k,v in tonsil_bp_dict.items() if len(v['All_digests'])>=3}\n",
    "bp_total = len(tonsil_bp_dict)\n",
    "\n",
    "bp_thresh = 1e9\n",
    "e9_bp_1dig = {k:v for k,v in tonsil_bp_dict.items() if len(v['All_digests'])==1 and np.nanmean(list(v['BP abundance'].values()))<=bp_thresh}\n",
    "e9_bp_2dig_sameseq = {k:v for k,v in tonsil_bp_dict.items() if len(v['All_digests'])==2 and len(v['Digests'])==2 and np.nanmean(list(v['BP abundance'].values()))<=bp_thresh}\n",
    "e9_bp_2dig_diffseq = {k:v for k,v in tonsil_bp_dict.items() if len(v['All_digests'])==2 and len(v['Digests'])!=2 and np.nanmean(list(v['BP abundance'].values()))<=bp_thresh}\n",
    "e9_bp_gr3dig = {k:v for k,v in tonsil_bp_dict.items() if len(v['All_digests'])>=3 and np.nanmean(list(v['BP abundance'].values()))<=bp_thresh}\n",
    "e9_bp_total = len({k:v for k,v in tonsil_bp_dict.items() if np.nanmean(list(v['BP abundance'].values()))<=bp_thresh})\n",
    "\n",
    "all_saap_pcnt_1dig = 100*len(saap_1dig)/total \n",
    "all_saap_pcnt_2dig_sameseq = 100*len(saap_2dig_sameseq)/total\n",
    "all_saap_pcnt_2dig_diffseq = 100*len(saap_2dig_diffseq)/total\n",
    "all_saap_pcnt_3dig = 100*len(saap_gr3dig)/total\n",
    "\n",
    "e9_saap_pcnt_1dig = 100*len(e9_saap_1dig)/e9_total \n",
    "e9_saap_pcnt_2dig_sameseq = 100*len(e9_saap_2dig_sameseq)/e9_total\n",
    "e9_saap_pcnt_2dig_diffseq = 100*len(e9_saap_2dig_diffseq)/e9_total\n",
    "e9_saap_pcnt_3dig = 100*len(e9_saap_gr3dig)/e9_total\n",
    "\n",
    "e8_saap_pcnt_1dig = 100*len(e8_saap_1dig)/e8_total \n",
    "e8_saap_pcnt_2dig_sameseq = 100*len(e8_saap_2dig_sameseq)/e8_total\n",
    "e8_saap_pcnt_2dig_diffseq = 100*len(e8_saap_2dig_diffseq)/e8_total\n",
    "e8_saap_pcnt_3dig = 100*len(e8_saap_gr3dig)/e8_total\n",
    "\n",
    "e7_saap_pcnt_1dig = 100*len(e7_saap_1dig)/e7_total \n",
    "e7_saap_pcnt_2dig_sameseq = 100*len(e7_saap_2dig_sameseq)/e7_total\n",
    "e7_saap_pcnt_2dig_diffseq = 100*len(e7_saap_2dig_diffseq)/e7_total\n",
    "e7_saap_pcnt_3dig = 100*len(e7_saap_gr3dig)/e7_total\n",
    "\n",
    "e9_bp_pcnt_1dig = 100*len(e9_bp_1dig)/e9_bp_total \n",
    "e9_bp_pcnt_2dig_sameseq = 100*len(e9_bp_2dig_sameseq)/e9_bp_total\n",
    "e9_bp_pcnt_2dig_diffseq = 100*len(e9_bp_2dig_diffseq)/e9_bp_total\n",
    "e9_bp_pcnt_3dig = 100*len(e9_bp_gr3dig)/e9_bp_total\n",
    "\n",
    "bp_pcnt_1dig = 100*len(bp_1dig)/bp_total \n",
    "bp_pcnt_2dig_sameseq = 100*len(bp_2dig_sameseq)/bp_total\n",
    "bp_pcnt_2dig_diffseq = 100*len(bp_2dig_diffseq)/bp_total\n",
    "bp_pcnt_3dig = 100*len(bp_gr3dig)/bp_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stacked barplot showing the % of SAAP in multiple digests\n",
    "\n",
    "bar_df = pd.DataFrame({'1 digest':[bp_pcnt_1dig, e9_bp_pcnt_1dig, e9_saap_pcnt_1dig, e8_saap_pcnt_1dig, e7_saap_pcnt_1dig, all_saap_pcnt_1dig],\n",
    "                     '2 digests, same sequence':[bp_pcnt_2dig_sameseq, e9_bp_pcnt_2dig_sameseq, e9_saap_pcnt_2dig_sameseq, e8_saap_pcnt_2dig_sameseq, e7_saap_pcnt_2dig_sameseq, all_saap_pcnt_2dig_sameseq],\n",
    "                     '2 digests, different sequence':[bp_pcnt_2dig_diffseq, e9_bp_pcnt_2dig_diffseq, e9_saap_pcnt_2dig_diffseq, e8_saap_pcnt_2dig_diffseq, e7_saap_pcnt_2dig_diffseq, all_saap_pcnt_2dig_diffseq],\n",
    "                     '3+ digests':[bp_pcnt_3dig, e9_bp_pcnt_3dig, e9_saap_pcnt_3dig, e8_saap_pcnt_3dig, e7_saap_pcnt_3dig, all_saap_pcnt_3dig]},\n",
    "                      index=['BP', 'BP$\\leq$10$^{9}$','SAAP>10$^{9}$','SAAP>10$^{8}$', 'SAAP>10$^{7}$', 'All SAAP'])\n",
    "\n",
    "saap_bar_df = bar_df.loc[[i for i in bar_df.index if 'SAAP' in i]]\n",
    "bp_bar_df = bar_df.loc[[i for i in bar_df.index if 'BP' in i]]\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "fig,ax = plt.subplots(figsize=(4,6), sharex=True)\n",
    "palette = sns.color_palette('rocket_r', n_colors=10)\n",
    "palette = [colors[0], palette[0], palette[3], palette[6], palette[9]]\n",
    "\n",
    "bar_df.plot(kind='barh',stacked=True, figsize=(4,3), color=palette, linewidth=0.1, ax=ax)\n",
    "ax.set_yticks([])\n",
    "ax.legend().remove()\n",
    "ax.set_xlabel('% peptides', fontsize=15)\n",
    "ax.tick_params('x', labelsize=13)\n",
    "plt.legend(bbox_to_anchor=(-0.5,1), ncol=2, frameon=False, loc='lower left', handletextpad=0.1, fontsize=11)\n",
    "\n",
    "plt.savefig(outdir+'BP_SAAP_%multdigests_bar_binnedSAAP_horz_newvalsearch_bpthresh.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ridgeplot with the abundance distributions of the peptides in each bar of the barplot \n",
    "\n",
    "ridge_rows = []\n",
    "ridge_cols = ['log$_{10}$(Abundance)','Group']\n",
    "\n",
    "for s,sdict in tonsil_saap_dict.items():\n",
    "    saap_abund = np.log10(np.mean(list(sdict['SAAP abundance'].values())))\n",
    "    bp_abund = np.log10(np.mean(list(sdict['BP abundance'].values())))\n",
    "    \n",
    "    if saap_abund!=0 and bp_abund!=0:\n",
    "        if saap_abund<=7:\n",
    "            ridge_rows.append([saap_abund, 'All SAAP'])\n",
    "        elif saap_abund<=8:\n",
    "            ridge_rows.append([saap_abund, 'All SAAP'])\n",
    "            ridge_rows.append([saap_abund, 'Log$_{10}$SAAP>7'])\n",
    "        elif saap_abund<=9:\n",
    "            ridge_rows.append([saap_abund, 'All SAAP'])\n",
    "            ridge_rows.append([saap_abund, 'Log$_{10}$SAAP>7'])\n",
    "            ridge_rows.append([saap_abund, 'Log$_{10}$SAAP>8'])\n",
    "            ridge_rows.append([saap_abund, 'Log$_{10}$SAAP>9'])\n",
    "        ridge_rows.append([bp_abund, 'BP'])\n",
    "        if bp_abund<=9:\n",
    "            ridge_rows.append([bp_abund, 'Log$_{10}$BP<9'])\n",
    "\n",
    "ridge_df = pd.DataFrame(ridge_rows, columns=ridge_cols)\n",
    "ridge_df.replace(-np.inf, np.nan, inplace=True)\n",
    "ridge_df.replace(np.inf, np.nan, inplace=True)\n",
    "ridge_df.dropna(how='any', axis=0, inplace=True)\n",
    "\n",
    "bp_ridge_df = ridge_df.loc[ridge_df['Group']=='BP']\n",
    "saap_ridge_df = ridge_df.loc[ridge_df['Group']!='BP']\n",
    "\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('whitegrid')\n",
    "g = sns.FacetGrid(ridge_df, row='Group', aspect=3, height=0.6, sharex=True,sharey=False, gridspec_kws={'hspace':-0.05},\n",
    "                 row_order=['All SAAP', 'Log$_{10}$SAAP>7', 'Log$_{10}$SAAP>8', 'Log$_{10}$SAAP>9', 'Log$_{10}$BP<9', 'BP'])\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[])\n",
    "g.set(xticks=[7,9,11])\n",
    "g.map_dataframe(sns.kdeplot, x='log$_{10}$(Abundance)', fill=True, color='#AAAAAA', alpha=0.5)\n",
    "g.savefig(outdir+'BP_SAAP_abund_ridgeplot_nevalsearch.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data Figure 1g. PEP post-FDR correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the p-values determined by MaxQuant and the q-values determined from only the substituted peptides\n",
    "\n",
    "plot_rows = []\n",
    "plot_cols = ['Dataset', 'TMT/Tissue', 'q-value', 'PEP']\n",
    "for ds in datasets:\n",
    "    data_dir = data_dir_list[datasets.index(ds)]\n",
    "    samples = samples_list[datasets.index(ds)]\n",
    "    qmtp_dict = pickle.load(open(data_dir+'qMTP_dict.p', 'rb'))\n",
    "    for s in samples:\n",
    "        s_dict = qmtp_dict[s]\n",
    "        for k,v in s_dict['Posterior subs probability'].items():\n",
    "            plot_rows.append([ds, s, 1-v[0], s_dict['q-value'][k][0]])\n",
    "plot_df = pd.DataFrame(plot_rows, columns=plot_cols)\n",
    "\n",
    "plot_df['-log q'] = plot_df.apply(lambda x: -np.log10(x['q-value']),axis=1)\n",
    "plot_df['-log PEP'] = plot_df.apply(lambda x: -np.log10(x['PEP']),axis=1)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(2.5,2.5))\n",
    "sns.ecdfplot(plot_df, x='-log q', label='log$_{10}$(q)')\n",
    "sns.ecdfplot(plot_df, x='-log PEP', label='log$_{10}$(PEP)')\n",
    "plt.ylabel('Cumulative density', fontsize=14)\n",
    "plt.xlabel('-log$_{10}$(FDR)', fontsize=14)\n",
    "ax.tick_params('both', labelsize=13)\n",
    "plt.plot((2,2), plt.ylim(), '--r')\n",
    "plt.legend(loc='lower right', fontsize=12, handletextpad=0.1)\n",
    "plt.savefig(outdir+'qvalue_CumDensity_plot.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data Figure 1 c,d. Trancript coverage stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_matches(file_path, regex_pattern):\n",
    "    \"\"\"Finds all instances of a regular expression in a text file.\n",
    "\n",
    "    Args:\n",
    "    file_path: Path to the text file.\n",
    "    regex_pattern: The regular expression pattern to search for.\n",
    "\n",
    "    Returns:\n",
    "    A list of all matching strings.\n",
    "    \"\"\"\n",
    "\n",
    "    matches = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            for match in re.finditer(regex_pattern, line):\n",
    "                matches.append(match.group())\n",
    "    return(matches)\n",
    "\n",
    "\n",
    "def get_transcrip_coverage(tmap_path):\n",
    "    \"\"\"\n",
    "    Returns the fraction of a transcriptome sequence that was contained a read.\n",
    "    Input is the path to a .gft.tmap file, generated by the custom protein database pipeline\n",
    "    Output is the a list of the fraction covered of each sequence in the file provided\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    lines = zip_ref.open(tmap_path, 'r').readlines()\n",
    "    lines = [line.decode('utf-8') for line in lines]\n",
    "    lines = [x.split('\\n')[0] for x in lines]\n",
    "    cols = [x for x in lines[0].split('\\t') if len(x)>0]\n",
    "    mtx = [x.split('\\t') for x in lines[1:]]\n",
    "    df = pd.DataFrame(mtx, columns=cols)\n",
    "    t_len = df['len'].astype(int).to_list()\n",
    "    match_len = df['ref_match_len'].to_list()\n",
    "    match_len = [int(x) if x!='-' else 0 for x in match_len]\n",
    "    frac_cov = [match_len[i]/t_len[i] for i in range(len(match_len))]\n",
    "    frac_cov = [x for x in frac_cov if x<=1]\n",
    "    return(frac_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a dictionary with each sample in each dataset and a list of the transcript sequence covereage in each samples database\n",
    "seq_cov_frac = {ds:{} for ds in datasets}\n",
    "for ds in datasets:\n",
    "    print(ds)\n",
    "    ds_dir = proj_dir_list[datasets.index(ds)]\n",
    "    rnaseq_dir = ds_dir+'RNAseq_data/'\n",
    "    zip_files = glob(rnaseq_dir+'*files2transfer.zip')\n",
    "\n",
    "    print(len(zip_files))\n",
    "    for i,zipdir in enumerate(zip_files):\n",
    "        sample = zipdir.split('/')[-1].split('.')[0]\n",
    "        file2read = 'files2transfer/'+sample+'.gffcmp.'+sample+'.stringtie.gtf.tmap'\n",
    "        try:\n",
    "            with zipfile.ZipFile(zipdir, 'r') as zip_ref:\n",
    "                try:\n",
    "                    frac_cov = get_transcrip_coverage(file2read)\n",
    "                    seq_cov_frac[ds][sample] = frac_cov\n",
    "                except:\n",
    "                    print('file not found')\n",
    "        except:\n",
    "            print('notzipfile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract and plot overall distribution of the transcript sequence coverage per sample         \n",
    "frac_cov = [list(seq_cov_frac[ds].values()) for ds in datasets]\n",
    "frac_cov = [x for y in frac_cov for x in y]\n",
    "frac_cov = [100*x for y in frac_cov]\n",
    "\n",
    "n_samples = np.sum([len(seq_cov_frac[ds].keys()) for ds in datasets])\n",
    "weights=[1/n_samples]*len(frac_cov)\n",
    "plot_df = pd.DataFrame(zip(frac_cov, weights), columns=['Transcript coverage', 'Weight'])\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "fig,ax = plt.subplots(figsize=(3,3))\n",
    "sns.histplot(data=plot_df, x='Transcript coverage', weights='Weight', color='#AAAAAA', linewidth=0, )\n",
    "mean = np.mean(frac_cov)\n",
    "plt.plot((mean, mean), ax.get_ylim(), '--r')\n",
    "ax.annotate('mean$=$'+str(np.round(mean,2))+'%', xy=(40,5e4), fontsize=12)\n",
    "plt.xlabel('Transcript coverage (%)', fontsize=14)\n",
    "plt.ylabel('# transcripts / sample', fontsize=14)\n",
    "ax.tick_params('both', labelsize=13)\n",
    "plt.yscale('log')\n",
    "plt.savefig(outdir+'transcript_coverage_percent_persample_all_hist.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract and plot a distribution of the number of transcripts with 100% sequence coverage\n",
    "\n",
    "plot_rows = []\n",
    "plot_cols = ['Sample', 'N transcripts 100%']\n",
    "for ds in datasets:\n",
    "    ds_dict = seq_cov_frac[ds]\n",
    "    for k,v in ds_dict.items():\n",
    "        plot_rows.append([k, len([x for x in v if x==1])])\n",
    "plot_df = pd.DataFrame(plot_rows, columns=plot_cols)\n",
    "plot_df  = plot_df.loc[plot_df['N transcripts 100%']!=0]\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(3,3))\n",
    "sns.histplot(data=plot_df, x='N transcripts 100%', color='#AAAAAA', linewidth=0, )\n",
    "median = np.median(plot_df['N transcripts 100%'].to_list())\n",
    "plt.plot((median, median), ax.get_ylim(), '--r')\n",
    "ax.annotate('median$=$\\n70,956', xy=(35000,125), fontsize=12)\n",
    "plt.xlabel('# transcripts with\\n100% sequence coverage', fontsize=14)\n",
    "plt.ylabel('# samples', fontsize=14)\n",
    "ax.tick_params('both', labelsize=13)\n",
    "\n",
    "plt.savefig(outdir+'n_transctipts_100pcnt_coverage_all_hist.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data Figure 1h: K/R AAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the file used here is the same as Supplemental_Data_2.SAAP_protein.xlsx but include SAAP with substitutions of K or R which were then filtered out and only has a subset of the columns (no protein data) \n",
    "all_saap_protein_df = pd.read_excel(proj_dir+'pipeline_output/analysis_dependencies/All_SAAP_protein_df_w_KR_AAS.xlsx')\n",
    "\n",
    "# get index of SAAP-BP pairs with substitution of K or R\n",
    "all_aas = all_saap_protein_df['AAS'].values\n",
    "kr_idx = [i for i,aas in enumerate(all_aas) if 'K' in aas or 'R' in aas]\n",
    "\n",
    "# subset of K|R substitutions that are K->R or R->K\n",
    "k2r_aas = [i for i in kr_idx if 'K' in all_aas[i] and 'R' in all_aas[i]]\n",
    "\n",
    "# subset of K|R substitutions that are missed cleavages\n",
    "all_kr_saaps = all_saap_protein_df.loc[kr_idx, 'SAAP'].values\n",
    "all_kr_saaps_trimmed = [x[:-1] for x in all_kr_saaps]\n",
    "all_missed_cleavages = [x for x in all_kr_saaps_trimmed if 'K' in x or 'R' in x]\n",
    "missed_cleavage_idx = [i for i in kr_idx if 'R' in  all_saap_protein_df.loc[i,'SAAP'][:-1] or 'K' in  all_saap_protein_df.loc[i,'SAAP'][:-1]]\n",
    "\n",
    "# subsets of K|R substitutions for pie chart\n",
    "other_kr_idx = [i for i in kr_idx if i not in k2r_aas and i not in missed_cleavage_idx]\n",
    "k2r_aas_and_missed = [i for i in k2r_aas if i in missed_cleavage_idx]\n",
    "miss_cleavage_only = [i for i in missed_cleavage_idx if i not in k2r_aas]\n",
    "k2r_aas_only = [i for i in k2r_aas if i not in missed_cleavage_idx]\n",
    "\n",
    "# plot pie chart\n",
    "labels = 'Other K|R\\nAAS', 'Missed\\ncleavage', 'K<>R', 'K<>R +\\nmissed cleavage'\n",
    "sizes = [len(other_kr_idx), len(miss_cleavage_only), len(k2r_aas_only), len(k2r_aas_and_missed)]\n",
    "fig,ax=plt.subplots(figsize=(2,2))\n",
    "ax.pie(sizes, labels=labels, labeldistance=1.1, autopct='%1.f%%')\n",
    "plt.savefig(outdir+'KR_missed_clevage_pie.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 2 - RAAS\n",
    "\n",
    "#### Incl. Extended Data Figures 2, 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in dataframes generated for Supplemental Data Figures.\n",
    "All data in these dataframes was taken from the dictionaries output from the decode pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_saap_df = pd.read_excel(proj_dir+'Supplemental_Data_2.SAAP_proteins.xlsx', index_col=0)\n",
    "filt_prec_quant_df = pd.read_excel(proj_dir+'Supplemental_Data_3.SAAP_precursor_quant.xlsx', index_col=0)\n",
    "filt_reporter_quant_df = pd.read_excel(proj_dir+'Supplemental_Data_4.SAAP_reporter_quant.xlsx', index_col=0)\n",
    "\n",
    "filt_saap_df_list = [filt_saap_df.loc[filt_saap_df['Dataset']==ds] for ds in datasets]\n",
    "reporter_quant_df_list = [filt_reporter_quant_df.loc[filt_reporter_quant_df['Dataset']==ds] for ds in datasets[:-1]]\n",
    "prec_quant_df_list = [filt_prec_quant_df.loc[filt_prec_quant_df['Dataset']==ds] for ds in datasets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2b. sample-level RAAS distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample/reporter ion level RAAS distributions for each dataset \n",
    "\n",
    "fig,axes = plt.subplots(1,len(datasets),figsize=(5,3), sharey=True)\n",
    "plt.subplots_adjust(wspace=0.05)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "for ax in axes:\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.tick_params('x', bottom=False,labelbottom=False)\n",
    "    if ax!=axes[0]:    \n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.tick_params(left=False)\n",
    "\n",
    "medians = [np.nanmedian(reporter_quant_df_list[i]['RAAS'].values) for i in range(len(datasets)-1)]\n",
    "med_sort_idx = list(np.argsort(medians))\n",
    "med_sort_idx.append(max(med_sort_idx)+1)\n",
    "\n",
    "for i,ds in enumerate(datasets):\n",
    "    ax_idx = med_sort_idx.index(i)\n",
    "    axes[ax_idx].set_xlabel(ds, fontsize=12)\n",
    "    if ds!='Healthy':\n",
    "        ratio_data = [x for x in reporter_quant_df_list[i]['RAAS'].values if ~np.isnan(x) and ~np.isinf(x)]\n",
    "    else:\n",
    "        ratio_data = [x for x in prec_quant_df_list[i]['RAAS'].values if ~np.isnan(x) and ~np.isinf(x)]\n",
    "    bihist(ratio_data, ratio_data, nbins=100,h=axes[ax_idx])\n",
    "    if ax_idx==0:\n",
    "        axes[ax_idx].annotate('N= ', (-0.1,1.01), xycoords='axes fraction', fontsize=13)\n",
    "        axes[ax_idx].annotate(str(np.round(len(ratio_data), -3))[0:2]+'k', (0.32,1.01), xycoords='axes fraction', fontsize=13)\n",
    "        \n",
    "    else:\n",
    "        axes[ax_idx].annotate(str(np.round(len(ratio_data), -3))[0:2]+'k', (0.25,1.01), xycoords='axes fraction', fontsize=13)\n",
    "        \n",
    "    axes[ax_idx].plot(axes[ax_idx].get_xlim(), (np.median(ratio_data), np.median(ratio_data)), '--r',linewidth=0.7)\n",
    "\n",
    "axes[0].set_ylabel(r'log$_{10}$(RAAS)', fontsize=15)\n",
    "axes[0].tick_params('y',labelsize=13)\n",
    "axes[0].set_yticks([-6,-4,-2,0,2,4]);\n",
    "\n",
    "plt.savefig(outdir+'Sample_level_RAAS_allDS.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 2b. sample-level RAAS distribution - all datasets in one distribution\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "fig,ax = plt.subplots(figsize=(3,3))\n",
    "\n",
    "ratios = []\n",
    "for i,ds in enumerate(datasets):\n",
    "    if ds!='Healthy':\n",
    "        ratio_data = [x for x in reporter_quant_df_list[i]['RAAS'].values if ~np.isnan(x) and ~np.isinf(x)]\n",
    "    else:\n",
    "        ratio_data = [x for x in prec_quant_df_list[i]['RAAS'].values if ~np.isnan(x) and ~np.isinf(x)]\n",
    "    ratios = ratios + ratio_data\n",
    "    \n",
    "sns.histplot(ratios, color='#AAAAAA', linewidth=0)\n",
    "plt.plot((np.median(ratios), np.median(ratios)),(plt.ylim()), '--r', linewidth=1)\n",
    "ax.annotate('Median =\\n$-$'+str(np.abs(np.round(np.median(ratios), 2))), (-1,2000), fontsize=12)\n",
    "ax.set_ylabel(r'# SAAP', fontsize=14)\n",
    "ax.set_xlabel(r'log$_{10}$(RAAS)', fontsize=14)\n",
    "ax.tick_params('both',labelsize=13)\n",
    "ax.set_xticks([-6,-4,-2,0,2,4]);\n",
    "\n",
    "plt.savefig(outdir+'Sample_level_RAAS_allDS_onehistplot.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data Figure 3a. TMT-level RAAS distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,len(datasets),figsize=(len(datasets),3), sharey=True)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "for ax in axes:\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.tick_params('x', bottom=False,labelbottom=False)\n",
    "    if ax!=axes[0]:    \n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.tick_params(left=False)\n",
    "\n",
    "medians = [np.nanmedian(prec_quant_df_list[i]['RAAS'].values) for i in range(len(datasets)-1)]\n",
    "med_sort_idx = list(np.argsort(medians))\n",
    "med_sort_idx.append(max(med_sort_idx)+1)\n",
    "\n",
    "for i,ds in enumerate(datasets):\n",
    "    ax_idx = med_sort_idx.index(i)\n",
    "    axes[ax_idx].set_xlabel(ds, fontsize=14)\n",
    "    ratio_data = [x for x in prec_quant_df_list[i]['RAAS'].values if ~np.isnan(x) and ~np.isinf(x)]\n",
    "    bihist(ratio_data, ratio_data, nbins=50,h=axes[ax_idx])\n",
    "    if ax_idx==0:\n",
    "        axes[ax_idx].annotate('N= ', (-0.2,1.01), xycoords='axes fraction', fontsize=13)\n",
    "    axes[ax_idx].annotate('{:,}'.format((len(ratio_data))), (0.2,1.01), xycoords='axes fraction', fontsize=13)\n",
    "    axes[ax_idx].plot(axes[ax_idx].get_xlim(), (np.median(ratio_data), np.median(ratio_data)), '--r',linewidth=0.7)\n",
    "\n",
    "axes[0].set_ylabel(r'log$_{10}$(RAAS)', fontsize=15)\n",
    "axes[0].tick_params('y',labelsize=13)\n",
    "\n",
    "plt.savefig(outdir+'TMT_level_RAAS_allDS_nogrid.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data Figure 3c. Sample median RAAS distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,len(datasets),figsize=(len(datasets),3), sharey=True)\n",
    "#plt.ylim([-3.5,0])\n",
    "sns.set_style('whitegrid')\n",
    "for ax in axes:\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.tick_params('x', bottom=False,labelbottom=False)\n",
    "    if ax!=axes[0]:    \n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.tick_params(left=False)\n",
    "\n",
    "sample_median_values_list = []\n",
    "for i,ds in enumerate(datasets):\n",
    "    if ds!='Healthy':\n",
    "        reporter_quant_df = reporter_quant_df_list[i]\n",
    "        samples = list(set(reporter_quant_df['Sample name'].values))\n",
    "        sample_medians = [np.nanmedian(reporter_quant_df.loc[reporter_quant_df['Sample name']==s, 'RAAS'].values) for s in samples]\n",
    "        sample_median_values_list.append(sample_medians)\n",
    "    else:\n",
    "        prec_quant_df = prec_quant_df_list[i]\n",
    "        samples = list(set(prec_quant_df['TMT/Tissue'].values))\n",
    "        sample_medians = [np.nanmedian(prec_quant_df.loc[prec_quant_df['TMT/Tissue']==s, 'RAAS'].values) for s in samples]\n",
    "        sample_median_values_list.append(sample_medians)\n",
    "        \n",
    "medians = [np.nanmedian(sample_median_values_list[i]) for i in range(len(datasets)-1)]\n",
    "med_sort_idx = list(np.argsort(medians))\n",
    "med_sort_idx.append(max(med_sort_idx)+1)\n",
    "\n",
    "for i,ds in enumerate(datasets):\n",
    "    ax_idx = med_sort_idx.index(i)\n",
    "    axes[ax_idx].set_xlabel(ds, fontsize=14)\n",
    "    ratio_data = [x for x in sample_median_values_list[i] if ~np.isnan(x) and ~np.isinf(x)]\n",
    "    bihist(ratio_data, ratio_data, nbins=15,h=axes[ax_idx])\n",
    "    if ax_idx==0:\n",
    "        axes[ax_idx].annotate('N= ', (-0.15,1.01), xycoords='axes fraction', fontsize=13)\n",
    "    axes[ax_idx].annotate('{:,}'.format((len(ratio_data))), (0.25,1.01), xycoords='axes fraction', fontsize=13)\n",
    "    axes[ax_idx].plot(axes[ax_idx].get_xlim(), (np.median(ratio_data), np.median(ratio_data)), '--r',linewidth=0.7)\n",
    "\n",
    "axes[0].set_ylabel(r'log$_{10}$(RAAS)', fontsize=15)\n",
    "axes[0].tick_params('y',labelsize=13)\n",
    "\n",
    "#plt.annotate('Cancer and normal adjacent tissue', (0.14,0.97), xycoords='figure fraction')\n",
    "#plt.show()\n",
    "plt.savefig(outdir+'Sample_median_RAAS_allDS.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended data figure 3b. Median RAAS for all unique SAAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,len(datasets),figsize=(len(datasets),3), sharey=True)\n",
    "sns.set_style('whitegrid')\n",
    "for ax in axes:\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.tick_params('x', bottom=False,labelbottom=False)\n",
    "    if ax!=axes[0]:    \n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.tick_params(left=False)\n",
    "\n",
    "saap_median_values_list = []\n",
    "for i,ds in enumerate(datasets):\n",
    "    if ds!='Healthy':\n",
    "        reporter_quant_df = reporter_quant_df_list[i]\n",
    "        saap = list(set(reporter_quant_df['SAAP'].values))\n",
    "        saap_medians = [np.nanmedian(reporter_quant_df.loc[reporter_quant_df['SAAP']==s, 'RAAS'].values) for s in saap]\n",
    "        saap_median_values_list.append(saap_medians)\n",
    "    else:\n",
    "        prec_quant_df = prec_quant_df_list[i]\n",
    "        saap = list(set(prec_quant_df['SAAP'].values))\n",
    "        saap_medians = [np.nanmedian(prec_quant_df.loc[prec_quant_df['SAAP']==s, 'RAAS'].values) for s in saap]\n",
    "        saap_median_values_list.append(saap_medians)\n",
    "        \n",
    "medians = [np.nanmedian(saap_median_values_list[i]) for i in range(len(datasets)-1)]\n",
    "med_sort_idx = list(np.argsort(medians))\n",
    "med_sort_idx.append(max(med_sort_idx)+1)\n",
    "\n",
    "for i,ds in enumerate(datasets):\n",
    "    ax_idx = med_sort_idx.index(i)\n",
    "    axes[ax_idx].set_xlabel(ds, fontsize=14)\n",
    "    ratio_data = [x for x in saap_median_values_list[i] if ~np.isnan(x) and ~np.isinf(x)]\n",
    "    bihist(ratio_data, ratio_data, nbins=15,h=axes[ax_idx])\n",
    "    if ax_idx==0:\n",
    "        axes[ax_idx].annotate('N= ', (-0.15,1.01), xycoords='axes fraction', fontsize=13)\n",
    "    axes[ax_idx].annotate('{:,}'.format((len(ratio_data))), (0.25,1.01), xycoords='axes fraction', fontsize=13)\n",
    "    axes[ax_idx].plot(axes[ax_idx].get_xlim(), (np.median(ratio_data), np.median(ratio_data)), '--r',linewidth=0.7)\n",
    "\n",
    "axes[0].set_ylabel(r'log$_{10}$(RAAS)', fontsize=15)\n",
    "axes[0].tick_params('y',labelsize=13)\n",
    "\n",
    "plt.savefig(outdir+'SAAP_median_RAAS_allDS.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended data figure 3d. Medians of extended 3a-c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_medians = [np.nanmedian(reporter_quant_df_list[i]['RAAS'].values) for i in range(len(datasets)-1)]\n",
    "all_medians.append(np.nanmedian(prec_quant_df_list[-1]['RAAS'].values))\n",
    "sample_median_values_list = []\n",
    "for i,ds in enumerate(datasets):\n",
    "    if ds!='Healthy':\n",
    "        reporter_quant_df = reporter_quant_df_list[i]\n",
    "        samples = list(set(reporter_quant_df['Sample name'].values))\n",
    "        sample_medians = [np.nanmedian(reporter_quant_df.loc[reporter_quant_df['Sample name']==s, 'RAAS'].values) for s in samples]\n",
    "        sample_median_values_list.append(sample_medians)\n",
    "    else:\n",
    "        prec_quant_df = prec_quant_df_list[i]\n",
    "        samples = list(set(prec_quant_df['TMT/Tissue'].values))\n",
    "        sample_medians = [np.nanmedian(prec_quant_df.loc[prec_quant_df['TMT/Tissue']==s, 'RAAS'].values) for s in samples]\n",
    "        sample_median_values_list.append(sample_medians)\n",
    "sample_medians = [np.nanmedian(sample_median_values_list[i]) for i in range(len(datasets))]\n",
    "\n",
    "saap_median_values_list = []\n",
    "for i,ds in enumerate(datasets):\n",
    "    if ds!='Healthy':\n",
    "        reporter_quant_df = reporter_quant_df_list[i]\n",
    "        saap = list(set(reporter_quant_df['SAAP'].values))\n",
    "        saap_medians = [np.nanmedian(reporter_quant_df.loc[reporter_quant_df['SAAP']==s, 'RAAS'].values) for s in saap]\n",
    "        saap_median_values_list.append(saap_medians)\n",
    "    else:\n",
    "        prec_quant_df = prec_quant_df_list[i]\n",
    "        saap = list(set(prec_quant_df['SAAP'].values))\n",
    "        saap_medians = [np.nanmedian(prec_quant_df.loc[prec_quant_df['SAAP']==s, 'RAAS'].values) for s in saap]\n",
    "        saap_median_values_list.append(saap_medians)\n",
    "        \n",
    "saap_medians = [np.nanmedian(saap_median_values_list[i]) for i in range(len(datasets))]\n",
    "\n",
    "plot_rows = []\n",
    "plot_cols = ['Dataset', 'Median RAAS', 'Median type']\n",
    "for m, median in enumerate(all_medians):\n",
    "    plot_rows.append([datasets[m], median, 'All data median'])\n",
    "for m, median in enumerate(sample_medians):\n",
    "    plot_rows.append([datasets[m], median, 'Sample median'])\n",
    "for m, median in enumerate(saap_medians):\n",
    "    plot_rows.append([datasets[m], median, 'SAAP median'])\n",
    "    \n",
    "plot_df = pd.DataFrame(plot_rows, columns=plot_cols)    \n",
    "\n",
    "fig,ax = plt.subplots(figsize=(6,3))\n",
    "sns.swarmplot(data=plot_df, x='Dataset', y='Median RAAS', hue='Median type', s=8,\n",
    "              order=['LUAD','LSCC','CCRCC','BRCA','UCEC','PDAC','Healthy'])\n",
    "plt.legend(title='', fontsize=13)\n",
    "ax.tick_params('both', labelsize=13)\n",
    "plt.ylabel('Median log$_{10}$(RAAS)', fontsize=14)\n",
    "plt.xlabel('')\n",
    "plt.savefig(outdir+'RAAS_distribution_median_comparison_swarmplot.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2g. Proteins with high RAAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dataframe was generated separately using the results from the protein set enrichment analysis \n",
    "\n",
    "ref_prot_df = pd.read_excel(proj_dir+'pipeline_output/analysis_dependencies/Reference_proteins_ranked_Median_RAAS.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "fig,ax = plt.subplots(figsize=(9,4))\n",
    "\n",
    "hue_order=['Protein transport and degradation','DNA, RNA processing and metabolism','Signaling and enzymatic reactions', 'Immune response', 'Cytokeletal and stuctural', 'Small molecule metabolism', 'Oxidative stress response', 'Transcription factor']\n",
    "nonpath_rows = [i for i,row in ref_prot_df.iterrows() if row['Median RAAS']>-1 and row['Pathway group'] not in hue_order]\n",
    "\n",
    "sns.scatterplot(data=ref_prot_df.loc[nonpath_rows], x='Rank', y='Median RAAS', color='#aaaaaa', s=80, linewidth=0, alpha=1)\n",
    "sns.scatterplot(data=ref_prot_df.loc[(ref_prot_df['Median RAAS']>-1) & (ref_prot_df['Pathway group']!='')], x='Rank', y='Median RAAS', s=80, hue='Pathway group', linewidth=0.2,alpha=0.8,\n",
    "                palette=colors[0:7]+['black'], hue_order=hue_order)\n",
    "\n",
    "ax.tick_params('both', labelsize=15)\n",
    "plt.xlabel('Protein rank', fontsize=17)\n",
    "plt.ylabel('Median log$_{10}$(RAAS)', fontsize=17)\n",
    "plt.legend(title='', fontsize=11)\n",
    "\n",
    "ranks2plot = [0,495,4,34,171, 158, 6]\n",
    "sns.scatterplot(data=ref_prot_df.loc[ref_prot_df['Rank'].isin(ranks2plot)], x='Rank', y='Median RAAS', s=120, hue='Pathway group', linewidth=0.8, alpha=1,\n",
    "                palette=colors[0:7]+['black'], hue_order=hue_order)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles=handles[:8], labels=labels[:8], fontsize=11, bbox_to_anchor=(1,1))\n",
    "\n",
    "texts2plot = ['LYST: Lysosomal trafficking regulator', 'PSMA1: Proteasome\\n'+r'subunit $\\alpha$ type-1',\n",
    "             'FES: Tyrosine-protein kinase Fes/Fps', 'DDX17: Probable ATP-dependent\\nRNA helicase isoform 3',\n",
    "             'ACTN1: Alpha-actinin-1', 'PSMA4: Proteasome\\n'+r'subunit $\\alpha$ type-4', \n",
    "             'ZNF845: Zinc finger protein 845']\n",
    "colors2plot = [colors[0], colors[0], colors[2], colors[1], colors[4], colors[0], 'black']\n",
    "\n",
    "for i,rank in enumerate(ranks2plot):\n",
    "    txt = texts2plot[i]\n",
    "    y = ref_prot_df.loc[ref_prot_df['Rank']==rank,'Median RAAS']\n",
    "    if 'Proteasome' not in txt and 'actin' not in txt and 'DDX' not in txt:\n",
    "        ax.annotate(txt, xy=(rank,y), xytext=(rank+50,y+0.1), xycoords='data', textcoords='data', va='top',\n",
    "                arrowprops=dict(facecolor='gray', headwidth=5,width=2, linewidth=0), color=colors2plot[i], fontsize=11)\n",
    "    elif 'DDX' in txt:\n",
    "        ax.annotate(txt, xy=(rank,y), xytext=(rank+50,y+0.3), xycoords='data', textcoords='data', va='center',\n",
    "        arrowprops=dict(facecolor='gray', headwidth=5,width=2, linewidth=0), color=colors2plot[i], fontsize=11)\n",
    "    elif 'type-4' in txt:\n",
    "        ax.annotate(txt, xy=(rank,y), xytext=(rank-180,y-0.6), xycoords='data', textcoords='data', va='bottom',\n",
    "        arrowprops=dict(facecolor='gray', headwidth=5,width=2, linewidth=0), color=colors2plot[i], fontsize=11)\n",
    "    elif 'type-1' in txt:\n",
    "        ax.annotate(txt, xy=(rank,y), xytext=(rank+45,y+0.4), xycoords='data', textcoords='data', va='bottom',\n",
    "        arrowprops=dict(facecolor='gray', headwidth=5,width=2, linewidth=0), color=colors2plot[i], fontsize=11)\n",
    "    else:\n",
    "        ax.annotate(txt, xy=(rank,y), xytext=(rank-160,y-0.8), xycoords='data', textcoords='data', va='center',\n",
    "        arrowprops=dict(facecolor='gray', headwidth=5,width=2, linewidth=0), color=colors2plot[i], fontsize=11)\n",
    "plt.savefig(outdir+'Protein_group_RAAS_rank_plot.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2d. Peptide precursor ion abundance relative to shared peptide \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raas2bin(raas):\n",
    "    \"\"\" function to bin RAAS values for plotting\"\"\"\n",
    "    if raas<-3:\n",
    "        raas_bin = '[-$\\infty$,-3]'\n",
    "    elif raas<-2:\n",
    "        raas_bin = '(-3,-2]'\n",
    "    elif raas<-1:\n",
    "        raas_bin = '(-2,-1]'\n",
    "    elif raas<0:\n",
    "        raas_bin = '(-1,0]'\n",
    "    elif raas<1:\n",
    "        raas_bin = '(0,1]'\n",
    "    else:\n",
    "        raas_bin = '(1,$\\infty$)'\n",
    "    return(raas_bin)\n",
    "\n",
    "\n",
    "# add RAAS bin and ratios of SAAP and BP to shared peptide abundance\n",
    "filt_prec_quant_df['RAAS_bin'] = filt_prec_quant_df['RAAS'].apply(raas2bin)\n",
    "filt_prec_quant_df['MTP/SP'] = np.nan\n",
    "filt_prec_quant_df['BP/SP'] = np.nan\n",
    "\n",
    "for i,row in filt_prec_quant_df.iterrows():\n",
    "    mtp = row['SAAP abundance']\n",
    "    bp = row['BP abundance']\n",
    "    sp = row['Mean shared peptide precursor intensity']\n",
    "    filt_prec_quant_df.loc[i,'MTP/SP'] = mtp/sp\n",
    "    filt_prec_quant_df.loc[i, 'BP/SP'] = bp/sp\n",
    "\n",
    "raas_bins = ['[-$\\infty$,-3]', '(-3,-2]','(-2,-1]','(-1,0]','(0,1]','(1,$\\infty$)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distributions of abundance of SAAP/BP to shared peptide abundance as a function of RAAS\n",
    "\n",
    "fig,axi = plt.subplots(2, len(raas_bins), figsize=(5,4), sharey=True)#, sharex=True)\n",
    "plt.subplots_adjust(wspace=0, hspace=0.1)\n",
    "sns.set_style('whitegrid')\n",
    "for j, axes in enumerate(axi):\n",
    "    for i,rbin in enumerate(raas_bins):\n",
    "        ax = axes[i]\n",
    "        if j==1:\n",
    "            ax.set_xlabel(rbin, fontsize=14);\n",
    "        ax.set_xticks([])\n",
    "        if j==0:\n",
    "            rbin_data = [np.log10(x) for x in filt_prec_quant_df.loc[filt_prec_quant_df['RAAS_bin']==rbin, 'MTP/SP'].values]\n",
    "            peptype = 'SAAP'\n",
    "        else:\n",
    "            rbin_data = [np.log10(x) for x in filt_prec_quant_df.loc[filt_prec_quant_df['RAAS_bin']==rbin, 'BP/SP'].values]\n",
    "            peptype = 'BP'\n",
    "\n",
    "        rbin_data = [x for x in rbin_data if (~np.isnan(x)) and (~np.isinf(x))]\n",
    "        bihist(rbin_data, rbin_data, nbins=20, h=ax)\n",
    "        if i>0:\n",
    "            ax.spines['left'].set_visible(False)\n",
    "           # ax.set_yticks([])\n",
    "        ax.spines['top'].set_visible(False)\n",
    "\n",
    "        median_abund = np.nanmedian(rbin_data)\n",
    "        print(rbin, median_abund)\n",
    "        ax.plot(ax.get_xlim(), (median_abund, median_abund), '--r')\n",
    "\n",
    "        if ax==axes[-1]:\n",
    "            ax.spines['right'].set_visible(False)\n",
    "        ax.set_ylim([-4.5,4])\n",
    "\n",
    "    axes[0].tick_params('y', labelsize=14)\n",
    "    axes[0].set_yticks([-4,-2,0,2,4], labels=[-4,-2,0,2,'']);\n",
    "    axes[0].annotate(peptype, (0.2, 0.85), xycoords='axes fraction', fontsize=13)   \n",
    "axi[1][0].annotate('log$_{10}$(ratio to shared peptides)', (-0.9,1.1), xycoords='axes fraction', fontsize=15, \n",
    "                   rotation='vertical', va='center')\n",
    "    \n",
    "plt.savefig(outdir+'SAAP_BP_SP_ratio_bihist_RAASbins_allDS.pdf', bbox_inches='tight')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended data figure 2i: Correlations of SAAP|BP to SP across all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a dataframe of the correlations of SAAP/BP abundances to shared peptide abundance \n",
    "# at the reporter ion level, across all sampls\n",
    "\n",
    "corr_dfs = []\n",
    "for d,ds in enumerate(datasets[:-1]):\n",
    "    print(ds)\n",
    "    ds_df = filt_reporter_quant_df.loc[filt_reporter_quant_df['Dataset']==ds]\n",
    "    set_peps = list(set(ds_df['SAAP']))\n",
    "\n",
    "    corr_rows = []\n",
    "    corr_cols = ['Dataset','SAAP','BP', 'N samples', 'RAAS list', 'Median RAAS', 'SAAP corr to mean SP', 'BP corr to mean SP']\n",
    "    for i,pep in enumerate(set_peps):\n",
    "        pep_df = ds_df.loc[ds_df['SAAP']==pep]\n",
    "        set_bps = list(set(pep_df['BP']))\n",
    "        for bp in set_bps:\n",
    "            pep_bp_df = pep_df.loc[pep_df['BP']==bp]\n",
    "            pep_bp_df = pep_bp_df.loc[~np.isnan(pep_bp_df['Mean shared peptide reporter intensity'])]\n",
    "            if len(pep_bp_df)>=10:\n",
    "                SAAP_corr = sp.stats.pearsonr(pep_bp_df['SAAP abundance'], pep_bp_df['Mean shared peptide reporter intensity'])[0]\n",
    "                bp_corr = sp.stats.pearsonr(pep_bp_df['BP abundance'], pep_bp_df['Mean shared peptide reporter intensity'])[0]\n",
    "                raas_list = list(pep_bp_df['RAAS'].values)\n",
    "                n_samples = len(raas_list)\n",
    "                median_raas = np.nanmedian(raas_list)\n",
    "                corr_rows.append([ds, pep, bp, n_samples, raas_list, median_raas, SAAP_corr, bp_corr])\n",
    "    \n",
    "    corr_df = pd.DataFrame(corr_rows, columns=corr_cols)\n",
    "    corr_df['RAAS bin'] = corr_df['Median RAAS'].apply(raas2bin)\n",
    "    corr_df['SAAP - BP corr'] = [row['SAAP corr to mean SP']-row['BP corr to mean SP'] for i,row in corr_df.iterrows()]\n",
    "    corr_df.dropna(how='any', axis=0, inplace=True)\n",
    "    corr_dfs.append(corr_df)\n",
    "    \n",
    "all_corr_df = pd.concat(corr_dfs)\n",
    "all_corr_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot violin plots of correlation distributions as function of RAAS for SAAP (middle panel)\n",
    "\n",
    "fig,axes = plt.subplots(1, len(raas_bins), figsize=(6,3), sharey=True)\n",
    "plt.subplots_adjust(wspace=0)\n",
    "plt.ylim([-1,1.2])\n",
    "sns.set_style('whitegrid')\n",
    "for i,rbin in enumerate(raas_bins):\n",
    "    ax = axes[i]\n",
    "    #ax.set_ylim([-0.5,1])\n",
    "    ax.set_xlabel(rbin, fontsize=13)\n",
    "    ax.set_xticks([])\n",
    "    rbin_data = all_corr_df.loc[all_corr_df['RAAS bin']==rbin, 'SAAP corr to mean SP'].values\n",
    "    print(len(rbin_data))\n",
    "    \n",
    "    bihist(rbin_data, rbin_data, nbins=20, h=ax)\n",
    "    if i>0:\n",
    "        ax.spines['left'].set_visible(False)\n",
    "       # ax.set_yticks([])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "    median_corr = np.nanmedian(rbin_data)\n",
    "    print(rbin, median_corr)\n",
    "    ax.plot(ax.get_xlim(), (median_corr, median_corr), '--r')\n",
    "     \n",
    "    if ax==axes[-1]:\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.plot(ax.get_xlim(), (median_corr, median_corr), '--r', linewidth=0.5)\n",
    "axes[0].set_ylabel('corr(SAAP, shared peptides)', fontsize=14)\n",
    "axes[0].set_yticks([-1, -0.5,0,0.5,1])\n",
    "axes[0].set_yticklabels([-1, -0.5,0,0.5,1], fontsize=13);\n",
    "\n",
    "plt.annotate(r'log$_{10}$(RAAS)',(0.45,0.02), xycoords=('figure fraction'), fontsize=15)\n",
    "plt.savefig(outdir+'SAAP_corr_to_median_SP.png', dpi=300, bbox_inches='tight')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot violin plots of correlation distributions as function of RAAS for SAAP (top panel)\n",
    "\n",
    "fig,axes = plt.subplots(1, len(raas_bins), figsize=(6,3), sharey=True)\n",
    "plt.subplots_adjust(wspace=0)\n",
    "plt.ylim([-1,1.2])\n",
    "sns.set_style('whitegrid')\n",
    "for i,rbin in enumerate(raas_bins):\n",
    "    ax = axes[i]\n",
    "    #ax.set_ylim([-0.5,1])\n",
    "    ax.set_xlabel(rbin, fontsize=13)\n",
    "    ax.set_xticks([])\n",
    "    rbin_data = all_corr_df.loc[all_corr_df['RAAS bin']==rbin, 'BP corr to mean SP'].values\n",
    "    \n",
    "    bihist(rbin_data, rbin_data, nbins=20, h=ax)\n",
    "    if i>0:\n",
    "        ax.spines['left'].set_visible(False)\n",
    "       # ax.set_yticks([])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "    median_corr = np.nanmedian(rbin_data)\n",
    "    print(rbin, median_corr)\n",
    "    ax.plot(ax.get_xlim(), (median_corr, median_corr), '--r')\n",
    "     \n",
    "    if ax==axes[-1]:\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.plot(ax.get_xlim(), (median_corr, median_corr), '--r', linewidth=0.5)\n",
    "axes[0].set_ylabel('corr(BP, shared peptides)', fontsize=14)\n",
    "axes[0].set_yticks([-1, -0.5,0,0.5,1])\n",
    "axes[0].set_yticklabels([-1, -0.5,0,0.5,1], fontsize=13);\n",
    "\n",
    "plt.annotate(r'log$_{10}$(RAAS)',(0.45,0.02), xycoords=('figure fraction'), fontsize=15)\n",
    "plt.savefig(outdir+'BP_corr_to_median_SP.png', dpi=300, bbox_inches='tight')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot violin plots of difference in correlation between SAAP and BP (lower panel)\n",
    "\n",
    "fig,axes = plt.subplots(1, len(raas_bins), figsize=(6,3), sharey=True)\n",
    "plt.subplots_adjust(wspace=0)\n",
    "sns.set_style('whitegrid')\n",
    "for i,rbin in enumerate(raas_bins):\n",
    "    ax = axes[i]\n",
    "    ax.set_xlabel(rbin, fontsize=13)\n",
    "    ax.set_xticks([])\n",
    "    rbin_data = [x for x in all_corr_df.loc[all_corr_df['RAAS bin']==rbin, 'SAAP - BP corr'].values if (~np.isnan(x) and (~np.isinf(x)))]\n",
    "    \n",
    "    bihist(rbin_data, rbin_data, nbins=20, h=ax)\n",
    "    if i>0:\n",
    "        ax.spines['left'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "    median_corr = np.nanmedian(rbin_data)\n",
    "    ax.plot(ax.get_xlim(), (median_corr, median_corr), '--r')\n",
    "\n",
    "axes[0].set_ylabel('Correlation difference', fontsize=14)\n",
    "axes[0].set_yticks([-2,-1,0,1,2])\n",
    "axes[0].set_yticklabels([-2,-1,0,1,2], fontsize=13);\n",
    "\n",
    "\n",
    "axes[2].annotate('log$_{10}$(RAAS)',(0,-0.25), xycoords=('axes fraction'), fontsize=16)\n",
    "\n",
    "plt.savefig(outdir+'SAAP_minus_BP_corr_to_SP.png', dpi=300, bbox_inches='tight')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2i and extended data figure 3i: codon mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codon2aa = {\n",
    "        'ATA':'I', 'ATC':'I', 'ATT':'I', 'ATG':'M',\n",
    "        'ACA':'T', 'ACC':'T', 'ACG':'T', 'ACT':'T',\n",
    "        'AAC':'N', 'AAT':'N', 'AAA':'K', 'AAG':'K',\n",
    "        'AGC':'S', 'AGT':'S', 'AGA':'R', 'AGG':'R',                \n",
    "        'CTA':'L', 'CTC':'L', 'CTG':'L', 'CTT':'L',\n",
    "        'CCA':'P', 'CCC':'P', 'CCG':'P', 'CCT':'P',\n",
    "        'CAC':'H', 'CAT':'H', 'CAA':'Q', 'CAG':'Q',\n",
    "        'CGA':'R', 'CGC':'R', 'CGG':'R', 'CGT':'R',\n",
    "        'GTA':'V', 'GTC':'V', 'GTG':'V', 'GTT':'V',\n",
    "        'GCA':'A', 'GCC':'A', 'GCG':'A', 'GCT':'A',\n",
    "        'GAC':'D', 'GAT':'D', 'GAA':'E', 'GAG':'E',\n",
    "        'GGA':'G', 'GGC':'G', 'GGG':'G', 'GGT':'G',\n",
    "        'TCA':'S', 'TCC':'S', 'TCG':'S', 'TCT':'S',\n",
    "        'TTC':'F', 'TTT':'F', 'TTA':'L', 'TTG':'L',\n",
    "        'TAC':'Y', 'TAT':'Y', 'TAA':'_', 'TAG':'_',\n",
    "        'TGC':'C', 'TGT':'C', 'TGA':'_', 'TGG':'W'\n",
    "}\n",
    "\n",
    "AAs = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "subs_list = [i+' to '+j for i in AAs for j in AAs if i!=j]\n",
    "subs_list = [x for x in subs_list if x[-1]!='L']\n",
    "subs_list = [x if x[-1]!='I' else x[:-1]+'I/L' for x in subs_list]\n",
    "\n",
    "# generate a dictionary with substitution types and their RAAS values for each dataset\n",
    "aas_ratio_dict = {}\n",
    "for i,ds in enumerate(datasets):\n",
    "    print(ds)\n",
    "    subs_dict = {x:[] for x in subs_list}\n",
    "    mtp_quant = pickle.load(open(data_dir_list[i]+'MTP_quant_dict.p', 'rb'))\n",
    "    for k,v in subs_dict.items():\n",
    "        sub_peps = {i:x for i,x in mtp_quant.items() if x['aa_sub']==k}\n",
    "        if len(sub_peps)>0:\n",
    "            sub_ratios = [l for L in [[y for y in x['Prec_ratio'].values() if (~np.isnan(y)) and (~np.isinf(y))] for x in sub_peps.values()] for l in L]\n",
    "            subs_dict[k] = v + sub_ratios\n",
    "    aas_ratio_dict[ds] = subs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataframe for plot\n",
    "\n",
    "plot_rows = []\n",
    "cols = ['Dataset', 'AAS', 'Minimum base error', 'Log substitution ratio', 'Bases changed']\n",
    "\n",
    "for ds in datasets:\n",
    "    subs_dict = aas_ratio_dict[ds]\n",
    "    for k,v in subs_dict.items():\n",
    "        base_codons = [i for i,x in codon2aa.items() if x==k[0]]\n",
    "        dest_codons =  [i for i,x in codon2aa.items() if x==k[-1]]\n",
    "        if base_codons!=dest_codons: # case of I/L to I/L\n",
    "            min_change = 3\n",
    "            min_changes = [1,2,3]\n",
    "            for b in base_codons:\n",
    "                for d in dest_codons:\n",
    "                    change = len([x for i,x in enumerate(b) if d[i]!=x])\n",
    "                    if change<min_change:\n",
    "                        min_change=change\n",
    "                        min_changes = [i+1 for i,x in enumerate(b) if d[i]!=x]\n",
    "                    elif change==min_change:\n",
    "                        new_changes = [i+1 for i,x in enumerate(b) if d[i]!=x]\n",
    "                        if new_changes[0]>min_changes[0]:\n",
    "                            min_changes=new_changes\n",
    "\n",
    "            for aasr in v:\n",
    "                aasr = np.log10(2**aasr)\n",
    "                plot_rows.append([ds, k, min_change, aasr, min_changes])\n",
    "\n",
    "plot_df = pd.DataFrame(plot_rows, columns=cols)\n",
    "plot_df.to_excel(outdir+'Codon_change_df.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_df = pd.read_excel(outdir+'Codon_change_df.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for all dataset separately (extended 3i)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "fig,ax = plt.subplots(figsize=(6,1.6))\n",
    "sns.boxplot(data=plot_df, x='Dataset', y='Log substitution ratio', hue='Minimum base error', dodge=True, fliersize=0.5, linewidth=0.8)\n",
    "plt.ylabel(r'log$_{10}$(RAAS)', fontsize=15);\n",
    "plt.xlabel('')\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "handles,labels = ax.get_legend_handles_labels()\n",
    "ph = [plt.plot([],marker=\"\", ls=\"\")[0]]\n",
    "plt.legend(handles=ph+handles, labels=['# codon mismatches:']+labels ,bbox_to_anchor=(0.45,1.05), fontsize=13, ncol=4, frameon=False, \n",
    "           columnspacing=0.7, handletextpad=0.1, loc='center')\n",
    "plt.savefig(outdir+'RAAS_vs_nCodonMismatches.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for all dataset together (figure 2i)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "fig,ax = plt.subplots(figsize=(1.7,3))\n",
    "sns.boxplot(data=plot_df, x='Minimum base error', y='Log substitution ratio', fliersize=0.5, linewidth=0.8, color='#AAAAAA')\n",
    "plt.ylabel(r'log$_{10}$(RAAS)', fontsize=14);\n",
    "plt.xlabel('# codon mismatches', fontsize=14)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.savefig(outdir+'allDS_RAAS_vs_nCodonMismatches.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended data figure 3j. T and V tRNA ligase abundances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " aa_name_letter_dict = {'cysteine': 'C', 'aspartate': 'D', 'serine': 'S', 'glutamine': 'Q', 'lysine': 'K',\n",
    "     'isoleucine': 'I', 'proline': 'P', 'threonine': 'T', 'phenylalanine': 'F', 'asparagine': 'N', \n",
    "     'glycine': 'G', 'histidine': 'H', 'leucine': 'L', 'arginine': 'R', 'tryptophan': 'W', \n",
    "     'alanine': 'A', 'valine':'V', 'glutamate': 'E', 'tyrosine': 'Y', 'methionine': 'M'}\n",
    "\n",
    "aa_letter_name_dict = {v:k for k,v in aa_name_letter_dict.items()}\n",
    "\n",
    "# this dictionary was generated in a separate script using the MaxQuant protein output data\n",
    "aars_abund_dict = pickle.load(open(proj_dir+'pipeline_output/analysis_dependencies/refnorm_AARS_abund_dict.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boxplot_data(aas):\n",
    "    \"\"\" function to get data for plotting tRNA ligase abundances of 2 amino acids, given a subsitution type\"\"\"\n",
    "    aa1 = aa_letter_name_dict[aas[0]]\n",
    "    aa2 = aa_letter_name_dict[aas[-1]]\n",
    "    \n",
    "    boxplot_rows = []\n",
    "    cols=['Reporter-distributed\\nprecursor intensity', 'tRNA ligase', 'Dataset']\n",
    "    \n",
    "    for ds in datasets[:-1]:\n",
    "        aars_df = aars_abund_dict[ds]\n",
    "        #aa1_aars_vals = [x for x in aars_df.loc[[i for i,row in aars_df.iterrows() if (aa1 in row['Unnamed: 0']) and ('mitochondria' not in row['Unnamed: 0'])],:].values[0][1:-1] if ~np.isnan(x)]\n",
    "        #aa2_aars_vals = [x for x in aars_df.loc[[i for i,row in aars_df.iterrows() if (aa2 in row['Unnamed: 0']) and ('mitochondria' not in row['Unnamed: 0'])],:].values[0][1:-1] if ~np.isnan(x)]\n",
    "        aa1_aars_vals = [x for x in aars_df.loc[[i for i,row in aars_df.iterrows() if (aa1 in i) and ('mitochondria' not in i)],:].values.flatten() if ~np.isnan(x)]\n",
    "        aa2_aars_vals = [x for x in aars_df.loc[[i for i,row in aars_df.iterrows() if (aa2 in i) and ('mitochondria' not in i)],:].values.flatten() if ~np.isnan(x)]\n",
    "\n",
    "        [boxplot_rows.append([val, aa1+'-tRNA ligase', ds]) for val in aa1_aars_vals]\n",
    "        [boxplot_rows.append([val, aa2+'-tRNA ligase', ds]) for val in aa2_aars_vals]\n",
    "    boxplot_df = pd.DataFrame(boxplot_rows, columns=cols)\n",
    "    \n",
    "    return(boxplot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate boxplot for substitution type\n",
    "\n",
    "aas = 'T to V'\n",
    "boxplot_df = get_boxplot_data(aas)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(3,2))\n",
    "sns.boxplot(data=boxplot_df, y='Reporter-distributed\\nprecursor intensity', x='Dataset', hue='tRNA ligase', linewidth=0.8, fliersize=0)\n",
    "#plt.ylim([0,0.8])\n",
    "ax.tick_params('y', labelsize=13)\n",
    "plt.xlabel('')\n",
    "plt.ylim([0,6])\n",
    "ax.legend(bbox_to_anchor=(0.5,1.15), fontsize=11, title='', frameon=False, loc='center')\n",
    "ax.tick_params('x', rotation=45, labelsize=12)\n",
    "plt.ylabel('Protein levels', fontsize=14)\n",
    "plt.savefig(outdir+'T2V_AAligase_abund.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figures 2k,l and Extended Data Figure 3l,m,n and Supplemental Figure 1: Protein turnover analysis with metabolic pulse SILAC data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savitski_dir = proj_dir+'Savitski/'\n",
    "aa_subs_dir = proj_dir+'AA_subs_pipeline/'\n",
    "val_dir = proj_dir+'MSFragger_validation/'\n",
    "\n",
    "cell_types = ['Hepatocytes','Bcells','Monocytes','NKcells']\n",
    "\n",
    "# read in dataset metadata and create dictionary with values \n",
    "metadata = pd.read_csv(val_dir+'Meta.csv')\n",
    "meta_dict = {}\n",
    "for i,row in metadata.iterrows():\n",
    "    meta_dict[row['raw file']] = {'celltype':row['cell type'], 'timepoint':row['time point'], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in supplemental data file generated from output of running decode pipeline on the savitski data\n",
    "# here there is one line per SAAP-BP per sample (replicates on separate lines)\n",
    "\n",
    "quant_df = pd.read_excel(proj_dir+'Supplemental_Data_5.SAAP_SILAC_quant.xlsx', index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of Hepatocyte RAAS, extended data figure 3l\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(3,3))\n",
    "sns.histplot(data=quant_df, x='Light+Heavy RAAS', color='#AAAAAA', linewidth=0)\n",
    "plt.xlabel('log$_{10}$RAAS', fontsize=14)\n",
    "plt.ylabel('# SAAP', fontsize=14)\n",
    "median = np.nanmedian(quant_df['Light+Heavy RAAS'])\n",
    "plt.plot((median,median), ax.get_ylim(), '--r')\n",
    "plt.annotate('Median$=$\\n'+'$-$'+str(np.round(np.abs(median),2)), xy=(-1,1500), fontsize=12)\n",
    "plt.xticks([-4,-2,0,2])\n",
    "ax.tick_params('both', labelsize=13)\n",
    "plt.savefig(outdir+'Savistki_allhepatocyte_RAAS_distribution.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat the data in quant_df so that there is one line per SAAP-BP pair per cell type\n",
    "# this is more convenient for computing degradation rates \n",
    "# this file is also provided in the google drive folder \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "rep_data_df_list = []\n",
    "quant_data = quant_df\n",
    "\n",
    "celltype = 'Hepatocytes'\n",
    "for celltype in cell_types:\n",
    "    print(celltype)\n",
    "    cell_data = quant_data.loc[quant_data['Cell type']==celltype]\n",
    "    saap_bp = list(set([row['SAAP']+';'+row['BP']+';'+row['AAS'] for i,row in cell_data.iterrows()]))\n",
    "    print(len(saap_bp))\n",
    "    timepoints = sorted(list(set(cell_data['Time'].to_list())))\n",
    "    reps = list(set(cell_data['Replicate'].to_list()))\n",
    "\n",
    "    cols = ['Cell type', 'SAAP', 'BP', 'AAS', 'CPTAC SAAP', \n",
    "            'BP_H_time1_rep1', 'BP_H_time1_rep2', 'BP_H_time2_rep1', 'BP_H_time2_rep2', 'BP_H_time3_rep1', 'BP_H_time3_rep2', 'BP_H_time4_rep1', 'BP_H_time4_rep2',\n",
    "            'BP_L_time1_rep1', 'BP_L_time1_rep2', 'BP_L_time2_rep1', 'BP_L_time2_rep2', 'BP_L_time3_rep1', 'BP_L_time3_rep2', 'BP_L_time4_rep1', 'BP_L_time4_rep2',\n",
    "            'BP_time1_rep1', 'BP_time1_rep2', 'BP_time2_rep1', 'BP_time2_rep2', 'BP_time3_rep1', 'BP_time3_rep2', 'BP_time4_rep1', 'BP_time4_rep2',\n",
    "            'SAAP_H_time1_rep1', 'SAAP_H_time1_rep2', 'SAAP_H_time2_rep1', 'SAAP_H_time2_rep2', 'SAAP_H_time3_rep1', 'SAAP_H_time3_rep2', 'SAAP_H_time4_rep1', 'SAAP_H_time4_rep2',\n",
    "            'SAAP_L_time1_rep1', 'SAAP_L_time1_rep2', 'SAAP_L_time2_rep1', 'SAAP_L_time2_rep2', 'SAAP_L_time3_rep1', 'SAAP_L_time3_rep2', 'SAAP_L_time4_rep1', 'SAAP_L_time4_rep2',\n",
    "            'SAAP_time1_rep1', 'SAAP_time1_rep2', 'SAAP_time2_rep1', 'SAAP_time2_rep2', 'SAAP_time3_rep1', 'SAAP_time3_rep2', 'SAAP_time4_rep1', 'SAAP_time4_rep2', \n",
    "            'BP_HL_time1_rep1', 'BP_HL_time1_rep2', 'BP_HL_time2_rep1', 'BP_HL_time2_rep2', 'BP_HL_time3_rep1', 'BP_HL_time3_rep2', 'BP_HL_time4_rep1', 'BP_HL_time4_rep2',\n",
    "            'SAAP_HL_time1_rep1', 'SAAP_HL_time1_rep2', 'SAAP_HL_time2_rep1', 'SAAP_HL_time2_rep2', 'SAAP_HL_time3_rep1', 'SAAP_HL_time3_rep2', 'SAAP_HL_time4_rep1', 'SAAP_HL_time4_rep2', \n",
    "            'RAAS_time1_rep1', 'RAAS_time1_rep2', 'RAAS_time2_rep1', 'RAAS_time2_rep2', 'RAAS_time3_rep1', 'RAAS_time3_rep2', 'RAAS_time4_rep1', 'RAAS_time4_rep2',\n",
    "            'BP_H_mean_time1', 'BP_H_mean_time2', 'BP_H_mean_time3', 'BP_H_mean_time4',\n",
    "            'BP_L_mean_time1', 'BP_L_mean_time2', 'BP_L_mean_time3', 'BP_L_mean_time4',\n",
    "            'BP_mean_time1', 'BP_mean_time2', 'BP_mean_time3', 'BP_mean_time4', \n",
    "            'SAAP_H_mean_time1', 'SAAP_H_mean_time2', 'SAAP_H_mean_time3', 'SAAP_H_mean_time4',\n",
    "            'SAAP_L_mean_time1', 'SAAP_L_mean_time2', 'SAAP_L_mean_time3', 'SAAP_L_mean_time4',\n",
    "            'SAAP_mean_time1', 'SAAP_mean_time2', 'SAAP_mean_time3','SAAP_mean_time4', \n",
    "            'BP_HL_mean_time1', 'BP_HL_mean_time2', 'BP_HL_mean_time3', 'BP_HL_mean_time4', \n",
    "            'SAAP_HL_mean_time1', 'SAAP_HL_mean_time2', 'SAAP_HL_mean_time3', 'SAAP_HL_mean_time4',\n",
    "            'RAAS_mean_time1', 'RAAS_mean_time2', 'RAAS_mean_time3', 'RAAS_mean_time4', 'N_timepoints',\n",
    "            'BP_H_mean', 'BP_H_std','BP_H_CV', 'BP_L_mean', 'BP_L_std','BP_L_CV', 'BP_mean', 'BP_std','BP_CV',\n",
    "            'SAAP_H_mean', 'SAAP_H_std','SAAP_H_CV', 'SAAP_L_mean', 'SAAP_L_std','SAAP_L_CV','SAAP_mean','SAAP_std','SAAP_CV',\n",
    "            'BP_HL_mean','BP_HL_std','BP_HL_CV','SAAP_HL_mean','SAAP_HL_std','SAAP_HL_CV','RAAS_mean','RAAS_std','RAAS_CV']\n",
    "    rep_data_df = pd.DataFrame(index=list(range(len(saap_bp))), columns=cols)\n",
    "\n",
    "    for i, sba in enumerate(saap_bp):\n",
    "        if i%1000==0:\n",
    "            print(i)\n",
    "        sba_split = sba.split(';')\n",
    "        saap = sba_split[0]\n",
    "        bp = sba_split[1]\n",
    "        aas = sba_split[2]\n",
    "\n",
    "        rep_data_df.loc[i, 'Cell type'] = celltype\n",
    "        rep_data_df.loc[i, 'SAAP'] = saap\n",
    "        rep_data_df.loc[i, 'BP'] = bp\n",
    "        rep_data_df.loc[i, 'AAS'] = aas\n",
    "\n",
    "        sba_df = cell_data.loc[(cell_data['SAAP']==saap) & (cell_data['BP']==bp)]\n",
    "        cptac = sba_df['CPTAC SAAP'].values[0]\n",
    "        rep_data_df.loc[i,'CPTAC SAAP'] = cptac\n",
    "        #sba_df\n",
    "\n",
    "        for j,tp in enumerate(timepoints):\n",
    "            rep1_df = sba_df.loc[(sba_df['Time']==tp) & (sba_df['Replicate']==1)]\n",
    "            rep2_df = sba_df.loc[(sba_df['Time']==tp) & (sba_df['Replicate']==2)]\n",
    "\n",
    "            bp_h_1 = rep1_df['Heavy BP intensity'].values[0]\n",
    "            bp_h_2 = rep2_df['Heavy BP intensity'].values[0]\n",
    "            bp_l_1 = rep1_df['Light BP intensity'].values[0]\n",
    "            bp_l_2 = rep2_df['Light BP intensity'].values[0]\n",
    "            bp_1 = rep1_df['Light+Heavy BP intensity'].values[0]\n",
    "            bp_2 = rep2_df['Light+Heavy BP intensity'].values[0]\n",
    "            bp_hl_1 = rep1_df['H/L BP intensity'].values[0]\n",
    "            bp_hl_2 = rep2_df['H/L BP intensity'].values[0]\n",
    "            saap_h_1 = rep1_df['Heavy SAAP intensity'].values[0]\n",
    "            saap_h_2 = rep2_df['Heavy SAAP intensity'].values[0]\n",
    "            saap_l_1 = rep1_df['Light SAAP intensity'].values[0]\n",
    "            saap_l_2 = rep2_df['Light SAAP intensity'].values[0]\n",
    "            saap_1 = rep1_df['Light+Heavy SAAP intensity'].values[0]\n",
    "            saap_2 = rep2_df['Light+Heavy SAAP intensity'].values[0]\n",
    "            saap_hl_1 = rep1_df['H/L SAAP intensity'].values[0]\n",
    "            saap_hl_2 = rep2_df['H/L SAAP intensity'].values[0]\n",
    "            raas_1 = rep1_df['Light+Heavy RAAS'].values[0]\n",
    "            raas_2 = rep2_df['Light+Heavy RAAS'].values[0]\n",
    "\n",
    "            rep_data_df.loc[i, 'BP_H_time'+str(j+1)+'_rep1'] = bp_h_1\n",
    "            rep_data_df.loc[i, 'BP_H_time'+str(j+1)+'_rep2'] = bp_h_2\n",
    "            rep_data_df.loc[i, 'BP_L_time'+str(j+1)+'_rep1'] = bp_l_1\n",
    "            rep_data_df.loc[i, 'BP_L_time'+str(j+1)+'_rep2'] = bp_l_2\n",
    "            rep_data_df.loc[i, 'BP_time'+str(j+1)+'_rep1'] = bp_1\n",
    "            rep_data_df.loc[i, 'BP_time'+str(j+1)+'_rep2'] = bp_2\n",
    "            rep_data_df.loc[i, 'SAAP_H_time'+str(j+1)+'_rep1'] = saap_h_1\n",
    "            rep_data_df.loc[i, 'SAAP_H_time'+str(j+1)+'_rep2'] = saap_h_2\n",
    "            rep_data_df.loc[i, 'SAAP_L_time'+str(j+1)+'_rep1'] = saap_l_1\n",
    "            rep_data_df.loc[i, 'SAAP_L_time'+str(j+1)+'_rep2'] = saap_l_2\n",
    "            rep_data_df.loc[i, 'SAAP_time'+str(j+1)+'_rep1'] = saap_1\n",
    "            rep_data_df.loc[i, 'SAAP_time'+str(j+1)+'_rep2'] = saap_2\n",
    "            rep_data_df.loc[i, 'BP_HL_time'+str(j+1)+'_rep1'] = bp_hl_1\n",
    "            rep_data_df.loc[i, 'BP_HL_time'+str(j+1)+'_rep2'] = bp_hl_2\n",
    "            rep_data_df.loc[i, 'SAAP_HL_time'+str(j+1)+'_rep1'] = saap_hl_1\n",
    "            rep_data_df.loc[i, 'SAAP_HL_time'+str(j+1)+'_rep2'] = saap_hl_2\n",
    "            rep_data_df.loc[i, 'RAAS_time'+str(j+1)+'_rep1'] = raas_1\n",
    "            rep_data_df.loc[i, 'RAAS_time'+str(j+1)+'_rep2'] = raas_2\n",
    "\n",
    "            rep_data_df.loc[i, 'BP_H_mean_time'+str(j+1)] = np.nanmean([bp_h_1,bp_h_2])\n",
    "            rep_data_df.loc[i, 'BP_L_mean_time'+str(j+1)] = np.nanmean([bp_l_1,bp_l_2])\n",
    "            rep_data_df.loc[i, 'BP_mean_time'+str(j+1)] = np.nanmean([bp_1,bp_2])\n",
    "            rep_data_df.loc[i, 'SAAP_H_mean_time'+str(j+1)] = np.nanmean([saap_h_1,saap_h_2])\n",
    "            rep_data_df.loc[i, 'SAAP_L_mean_time'+str(j+1)] = np.nanmean([saap_l_1,saap_l_2])\n",
    "            rep_data_df.loc[i, 'SAAP_mean_time'+str(j+1)] = np.nanmean([saap_1,saap_2])\n",
    "            rep_data_df.loc[i, 'BP_HL_mean_time'+str(j+1)] = np.nanmean([bp_hl_1,bp_hl_2])\n",
    "            rep_data_df.loc[i, 'SAAP_HL_mean_time'+str(j+1)] = np.nanmean([saap_hl_1,saap_hl_2])\n",
    "            rep_data_df.loc[i, 'RAAS_mean_time'+str(j+1)] = np.nanmean([raas_1,raas_2])\n",
    "\n",
    "        rep_data_df.loc[i, 'N_timepoints'] = len([x for x in rep_data_df.loc[i,[c for c in rep_data_df.columns if 'RAAS_mean_time' in c]] if ~np.isnan(x)])\n",
    "\n",
    "        bp_h_vals = rep_data_df.loc[i,[x for x in rep_data_df.columns if 'BP_H_mean_time' in x]].to_list()\n",
    "        rep_data_df.loc[i, 'BP_H_mean'] = np.nanmean(bp_h_vals)\n",
    "        rep_data_df.loc[i, 'BP_H_std'] = np.nanstd(bp_h_vals)\n",
    "        rep_data_df.loc[i, 'BP_H_CV'] = np.nanstd(bp_h_vals)/np.nanmean(bp_h_vals)\n",
    "        bp_l_vals = rep_data_df.loc[i,[x for x in rep_data_df.columns if 'BP_L_mean_time' in x]].to_list()\n",
    "        rep_data_df.loc[i, 'BP_L_mean'] = np.nanmean(bp_l_vals)\n",
    "        rep_data_df.loc[i, 'BP_L_std'] = np.nanstd(bp_l_vals)\n",
    "        rep_data_df.loc[i, 'BP_L_CV'] = np.nanstd(bp_l_vals)/np.nanmean(bp_l_vals)\n",
    "        bp_vals = rep_data_df.loc[i,[x for x in rep_data_df.columns if 'BP_mean_time' in x]].to_list()\n",
    "        rep_data_df.loc[i, 'BP_mean'] = np.nanmean(bp_vals)\n",
    "        rep_data_df.loc[i, 'BP_std'] = np.nanstd(bp_vals)\n",
    "        rep_data_df.loc[i, 'BP_CV'] = np.nanstd(bp_vals)/np.nanmean(bp_vals)\n",
    "        saap_h_vals = rep_data_df.loc[i,[x for x in rep_data_df.columns if 'SAAP_H_mean_time' in x]].to_list()\n",
    "        rep_data_df.loc[i, 'SAAP_H_mean'] = np.nanmean(saap_h_vals)\n",
    "        rep_data_df.loc[i, 'SAAP_H_std'] = np.nanstd(saap_h_vals)\n",
    "        rep_data_df.loc[i, 'SAAP_H_CV'] = np.nanstd(saap_h_vals)/np.nanmean(saap_h_vals)\n",
    "        saap_l_vals = rep_data_df.loc[i,[x for x in rep_data_df.columns if 'SAAP_L_mean_time' in x]].to_list()\n",
    "        rep_data_df.loc[i, 'SAAP_L_mean'] = np.nanmean(saap_l_vals)\n",
    "        rep_data_df.loc[i, 'SAAP_L_std'] = np.nanstd(saap_l_vals)\n",
    "        rep_data_df.loc[i, 'SAAP_L_CV'] = np.nanstd(saap_l_vals)/np.nanmean(saap_l_vals)\n",
    "        saap_vals = rep_data_df.loc[i,[x for x in rep_data_df.columns if 'SAAP_mean_time' in x]].to_list()\n",
    "        rep_data_df.loc[i, 'SAAP_mean'] = np.nanmean(saap_vals)\n",
    "        rep_data_df.loc[i, 'SAAP_std'] = np.nanstd(saap_vals)\n",
    "        rep_data_df.loc[i, 'SAAP_CV'] = np.nanstd(saap_vals)/np.nanmean(saap_vals)\n",
    "        bp_hl_vals = rep_data_df.loc[i,[x for x in rep_data_df.columns if 'BP_HL_mean_time' in x]].to_list()\n",
    "        rep_data_df.loc[i, 'BP_HL_mean'] = np.nanmean(bp_hl_vals)\n",
    "        rep_data_df.loc[i, 'BP_HL_std'] = np.nanstd(bp_hl_vals)\n",
    "        rep_data_df.loc[i, 'BP_HL_CV'] = np.nanstd(bp_hl_vals)/np.nanmean(bp_hl_vals)\n",
    "        saap_hl_vals = rep_data_df.loc[i,[x for x in rep_data_df.columns if 'SAAP_HL_mean_time' in x]].to_list()\n",
    "        rep_data_df.loc[i, 'SAAP_HL_mean'] = np.nanmean(saap_hl_vals)\n",
    "        rep_data_df.loc[i, 'SAAP_HL_std'] = np.nanstd(saap_hl_vals)\n",
    "        rep_data_df.loc[i, 'SAAP_HL_CV'] = np.nanstd(saap_hl_vals)/np.nanmean(saap_hl_vals)\n",
    "        raas_vals = [10**x for x in rep_data_df.loc[i,[x for x in rep_data_df.columns if 'RAAS_mean_time' in x]].to_list()]\n",
    "        rep_data_df.loc[i, 'RAAS_mean'] = np.log10(np.nanmean(raas_vals))\n",
    "        rep_data_df.loc[i, 'RAAS_std'] = np.nanstd(raas_vals)\n",
    "        rep_data_df.loc[i, 'RAAS_CV'] = np.nanstd(raas_vals)/np.nanmean(raas_vals)\n",
    "\n",
    "    rep_data_df_list.append(rep_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns with log of the abundance values for all heavy and light peptides and save file\n",
    "\n",
    "new_rep_data_df_list = []\n",
    "for i,rep_data_df in enumerate(rep_data_df_list):\n",
    "    celltype = rep_data_df['Cell type'].values[0]\n",
    "    print(celltype)\n",
    "    cell_meta = metadata.loc[metadata['cell type']==celltype]\n",
    "    timepoints = list(set(cell_meta['time point'].to_list()))\n",
    "    timepoints = [str(y)+'h' for y in sorted([int(x.split('h')[0]) for x in timepoints])]\n",
    "    for j,tp in enumerate(timepoints): \n",
    "        print(tp)\n",
    "        rep_data_df['BP_H_time'+str(j+1)+'_rep1_log'] = [np.log10(x) for x in rep_data_df['BP_H_time'+str(j+1)+'_rep1'].to_list()]\n",
    "        rep_data_df['BP_H_time'+str(j+1)+'_rep2_log'] = [np.log10(x) for x in rep_data_df['BP_H_time'+str(j+1)+'_rep2'].to_list()]\n",
    "        rep_data_df['BP_L_time'+str(j+1)+'_rep1_log'] = [np.log10(x) for x in rep_data_df['BP_L_time'+str(j+1)+'_rep1'].to_list()]\n",
    "        rep_data_df['BP_L_time'+str(j+1)+'_rep2_log'] = [np.log10(x) for x in rep_data_df['BP_L_time'+str(j+1)+'_rep2'].to_list()]\n",
    "        rep_data_df['BP_time'+str(j+1)+'_rep1_log'] = [np.log10(x) for x in rep_data_df['BP_time'+str(j+1)+'_rep1'].to_list()]\n",
    "        rep_data_df['BP_time'+str(j+1)+'_rep2_log'] = [np.log10(x) for x in rep_data_df['BP_time'+str(j+1)+'_rep2'].to_list()]\n",
    "        rep_data_df['SAAP_H_time'+str(j+1)+'_rep1_log'] = [np.log10(x) for x in rep_data_df['SAAP_H_time'+str(j+1)+'_rep1'].to_list()]\n",
    "        rep_data_df['SAAP_H_time'+str(j+1)+'_rep2_log'] = [np.log10(x) for x in rep_data_df['SAAP_H_time'+str(j+1)+'_rep2'].to_list()]\n",
    "        rep_data_df['SAAP_L_time'+str(j+1)+'_rep1_log'] = [np.log10(x) for x in rep_data_df['SAAP_L_time'+str(j+1)+'_rep1'].to_list()]\n",
    "        rep_data_df['SAAP_L_time'+str(j+1)+'_rep2_log'] = [np.log10(x) for x in rep_data_df['SAAP_L_time'+str(j+1)+'_rep2'].to_list()]\n",
    "        rep_data_df['SAAP_time'+str(j+1)+'_rep1_log'] = [np.log10(x) for x in rep_data_df['SAAP_time'+str(j+1)+'_rep1'].to_list()]\n",
    "        rep_data_df['SAAP_time'+str(j+1)+'_rep2_log'] = [np.log10(x) for x in rep_data_df['SAAP_time'+str(j+1)+'_rep2'].to_list()]\n",
    "        rep_data_df['BP_H_time'+str(j+1)+'_mean_log'] = [np.log10(np.nanmean([row['BP_H_time'+str(j+1)+'_rep1'], row['BP_H_time'+str(j+1)+'_rep2']])) for i,row in rep_data_df.iterrows()]\n",
    "        rep_data_df['BP_L_time'+str(j+1)+'_mean_log'] = [np.log10(np.nanmean([row['BP_L_time'+str(j+1)+'_rep1'], row['BP_L_time'+str(j+1)+'_rep2']])) for i,row in rep_data_df.iterrows()]\n",
    "        rep_data_df['BP_time'+str(j+1)+'_mean_log'] = [np.log10(np.nanmean([row['BP_time'+str(j+1)+'_rep1'], row['BP_time'+str(j+1)+'_rep2']])) for i,row in rep_data_df.iterrows()]\n",
    "        rep_data_df['SAAP_H_time'+str(j+1)+'_mean_log'] = [np.log10(np.nanmean([row['SAAP_H_time'+str(j+1)+'_rep1'], row['SAAP_H_time'+str(j+1)+'_rep2']])) for i,row in rep_data_df.iterrows()]\n",
    "        rep_data_df['SAAP_L_time'+str(j+1)+'_mean_log'] = [np.log10(np.nanmean([row['SAAP_L_time'+str(j+1)+'_rep1'], row['SAAP_L_time'+str(j+1)+'_rep2']])) for i,row in rep_data_df.iterrows()]\n",
    "        rep_data_df['SAAP_time'+str(j+1)+'_mean_log'] = [np.log10(np.nanmean([row['SAAP_time'+str(j+1)+'_rep1'], row['SAAP_time'+str(j+1)+'_rep2']])) for i,row in rep_data_df.iterrows()]\n",
    "\n",
    "        rep_data_df['BP_HL_time'+str(j+1)+'_rep1_log'] = [np.log10(x) for x in rep_data_df['BP_HL_time'+str(j+1)+'_rep1'].to_list()]\n",
    "        rep_data_df['BP_HL_time'+str(j+1)+'_rep2_log'] = [np.log10(x) for x in rep_data_df['BP_HL_time'+str(j+1)+'_rep2'].to_list()]\n",
    "        rep_data_df['SAAP_HL_time'+str(j+1)+'_rep1_log'] = [np.log10(x) for x in rep_data_df['SAAP_HL_time'+str(j+1)+'_rep1'].to_list()]\n",
    "        rep_data_df['SAAP_HL_time'+str(j+1)+'_rep2_log'] = [np.log10(x) for x in rep_data_df['SAAP_HL_time'+str(j+1)+'_rep2'].to_list()]\n",
    "        rep_data_df['BP_HL_time'+str(j+1)+'_rep1_log+1'] = [np.log10(x+1) for x in rep_data_df['BP_HL_time'+str(j+1)+'_rep1'].to_list()]\n",
    "        rep_data_df['BP_HL_time'+str(j+1)+'_rep2_log+1'] = [np.log10(x+1) for x in rep_data_df['BP_HL_time'+str(j+1)+'_rep2'].to_list()]\n",
    "        rep_data_df['SAAP_HL_time'+str(j+1)+'_rep1_log+1'] = [np.log10(x+1) for x in rep_data_df['SAAP_HL_time'+str(j+1)+'_rep1'].to_list()]\n",
    "        rep_data_df['SAAP_HL_time'+str(j+1)+'_rep2_log+1'] = [np.log10(x+1) for x in rep_data_df['SAAP_HL_time'+str(j+1)+'_rep2'].to_list()]\n",
    "\n",
    "        rep_data_df['BP_HL_time'+str(j+1)+'_mean_log'] = [np.log10(np.nanmean([row['BP_HL_time'+str(j+1)+'_rep1'], row['BP_HL_time'+str(j+1)+'_rep2']])) for i,row in rep_data_df.iterrows()]\n",
    "        rep_data_df['SAAP_HL_time'+str(j+1)+'_mean_log'] = [np.log10(np.nanmean([row['SAAP_HL_time'+str(j+1)+'_rep1'], row['SAAP_HL_time'+str(j+1)+'_rep2']])) for i,row in rep_data_df.iterrows()]\n",
    "        rep_data_df['BP_HL_time'+str(j+1)+'_mean_log+1'] = [np.log10(np.nanmean([row['BP_HL_time'+str(j+1)+'_rep1'], row['BP_HL_time'+str(j+1)+'_rep2']])+1) for i,row in rep_data_df.iterrows()]\n",
    "        rep_data_df['SAAP_HL_time'+str(j+1)+'_mean_log+1'] = [np.log10(np.nanmean([row['SAAP_HL_time'+str(j+1)+'_rep1'], row['SAAP_HL_time'+str(j+1)+'_rep2']])+1) for i,row in rep_data_df.iterrows()]\n",
    "    new_rep_data_df_list.append(rep_data_df)\n",
    "    \n",
    "rep_data_df_all = pd.concat(rep_data_df_list)\n",
    "rep_data_df.replace(np.inf, np.nan, inplace=True)\n",
    "rep_data_df.replace(-np.inf, np.nan, inplace=True)\n",
    "rep_data_df_all.to_csv(aa_subs_dir+'Median_normalized_Replicate_data_all_celltypes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute degradation rates \n",
    "\n",
    "def get_model_params(x,y):\n",
    "    \"\"\" \n",
    "    Generate linear regression model to fit peptide abundance data to time points\n",
    "    input: x - timepoints; y - abundance data (or H/L to compute degradation rates)\n",
    "    output: slope of regression (this is the degradation rate when fitting H/L), R^2 of the fit, and predicted y values\n",
    "    \"\"\"\n",
    "    x = np.array(x).reshape(-1,1)\n",
    "    y = np.array(y)\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    model.fit(x, y)\n",
    "    y_pred = model.predict(x)\n",
    "    slope = model.coef_[0]\n",
    "    score = model.score(x,y)\n",
    "    return(slope, score, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute degradation rates of heavy and light and H/L ratio \n",
    "\n",
    "bp_deg_rates = []\n",
    "saap_deg_rates = []\n",
    "bp_deg_r2_list = []\n",
    "saap_deg_r2_list = []\n",
    "bp_deg_pred_list = []\n",
    "saap_deg_pred_list = []\n",
    "n_bp_times_in_deg = []\n",
    "n_saap_times_in_deg = []\n",
    "\n",
    "bp_light_slope_list = []\n",
    "saap_light_slope_list = []\n",
    "bp_light_r2_list = []\n",
    "saap_light_r2_list = []\n",
    "bp_light_pred_list = []\n",
    "saap_light_pred_list = []\n",
    "\n",
    "bp_heavy_slope_list = []\n",
    "saap_heavy_slope_list = []\n",
    "bp_heavy_r2_list = []\n",
    "saap_heavy_r2_list = []\n",
    "bp_heavy_pred_list = []\n",
    "saap_heavy_pred_list = []\n",
    "\n",
    "i=0\n",
    "row = rep_data_df_all.loc[i]\n",
    "\n",
    "for i,row in rep_data_df_all.iterrows():\n",
    "    if i%1000==0:\n",
    "        print(i)\n",
    "    celltype = row['Cell type']\n",
    "    x = ordered_times[celltype]\n",
    "\n",
    "    bp_hl = [row['BP_HL_time'+str(j)+'_mean_log+1'] for j in range(1,5)]\n",
    "    x_bp_hl = [x[j] for j in range(len(x)) if ~np.isnan(bp_hl[j])]\n",
    "    bp_hl = [x for x in bp_hl if ~np.isnan(x)]\n",
    "    n_bp = len(bp_hl)\n",
    "\n",
    "    saap_hl = [row['SAAP_HL_time'+str(j)+'_mean_log+1'] for j in range(1,5)]\n",
    "    x_saap_hl = [x[j] for j in range(len(x)) if ~np.isnan(saap_hl[j])]\n",
    "    saap_hl = [x for x in saap_hl if ~np.isnan(x)]\n",
    "    n_saap = len(saap_hl)\n",
    "\n",
    "    bp_deg_slope = saap_deg_slope = np.nan\n",
    "    bp_deg_r2 = saap_deg_r2 = np.nan\n",
    "    bp_deg_pred = saap_deg_pred = np.nan\n",
    "    if len(bp_hl)>0:\n",
    "        bp_deg_slope, bp_deg_r2, bp_deg_pred = get_model_params(x_bp_hl, bp_hl)\n",
    "    if len(saap_hl)>0:\n",
    "        saap_deg_slope, saap_deg_r2, saap_deg_pred = get_model_params(x_saap_hl, saap_hl)\n",
    "\n",
    "    bp_deg_rates.append(bp_deg_slope)\n",
    "    saap_deg_rates.append(saap_deg_slope)\n",
    "    bp_deg_r2_list.append(bp_deg_r2)\n",
    "    saap_deg_r2_list.append(saap_deg_r2)\n",
    "    bp_deg_pred_list.append(bp_deg_pred)\n",
    "    saap_deg_pred_list.append(saap_deg_pred)\n",
    "    n_bp_times_in_deg.append(n_bp)\n",
    "    n_saap_times_in_deg.append(n_saap)\n",
    "\n",
    "\n",
    "    bp_light = [row['BP_L_time'+str(j)+'_mean_log'] for j in range(1,5)]\n",
    "    x_bp_light = [x[j] for j in range(len(x)) if ~np.isnan(bp_light[j])]\n",
    "    bp_light = [x for x in bp_light if ~np.isnan(x)]\n",
    "\n",
    "    saap_light = [row['SAAP_L_time'+str(j)+'_mean_log'] for j in range(1,5)]\n",
    "    x_saap_light = [x[j] for j in range(len(x)) if ~np.isnan(saap_light[j])]\n",
    "    saap_light = [x for x in saap_light if ~np.isnan(x)]\n",
    "\n",
    "    bp_light_slope = saap_light_slope = np.nan\n",
    "    bp_light_r2 = saap_light_r2 = np.nan\n",
    "    bp_light_pred = saap_light_pred = np.nan\n",
    "    if len(bp_light)>0:\n",
    "        bp_light_slope, bp_light_r2, bp_light_pred = get_model_params(x_bp_light, bp_light)\n",
    "    if len(saap_light)>0:\n",
    "        saap_light_slope, saap_light_r2, saap_light_pred = get_model_params(x_saap_light, saap_light)\n",
    "\n",
    "    bp_light_slope_list.append(bp_light_slope)\n",
    "    saap_light_slope_list.append(saap_light_slope)\n",
    "    bp_light_r2_list.append(bp_light_r2)\n",
    "    saap_light_r2_list.append(saap_light_r2)\n",
    "    bp_light_pred_list.append(bp_light_pred)\n",
    "    saap_light_pred_list.append(saap_light_pred)\n",
    "\n",
    "\n",
    "    bp_heavy = [row['BP_H_time'+str(j)+'_mean_log'] for j in range(1,5)]\n",
    "    x_bp_heavy = [x[j] for j in range(len(x)) if ~np.isnan(bp_heavy[j])]\n",
    "    bp_heavy = [x for x in bp_heavy if ~np.isnan(x)]\n",
    "\n",
    "    saap_heavy = [row['SAAP_H_time'+str(j)+'_mean_log'] for j in range(1,5)]\n",
    "    x_saap_heavy = [x[j] for j in range(len(x)) if ~np.isnan(saap_heavy[j])]\n",
    "    saap_heavy = [x for x in saap_heavy if ~np.isnan(x)]\n",
    "\n",
    "    bp_heavy_slope = saap_heavy_slope = np.nan\n",
    "    bp_heavy_r2 = saap_heavy_r2 = np.nan\n",
    "    bp_heavy_pred = saap_heavy_pred = np.nan\n",
    "    if len(bp_heavy)>0:\n",
    "        bp_heavy_slope, bp_heavy_r2, bp_heavy_pred = get_model_params(x_bp_heavy, bp_heavy)\n",
    "    if len(saap_heavy)>0:\n",
    "        saap_heavy_slope, saap_heavy_r2, saap_heavy_pred = get_model_params(x_saap_heavy, saap_heavy)\n",
    "\n",
    "    bp_heavy_slope_list.append(bp_heavy_slope)\n",
    "    saap_heavy_slope_list.append(saap_heavy_slope)    \n",
    "    bp_heavy_r2_list.append(bp_heavy_r2)\n",
    "    saap_heavy_r2_list.append(saap_heavy_r2)\n",
    "    bp_heavy_pred_list.append(bp_heavy_pred)\n",
    "    saap_heavy_pred_list.append(saap_heavy_pred)\n",
    "    \n",
    "rep_data_df_all['BP_deg_rate'] = bp_deg_rates\n",
    "rep_data_df_all['SAAP_deg_rate'] = saap_deg_rates\n",
    "rep_data_df_all['BP_deg_rate_log'] = [np.log10(x) for x in rep_data_df_all['BP_deg_rate'].to_list()]\n",
    "rep_data_df_all['SAAP_deg_rate_log'] = [np.log10(x) for x in rep_data_df_all['SAAP_deg_rate'].to_list()]\n",
    "rep_data_df_all['BP_N_timepoints_in_deg'] = n_bp_times_in_deg\n",
    "rep_data_df_all['SAAP_N_timepoints_in_deg'] = n_saap_times_in_deg\n",
    "\n",
    "rep_data_df_all['BP_deg_r2'] = bp_deg_r2_list\n",
    "rep_data_df_all['SAAP_deg_r2'] = saap_deg_r2_list\n",
    "rep_data_df_all['BP_deg_predicted'] = bp_deg_pred_list\n",
    "rep_data_df_all['SAAP_deg_predicted'] = saap_deg_pred_list\n",
    "\n",
    "rep_data_df_all['BP_light_slope'] = bp_light_slope_list\n",
    "rep_data_df_all['SAAP_light_slope'] = saap_light_slope_list\n",
    "rep_data_df_all['BP_light_r2'] = bp_light_r2_list\n",
    "rep_data_df_all['SAAP_light_r2'] = saap_light_r2_list\n",
    "rep_data_df_all['BP_light_predicted'] = bp_light_pred_list\n",
    "rep_data_df_all['SAAP_light_predicted'] = saap_light_pred_list\n",
    "\n",
    "rep_data_df_all['BP_heavy_slope'] = bp_heavy_slope_list\n",
    "rep_data_df_all['SAAP_heavy_slope'] = saap_heavy_slope_list\n",
    "rep_data_df_all['BP_heavy_r2'] = bp_heavy_r2_list\n",
    "rep_data_df_all['SAAP_heavy_r2'] = saap_heavy_r2_list\n",
    "rep_data_df_all['BP_heavy_predicted'] = bp_heavy_pred_list\n",
    "rep_data_df_all['SAAP_heavy_predicted'] = saap_heavy_pred_list\n",
    "\n",
    "# compute ratio of SAAP degradation rate to BP degradation rate \n",
    "rep_data_df_all['SAAP_BP_deg_rate'] = [row['SAAP_deg_rate']/row['BP_deg_rate'] for i,row in rep_data_df_all.iterrows()]\n",
    "rep_data_df_all['SAAP_BP_deg_rate_log'] = [np.log2(x) for x in rep_data_df_all['SAAP_BP_deg_rate'].to_list()]\n",
    "\n",
    "rep_data_df_all.to_csv(aa_subs_dir+'Median_normalized_Replicate_data_all_celltypes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ratio of SAAP degradation to BP degradation vs RAAS for given cell type. Figure 2l, extended data figure 3 m,n.\n",
    "\n",
    "celltype = 'Hepatocytes'\n",
    "rep_data_df = rep_data_df_all.loc[rep_data_df_all['Cell type']==celltype]\n",
    "#rep_data_df = rep_data_df.loc[(rep_data_df['BP_N_timepoints_in_deg']>2) & (rep_data_df['SAAP_N_timepoints_in_deg']>2)]\n",
    "rep_data_df.dropna(inplace=True, subset=['SAAP_BP_deg_rate_log', 'RAAS_mean'])\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "fig,ax = plt.subplots(figsize=(3,3))\n",
    "\n",
    "subset1_df = rep_data_df.loc[rep_data_df['CPTAC SAAP']==False]\n",
    "subset2_df = rep_data_df.loc[rep_data_df['CPTAC SAAP']==True]\n",
    "\n",
    "sns.scatterplot(data=rep_data_df, x='RAAS_mean', y='SAAP_BP_deg_rate_log', s=30, alpha=0, hue='CPTAC SAAP', palette=['#AAAAAA', 'k'])#, palette='RdBu_r')\n",
    "sns.scatterplot(data=subset1_df, x='RAAS_mean', y='SAAP_BP_deg_rate_log', s=30, alpha=0.8, color='#AAAAAA')#, palette='RdBu_r')\n",
    "sns.scatterplot(data=subset2_df, x='RAAS_mean', y='SAAP_BP_deg_rate_log', s=30, alpha=0.8, color='k')#, palette='RdBu_r')\n",
    "\n",
    "#scatter = plt.scatter(data=hep_data, x='Light+Heavy RAAS', y='RTO', s=30, alpha=0.5, edgecolor='w', linewidth=0.7)\n",
    "vect2 = [float(x) for x in rep_data_df['SAAP_BP_deg_rate_log'].values]\n",
    "vect1 = [float(x) for x in rep_data_df['RAAS_mean'].values]\n",
    "y_vals = get_pred_y(vect1,vect2)\n",
    "plt.plot(vect1, y_vals, '--r')\n",
    "\n",
    "vect1_2 = subset1_df['SAAP_BP_deg_rate_log'].values\n",
    "vect1_1 = subset1_df['RAAS_mean'].values\n",
    "y1_vals = get_pred_y(vect1_1, vect1_2)\n",
    "#plt.plot(vect1_1, y1_vals, '--', color='#555555')\n",
    "\n",
    "vect2_2 = subset2_df['SAAP_BP_deg_rate_log'].values\n",
    "vect2_1 = subset2_df['RAAS_mean'].values\n",
    "y2_vals = get_pred_y(vect2_1,vect2_2)\n",
    "#plt.plot(vect2_1, y2_vals, '--', color='k')\n",
    "\n",
    "r,p = sp.stats.pearsonr(vect1, vect2)\n",
    "r1,p1 = sp.stats.pearsonr(vect1_1, vect1_2)\n",
    "r2,p2 = sp.stats.pearsonr(vect2_1, vect2_2)\n",
    "print(r,p)\n",
    "print(r1,p1)\n",
    "print(r2,p2)\n",
    "\n",
    "ax.annotate('r$=-$'+str(np.round(np.abs(r),2)), xy=(1.05,0.7), xycoords='axes fraction', fontsize=12, color='r')\n",
    "ax.annotate('p$<$10$^{-10}$', xy=(1.05,0.6), xycoords='axes fraction', fontsize=12,color='r')\n",
    "#ax.annotate('p$=$0.95', xy=(1.05,0.6), xycoords='axes fraction', fontsize=12, color='r')\n",
    "\n",
    "ax.annotate('r$=-$'+str(np.round(np.abs(r2),2)), xy=(1.05,0.45), xycoords='axes fraction', fontsize=12, color='k')\n",
    "ax.annotate('p$<$10$^{-4}$', xy=(1.05,0.35), xycoords='axes fraction', fontsize=12, color='k')\n",
    "#ax.annotate('p$=$0.06', xy=(1.05,0.35), xycoords='axes fraction', fontsize=12, color='k')\n",
    "\n",
    "ax.annotate('r$=-$'+str(np.round(np.abs(r1),2)), xy=(1.05,0.2), xycoords='axes fraction', fontsize=12, color='#555555')\n",
    "ax.annotate('p$<$10$^{-4}$', xy=(1.05,0.1), xycoords='axes fraction', fontsize=12, color='#555555')\n",
    "#ax.annotate('p$=$0.73', xy=(1.05,0.1), xycoords='axes fraction', fontsize=12, color='#555555')\n",
    "\n",
    "handles = [Line2D([0], [0], marker='o', color='w', markerfacecolor='k', markersize=8), Line2D([0], [0], marker='o', color='w', markerfacecolor='#555555', markersize=8, alpha=0.8)]\n",
    "plt.legend(fontsize=12,handles=handles, labels=['CPTAC+Healthy', 'Savitski, $\\it{et\\ al.}$'], handletextpad=0.1,\n",
    "          bbox_to_anchor=(1.75,1.05), frameon=False, loc='upper right')\n",
    "\n",
    "ax.tick_params('both', labelsize=14)\n",
    "plt.ylabel('log$_{2}$('+r'$\\alpha_{SAAP}$'+'$/$'+r'$\\alpha_{BP}$'+')', fontsize=15)\n",
    "plt.xlabel('log$_{10}$(RAAS)', fontsize=15)\n",
    "\n",
    "plt.title(celltype, fontsize=14)\n",
    "#plt.title('B Cells', fontsize=14)\n",
    "\n",
    "plt.savefig(outdir+'figures/'+celltype+'_log2_SAAP_BP_deg_vs_RAAS.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot example of H/L ratios relative to time point to illustrate computation. Figure 2k\n",
    "\n",
    "\n",
    "# filter rep_data_df_all for peptides with no missing data, high R2, high RAAS and low SAAP degradation to find example\n",
    "rep_data_df = rep_data_df_all.loc[rep_data_df_all['Cell type']=='Hepatocytes']\n",
    "rep_data_df = rep_data_df.loc[(rep_data_df['SAAP_N_timepoints_in_deg']==4) & (rep_data_df['BP_N_timepoints_in_deg']==4)]\n",
    "rep_data_df = rep_data_df.loc[(rep_data_df['SAAP_deg_r2']>=0.5) & (rep_data_df['BP_deg_r2']>=0.5)]\n",
    "example_df = rep_data_df.loc[(rep_data_df['SAAP_BP_deg_rate_log']<0) & (rep_data_df['RAAS_mean']>1)]\n",
    "cell_quant_data = quant_df.loc[quant_df['Cell type']=='Hepatocytes']\n",
    "\n",
    "example_row = example_df.loc[[i for i,row in example_df.iterrows() if row['SAAP']=='LFSNGQDVSNK']]\n",
    "\n",
    "# extract data for plot. convert log10 to ln. \n",
    "saap = example_row['SAAP'].values[0]\n",
    "bp = example_row['BP'].values[0]\n",
    "aas = example_row['AAS'].values[0]\n",
    "raas = example_row['RAAS_mean'].values[0]\n",
    "saap_deg = np.log(10**(example_row['SAAP_deg_rate'].values[0]))\n",
    "bp_deg = np.log(10**(example_row['BP_deg_rate'].values[0]))\n",
    "saap_bp_deg = saap_deg/bp_deg\n",
    "saap_hl_pred = [np.log(10**x) for x in example_row['SAAP_deg_predicted'].values[0]]\n",
    "bp_hl_pred = [np.log(10**x) for x in example_row['BP_deg_predicted'].values[0]]\n",
    "row_quant = cell_quant_data.loc[(cell_quant_data['SAAP']==saap) & (cell_quant_data['BP']==bp)]\n",
    "tps = sorted(list(set(row_quant['Time'])))\n",
    "saap_light_tps = []\n",
    "saap_heavy_tps = []\n",
    "bp_light_tps = []\n",
    "bp_heavy_tps = []\n",
    "saap_hl_tps = []\n",
    "bp_hl_tps = []\n",
    "\n",
    "for tp in tps:\n",
    "    tp_quant = row_quant.loc[row_quant['Time']==tp]\n",
    "    rep1_row = tp_quant.loc[tp_quant['Replicate']==1]\n",
    "    rep2_row = tp_quant.loc[tp_quant['Replicate']==2]\n",
    "    time = rep1_row['Time'].values[0]\n",
    "    hl_saap = np.nanmean([np.log(rep1_row['H/L SAAP intensity'].values[0]+1), np.log(rep2_row['H/L SAAP intensity'].values[0]+1)])\n",
    "    hl_bp = np.nanmean([np.log(rep1_row['H/L BP intensity'].values[0]+1), np.log(rep2_row['H/L BP intensity'].values[0]+1)])\n",
    "    saap_hl_tps.append(hl_saap)\n",
    "    bp_hl_tps.append(hl_bp)\n",
    "\n",
    "    \n",
    "# plot figure 2k\n",
    "fig,ax = plt.subplots(figsize=(3,3))\n",
    "tps = [0]+tps\n",
    "saap_hl_tps = [0] + saap_hl_tps\n",
    "bp_hl_tps = [0] + bp_hl_tps\n",
    "bp_hl_pred = [0] + bp_hl_pred\n",
    "\n",
    "sns.regplot(x=tps, y=saap_hl_tps, label='SAAP_H/L', ci=None, scatter_kws={'s':50})\n",
    "sns.regplot(x=tps, y=bp_hl_tps, label='BP_H/L', ci=None, scatter_kws={'s':50}, line_kws={'linewidth':0})\n",
    "sns.lineplot(x=tps, y=bp_hl_pred, color=colors[1], linewidth=2)\n",
    "aas_idx = [i for i,x in enumerate(saap) if bp[i]!=x][0]\n",
    "plt.title(saap[:aas_idx]+r'$\\bf(N$'+r'$\\rightarrow$'+r'$\\bf M)$'+saap[aas_idx+1:], fontsize=14)\n",
    "ax.tick_params('both', labelsize=13)\n",
    "plt.ylabel('ln(1+Heavy $/$ Light)', fontsize=14)\n",
    "plt.xlabel('Time point (hours)', fontsize=14)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles=handles, labels =['SAAP', 'BP'], bbox_to_anchor=(0.96,0.85), frameon=False, loc='upper left', fontsize=12)\n",
    "plt.annotate('RAAS$=$'+str(np.round(10**raas,2)), xy=(1.05,0.48), xycoords='axes fraction', fontsize=12)\n",
    "plt.annotate(r'$\\dfrac{\\alpha_{BP}}{\\alpha_{SAAP}}$'+'$=$'+str(np.round(np.abs(1/saap_bp_deg),2)), xy=(1.05,0.3), xycoords='axes fraction', fontsize=12)\n",
    "plt.annotate(r'$\\alpha_{SAAP}=$'+'\\n'+str(np.round(saap_deg_day,2))+' days$^{-1}$',xy=(0.35,0.15), xycoords='axes fraction', color=colors[0], fontsize=12)\n",
    "plt.annotate(r'$\\alpha_{BP}=$'+'\\n'+str(np.round(bp_deg_day,2))+' days$^{-1}$',xy=(0.35,0.8), xycoords='axes fraction', color=colors[1], fontsize=12)\n",
    "plt.savefig(outdir+'saap_bp_hl_example4fig2.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see which tissues SAAP identified in this dataset were identified in in the healthy human tissue data \n",
    "# Supp. Figure 1a\n",
    "\n",
    "celltype = 'Hepatocytes'\n",
    "pep_df = pd.read_csv(val_dir+celltype+'/Results/combined_modified_peptide_label_quant.tsv', sep='\\t')\n",
    "\n",
    "fasta = open(savitski_dir+'databases/2024-07-21-decoys-contam-human_MTP_Hepatocytes.fasta.fas', 'r').read()\n",
    "fasta_entries = [x for x in fasta.split('>')]\n",
    "all_mtps = [x for x in fasta_entries if re.match('MTP\\|', x)] # these come from Savitski DP search \n",
    "all_saap = [x for x in fasta_entries if re.match('SAAP_', x)] # these come from CPTAC/label-free DP searches\n",
    "\n",
    "# get all peptide sequences that were validated by MSFragger search \n",
    "mtp_saap_peps = [x for x in allpeps if x in all_mtp_seqs and x in all_saap_seqs]\n",
    "mtp_peps = [x for x in allpeps if x in all_mtp_seqs and x not in all_saap_seqs]\n",
    "saap_peps = [x for x in allpeps if x not in all_mtp_seqs and x in all_saap_seqs]\n",
    "other_peps = [x for x in allpeps if x not in all_mtp_seqs and x not in all_saap_seqs]\n",
    "\n",
    "val_saap = mtp_saap_peps + saap_peps \n",
    "set_tissues = list(set(filt_prec_quant_df['TMT/Tissue'].to_list()))\n",
    "set_tissues = [x for x in set_tissues if not re.match('S[1-9]', x)]\n",
    "\n",
    "# generate dataframe with the number of validated SAAP that were found in each type of healthy tissue\n",
    "plot_rows = []\n",
    "plot_cols = ['Tissue', 'N SAAP']\n",
    "for tissue in set_tissues:\n",
    "    tissue_ct = 0\n",
    "    for saap in val_saap:\n",
    "        tissues = filt_prec_quant_df.loc[filt_prec_quant_df['SAAP']==saap, 'TMT/Tissue'].to_list()\n",
    "        if tissue in tissues:\n",
    "            tissue_ct+=1\n",
    "    plot_rows.append([tissue, tissue_ct])\n",
    "plot_df = pd.DataFrame(plot_rows, columns=plot_cols)\n",
    "plot_df.sort_values('N SAAP', ascending=False, inplace=True)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8,4))\n",
    "sns.barplot(data=plot_df, x='Tissue', y='N SAAP')\n",
    "plt.xticks(rotation=90);\n",
    "ax.tick_params('both', labelsize=13)\n",
    "plt.ylabel('N SAAP', fontsize=14)\n",
    "plt.xlabel('')\n",
    "\n",
    "plt.savefig(outdir+'MSFragger_validation_SAAP_in_healthy_tissues.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataframe for plot of how many candidate SAAP from Savitski DP search were validated by MSFragger \n",
    "# supp. figure 1b\n",
    "\n",
    "plot_rows = []\n",
    "plot_cols = ['Cell type', 'Sample', '% peptides', '% type']\n",
    "\n",
    "for celltype in cell_types:\n",
    "    qmtp_dict = pickle.load(open(aa_subs_dir+'qMTP_dict_'+celltype+'.p','rb'))\n",
    "    cand_seqs = list(set([x for y in list(qmtp_dict['mistranslated sequence'].values()) for x in y]))\n",
    "    all_seqs = cand_seqs + cptac_saaps\n",
    "    cell_df = quant_df.loc[quant_df['Cell type']==celltype]\n",
    "    cell_times = ordered_times[celltype]\n",
    "    reps = [1,2]\n",
    "\n",
    "    all_val_seqs = list(set(cell_df['SAAP'].to_list()))\n",
    "    for time in cell_times:\n",
    "        for rep in reps:\n",
    "            sample = str(time)+'_'+str(rep)\n",
    "            sample_df = cell_df.loc[(cell_df['Time']==time) & (cell_df['Replicate']==rep)]\n",
    "            sample_df.dropna(inplace=True, subset=['Light+Heavy SAAP intensity'])\n",
    "            val_seqs = list(set(sample_df['SAAP'].to_list()))\n",
    "            pcnt_sav_saap = 100*len([x for x in cand_seqs if x in val_seqs])/len(cand_seqs)\n",
    "            pcnt_cptac_saap = 100*len([x for x in cptac_saaps if x in val_seqs])/len(cptac_saaps)\n",
    "            pcnt_all_saap = 100*len([x for x in all_seqs if x in val_seqs])/len(all_seqs)\n",
    "            plot_rows.append([celltype, sample, pcnt_sav_saap, 'Savitskit SAAP'])\n",
    "            plot_rows.append([celltype, sample, pcnt_cptac_saap, 'CPTAC SAAP'])\n",
    "plot_df = pd.DataFrame(plot_rows, columns=plot_cols)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "\n",
    "plot_df = plot_df.loc[plot_df['% type']=='Savitskit SAAP']\n",
    "sns.boxplot(data=plot_df, x='Cell type', y='% peptides', linewidth=0.8, fliersize=0, dodge=True, saturation=0.8, color='#AAAAAA')\n",
    "sns.stripplot(data=plot_df, x='Cell type', y='% peptides', linewidth=1, dodge=True, color='#555555')\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xticks(rotation=45, fontsize=14)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('% validated SAAP', fontsize=15)\n",
    "plt.savefig(outdir+'figures/percent_validated_boxplot.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended data figure 2d,e,f: ionization efficiency normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ionization efficiencies for peptides and normalization of abundances are computed in decode pipeline quant\n",
    "# here read in data from MTP_quant_dict.p and plot \n",
    "\n",
    "all_ds_mtp_ie = []\n",
    "all_ds_bp_ie = []\n",
    "\n",
    "for ds in datasets:\n",
    "    print(ds)\n",
    "    data_dir = data_dir_list[datasets.index(ds)]\n",
    "    quant_dict = pickle.load(open(data_dir+'MTP_quant_dict.p', 'rb'))\n",
    "\n",
    "    ds_mtp_ie = []\n",
    "    ds_bp_ie = []\n",
    "    for q,qdict in quant_dict.items():\n",
    "        ds_mtp_ie.append(qdict['IE_dict']['MTP_IE'])\n",
    "        ds_bp_ie.append(qdict['IE_dict']['BP_IE'])\n",
    "    all_ds_mtp_ie = all_ds_mtp_ie + ds_mtp_ie\n",
    "    all_ds_bp_ie = all_ds_bp_ie + ds_bp_ie\n",
    "    \n",
    "# plot histogram with SAAP and BP ionization efficiencies (Ext. Data Fig. 2d)\n",
    "fig,ax = plt.subplots(figsize=(4,3))\n",
    "sns.histplot(all_ds_mtp_ie, alpha=0.8, label='SAAP')\n",
    "sns.histplot(all_ds_bp_ie, alpha=0.5,color=colors[1], label='BP')\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles=handles[1:], labels=labels[1:])\n",
    "plt.xlabel('Ionization efficiency', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "ax.tick_params('both', labelsize=13)\n",
    "plt.savefig(outdir+'All_peptide_IE_hist.pdf', bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# plot a correlation plot of SAAP to BP ionization efficiency (Ext. Data Fig. 2e)\n",
    "fig,ax = plt.subplots(figsize=(4,3))\n",
    "sns.scatterplot(y=all_ds_mtp_ie, x=all_ds_bp_ie, alpha=0.8, s=15, linewidth=0.5)\n",
    "plt.xlabel('BP ionization efficiency', fontsize=14)\n",
    "plt.ylabel('SAAP ionization efficiency', fontsize=14)\n",
    "ax.tick_params('both', labelsize=13)\n",
    "plt.savefig(outdir+'All_peptide_IE_corr.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# plot a distribution of the fold changes between SAAP and BP ionization efficiencies (Ext. Data Fig. 2f)\n",
    "ie_fc = [all_ds_mtp_ie[i]/all_ds_bp_ie[i] for i in range(len(ds_mtp_ie))]\n",
    "fig,ax=plt.subplots(figsize=(4,3))\n",
    "sns.histplot(ie_fc, bins=20)\n",
    "plt.xlabel('Ionization fold change', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "ax.tick_params('both', labelsize=13)\n",
    "plt.savefig(outdir+'All_saap_bp_IE_FC.pdf', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended data figure 2a,b,c: N frags, PEP, mass error of high vs low RAAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ext. Data Fig 2a,b\n",
    "# generate a dictionary with PEP values and N fragments for all SAAP in all datasets \n",
    "\n",
    "paas_pep_dict = {}\n",
    "for ds in datasets:\n",
    "    print(ds)\n",
    "    data_dir = data_dir_list[datasets.index(ds)]\n",
    "    samples = samples_list[datasets.index(ds)]\n",
    "    mtp_dict = pickle.load(open(data_dir + 'Ion_validated_MTP_dict.p', 'rb'))\n",
    "    mtp_quant_dict = pickle.load(open(data_dir + 'MTP_quant_dict.p', 'rb'))\n",
    "\n",
    "    plot_rows = []\n",
    "    plot_cols = ['Dataset', 'Sample', 'PAAS', 'PAAS_val_idx', 'DP PEP', 'PAAS PEP', 'PAAS q', 'PAAS Precursor Intensity','BP Precursor Intensity', 'Precursor RAAS', 'N fragments']\n",
    "    for s in samples:\n",
    "        s_dict = mtp_dict[s]\n",
    "        for k, paas in s_dict['mistranslated sequence'].items():\n",
    "            paas_pep = s_dict['Posterior subs probability'][k]\n",
    "            paas_q = s_dict['q-value'][k]\n",
    "            dp_pep = s_dict['DP PEP'][k]\n",
    "            n_frags = s_dict['fragment_evidence'][k]\n",
    "            q_dict = [i for i,v in mtp_quant_dict.items() if v['MTP_seq']==paas]\n",
    "            if len(q_dict)>0:\n",
    "                q_dict = mtp_quant_dict[q_dict[0]]\n",
    "                paas_prec = q_dict['MTP_PrecInt'][s]\n",
    "                bp_prec = q_dict['BP_PrecInt'][s]\n",
    "                raas = q_dict['Prec_ratio'][s]\n",
    "                if (~np.isnan(raas)) and (~np.isinf(raas)):\n",
    "                    plot_rows.append([ds, s, paas, k, dp_pep, paas_pep, paas_q, paas_prec, bp_prec, raas, n_frags])\n",
    "    plot_df = pd.DataFrame(plot_rows, columns=plot_cols)   \n",
    "    paas_pep_dict[ds] = plot_df\n",
    "\n",
    "pickle.dump(paas_pep_dict, open(outdir+'SAAP_PEP_dfs.p', 'wb'))\n",
    "\n",
    "# create data frame for plot \n",
    "all_ds_plot_df = pd.concat([v for k,v in paas_pep_dict.items()])\n",
    "all_ds_plot_df['RAAS group'] = ['$\\geq$0' if raas>=0 else '<0' for i,raas in list(enumerate(all_ds_plot_df['Precursor RAAS'].values))]\n",
    "all_ds_plot_df = all_ds_plot_df.loc[all_ds_plot_df['PAAS q']<=0.01]\n",
    "\n",
    "# plot histogram of confidence values stratified by RAAS (Ext. Data Fig. 2a)\n",
    "fig,ax = plt.subplots(figsize=(4,3))\n",
    "all_ds_plot_df['-log q'] = [-np.log10(x) for x in all_ds_plot_df['PAAS q']]\n",
    "high_raas_df = all_ds_plot_df.loc[all_ds_plot_df['Precursor RAAS']>=0]\n",
    "low_raas_df = all_ds_plot_df.loc[all_ds_plot_df['Precursor RAAS']<0]\n",
    "sns.kdeplot(data = high_raas_df.loc[~np.isinf(high_raas_df['-log q'])], x='-log q', fill=False, color=colors[1], label='log$_{10}$(RAAS)$\\geq$0')\n",
    "sns.kdeplot(data = low_raas_df.loc[~np.isinf(low_raas_df['-log q'])], x='-log q', fill=False, label='log$_{10}$(RAAS) < 0')\n",
    "ax.tick_params('both', labelsize=13)\n",
    "plt.ylabel('Density', fontsize=14)\n",
    "plt.xlabel('-log q-value', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.savefig(outdir+'RAASgroup_logq_hist.pdf', bbox_inches='tight')\n",
    "\n",
    "# plot histogram of N fragments on substitution site stratified by RAAS (Ext. Data Fig. 2b)\n",
    "fig,ax = plt.subplots(figsize=(4,3))\n",
    "sns.kdeplot(data = high_raas_df.loc[~np.isinf(high_raas_df['-log q'])], x='N fragments', fill=False, color=colors[1], label='log$_{10}$(RAAS)$\\geq$0')\n",
    "sns.kdeplot(data = low_raas_df.loc[~np.isinf(low_raas_df['-log q'])], x='N fragments', fill=False, label='log$_{10}$(RAAS) < 0')\n",
    "ax.tick_params('both', labelsize=13)\n",
    "plt.ylabel('Density', fontsize=14)\n",
    "plt.xlabel('# fragments supporting substitution', fontsize=14)\n",
    "plt.yticks([0,0.03,0.06,0.09,0.12])\n",
    "plt.legend(fontsize=12)\n",
    "plt.savefig(outdir+'RAASgroup_Nfrags_hist.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ext. Data Fig. 2c\n",
    "\n",
    "def get_saap_mass_err(saap, s_saap_dict):\n",
    "    saap_idx = [k for k,v in s_saap_dict['mistranslated sequence'].items() if v==saap]\n",
    "    err = [s_saap_dict['Mass error (ppm)'][k] for k in saap_idx]\n",
    "    return(np.median(err))\n",
    "\n",
    "# create a dictionary with mass errors of SAAP with high and low RAAS\n",
    "mass_err_dict = {ds:{'High RAAS mass error':[], 'Low RAAS mass error':[]} for ds in datasets}\n",
    "for ds in datasets:\n",
    "    data_dir = data_dir_list[datasets.index(ds)]\n",
    "    ds_prec_df = filt_prec_quant_df.loc[filt_prec_quant_df['Dataset']==ds]   \n",
    "    saap_dict = pickle.load(open(data_dir+'Ion_validated_MTP_dict.p','rb'))\n",
    "    samples = samples_list[datasets.index(ds)]\n",
    "    for s in samples:\n",
    "        s_saap_dict = saap_dict[s]\n",
    "        if 'Mass error (ppm)' in s_saap_dict.keys():\n",
    "            s_prec_df = ds_prec_df.loc[ds_prec_df['TMT/Tissue']==s]\n",
    "            high_saap = s_prec_df.loc[s_prec_df['RAAS']>=0, 'SAAP'].to_list()\n",
    "            low_saap = s_prec_df.loc[s_prec_df['RAAS']<0, 'SAAP'].to_list()\n",
    "            high_errs = [get_saap_mass_err(saap, s_saap_dict) for saap in high_saap]\n",
    "            low_errs = [get_saap_mass_err(saap, s_saap_dict) for saap in low_saap]\n",
    "            mass_err_dict[ds]['High RAAS mass error']  = mass_err_dict[ds]['High RAAS mass error'] + high_errs\n",
    "            mass_err_dict[ds]['Low RAAS mass error']  = mass_err_dict[ds]['Low RAAS mass error'] + low_errs \n",
    "pickle.dump(mass_err_dict, open(outdir+'High_v_low_RAAS_mass_error_ppm.p','wb'))\n",
    "\n",
    "# create dataframe for plot\n",
    "plot_df_list = []\n",
    "for ds in datasets:\n",
    "    print(ds)\n",
    "    ds_me_dict = mass_err_dict[ds]\n",
    "    high_errs = ds_me_dict['High RAAS mass error']\n",
    "    low_errs = ds_me_dict['Low RAAS mass error']\n",
    "    ds_list = [ds]*len(high_errs+low_errs)\n",
    "    high_str_list = ['RAAS$\\geq$0']*len(high_errs)\n",
    "    low_str_list = ['RAAS < 0']*len(low_errs)\n",
    "    ds_plot_df = pd.DataFrame(zip(ds_list, high_errs+low_errs, high_str_list+low_str_list), columns=['Dataset', 'Mass error (ppm)', 'Peptide type'])\n",
    "    plot_df_list.append(ds_plot_df)\n",
    "plot_df = pd.concat(plot_df_list)\n",
    "\n",
    "# plot distributions of mass errors for SAAP with high and low RAAS \n",
    "fig,ax = plt.subplots(figsize=(6,3))\n",
    "sns.boxplot(data=plot_df, x='Dataset', hue='Peptide type', y='Mass error (ppm)', linewidth=1, fliersize=0.5, palette='Greys')\n",
    "plt.ylabel('Mass error (ppm)', fontsize=14)\n",
    "ax.tick_params('both', labelsize=13)\n",
    "plt.xlabel('')\n",
    "plt.ylim(-4,4)\n",
    "plt.legend(loc='lower left', fontsize=12, frameon=False, ncol=1)\n",
    "plt.savefig(outdir+'HighvLow_RAAS_Mass_error_boxplots.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2c, Extended Data Figure 2g: Consistency of RAAS values for same substitution detected in different peptides/enzymatic digests\n",
    "\n",
    "uses tonsil_saap_dict.p generated above in for figure 1h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_enz_list = ['Chymotrypsin', 'LysC', 'ArgC', 'GluC']\n",
    "\n",
    "# get list of SAAPs across digests with the same substitution (using the index in the protein sequence)\n",
    "prot_aas_idx_pairs = {}\n",
    "for s, sdict in tonsil_saap_dict.items():\n",
    "    prot_aas_idx_pairs[s] = []\n",
    "    pep_ids = sdict['Peptide IDs']\n",
    "    for p,pid in pep_ids.items():\n",
    "        prot_aas_idx_pairs[s].append([pid['saap_prot_fasta_idx'], pid['saap_prot_idx']])\n",
    "et_prot_aas_idx_pairs = [x for y in list(prot_aas_idx_pairs.values()) for x in y if len(x)>0]\n",
    "saaps_each_pair = {str(pair):[x for x,v in prot_aas_idx_pairs.items() if pair in v] for pair in set_prot_aas_idx_pairs}\n",
    "saaps_each_pair = {k:v for k,v in saaps_each_pair.items() if len(v)>1}\n",
    "saap_lists_w_same_aas = []\n",
    "for k,v in saaps_each_pair.items():\n",
    "    if v not in saap_lists_w_same_aas:\n",
    "        saap_lists_w_same_aas.append(v)\n",
    "\n",
    "# generate dataframe with RAAS values for substitutions found in multiple digests \n",
    "plot_rows = []\n",
    "plot_cols = ['Trypsin RAAS', 'Other RAAS', 'Digest', 'Same sequence', 'SAAP abundance']\n",
    "for s, sdict in tonsil_saap_dict.items():\n",
    "    if 'Trypsin' in sdict['Digests']:\n",
    "        raas_dict = sdict['RAAS']\n",
    "        trypsin_raas = np.log10(2**raas_dict['Trypsin'])\n",
    "        saap_abund = sdict['SAAP abundance']['Trypsin']\n",
    "        # include abundance values to stratify plot by SAAP abundance \n",
    "        if saap_abund>=1e10:\n",
    "            saap_abund=10\n",
    "        elif saap_abund>=1e9:\n",
    "            saap_abund=9\n",
    "        elif saap_abund>=1e8:\n",
    "            saap_abund=8\n",
    "        else:\n",
    "            saap_abund=7\n",
    "        for enz in other_enz_list:\n",
    "            if enz in sdict['Digests'] :\n",
    "                same_seq = True\n",
    "            if enz in raas_dict:\n",
    "                raas = np.log10(2**raas_dict[enz])\n",
    "                plot_rows.append([trypsin_raas, raas, enz, same_seq, saap_abund])\n",
    "\n",
    "for saap_pair in saap_lists_w_same_aas:\n",
    "    sdict1 = tonsil_saap_dict[saap_pair[0]]\n",
    "    sdict2 = tonsil_saap_dict[saap_pair[1]]\n",
    "    if 'Trypsin' in sdict1['Digests']:\n",
    "        trypsin_raas = np.log10(2**sdict1['RAAS']['Trypsin'])\n",
    "        saap_abund = sdict1['SAAP abundance']['Trypsin']\n",
    "        if saap_abund>=1e10:\n",
    "            saap_abund=10\n",
    "        elif saap_abund>=1e9:\n",
    "            saap_abund=9\n",
    "        elif saap_abund>=1e8:\n",
    "            saap_abund=8\n",
    "        else:\n",
    "            saap_abund=7\n",
    "        other_dig = sdict2['Digests']\n",
    "        for dig in other_dig:\n",
    "            if dig!='Trypsin':\n",
    "                other_raas = np.log10(2**sdict2['RAAS'][dig])\n",
    "                plot_rows.append([trypsin_raas, other_raas, dig, False, saap_abund])\n",
    "    elif 'Trypsin' in sdict2['Digests']:\n",
    "        trypsin_raas = np.log10(2**sdict2['RAAS']['Trypsin'])        \n",
    "        saap_abund = sdict2['SAAP abundance']['Trypsin']\n",
    "        if saap_abund>=1e10:\n",
    "            saap_abund=10\n",
    "        elif saap_abund>=1e9:\n",
    "            saap_abund=9\n",
    "        elif saap_abund>=1e8:\n",
    "            saap_abund=8\n",
    "        else:\n",
    "            saap_abund=7\n",
    "        other_dig = sdict1['Digests']\n",
    "        for dig in other_dig:\n",
    "            if dig!='Trypsin':\n",
    "                other_raas = np.log10(2**sdict1['RAAS'][dig])       \n",
    "                plot_rows.append([trypsin_raas, other_raas, dig, False, saap_abund])\n",
    "\n",
    "plot_df = pd.DataFrame(plot_rows, columns=plot_cols)\n",
    "plot_df = plot_df.replace(np.inf, np.nan)\n",
    "plot_df = plot_df.replace(-np.inf, np.nan)\n",
    "plot_df = plot_df.dropna()\n",
    "plot_df.to_excel(outdir+'Trypsin_vs_other_digest_plot_df.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot RAAS of substitution in another digest vs RAAS of substitution in trypsin, colored by SAAP abundance\n",
    "# Ext. Data Fig. 2g\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "fig,ax=plt.subplots(figsize=(3,3))\n",
    "sns.scatterplot(data=plot_df, x='Trypsin RAAS', y='Other RAAS', hue='SAAP abundance')\n",
    "plt.legend(loc='lower left', handletextpad=0, ncol=2, bbox_to_anchor=(0,1), frameon=False, fontsize=11, title='log$_{10}$(SAAP abundance)', title_fontsize=11)\n",
    "\n",
    "r,p = sp.stats.pearsonr(plot_df['Trypsin RAAS'].to_list(), plot_df['Other RAAS'].to_list())\n",
    "ax.text(-4.8,0.6, 'r = '+str(np.round(r, 2)), fontsize=11)\n",
    "ax.text(-4.8,0.1, 'p < 10$^{-11}$', fontsize=11)\n",
    "\n",
    "plt.ylabel('Other protease log$_{10}$(RAAS)', fontsize=13)\n",
    "plt.xlabel('Trypsin log$_{10}$(RAAS)', fontsize=13)\n",
    "ax.tick_params('both', labelsize=12)\n",
    "plt.savefig(outdir+'tonsil_trypsinRAAS_vs_otherRAAS_scatter_saapabundcolor_newvalsearch.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot RAAS of substitution in another digest vs RAAS of substitution in trypsin, colored by digest\n",
    "# Fig. 2c\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "fig,ax=plt.subplots(figsize=(3,3))\n",
    "sns.scatterplot(data=plot_df, x='Trypsin RAAS', y='Other RAAS', hue='Digest')\n",
    "handles, labels = ax.get_legend_handles_labels()  \n",
    "plt.legend(handles=handles, labels=labels, loc='center', bbox_to_anchor=(0.5,1.08),\n",
    "           handletextpad=-0.3, ncol=2, frameon=False, fontsize=11, columnspacing=0.1)#, title='log$_{10}$(SAAP abundance)')\n",
    "ax.annotate(r'X$:$', xy=(0.25,1.01), xycoords='figure fraction', fontsize=15)\n",
    "\n",
    "r,p = sp.stats.pearsonr(plot_df['Trypsin RAAS'].to_list(), plot_df['Other RAAS'].to_list())\n",
    "ax.text(-4.8,1, 'r = '+str(np.round(r, 2)), fontsize=11)\n",
    "ax.text(-4.8,0.5, 'p < 10$^{-11}$', fontsize=11)\n",
    "plt.yticks([-4,-2,0,2])\n",
    "\n",
    "plt.ylabel('Protease X, log$_{10}$(RAAS)', fontsize=14)\n",
    "plt.xlabel('Trypsin, log$_{10}$(RAAS)', fontsize=14)\n",
    "ax.tick_params('both', labelsize=13)\n",
    "plt.savefig(outdir+'tonsil_trypsinRAAS_vs_otherRAAS_scatter_digestseqcolor_newvalsearch.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data FIgure 2h: Compare abundance of missed cleaved BPs to BPs without missed cleavages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for plot from Supplemental_Data_2.SAAP_precursor_quant.xlsx\n",
    "\n",
    "ds_bp_mc_dict = {ds:{} for ds in datasets}\n",
    "for ds in datasets:\n",
    "    ds_saap_df = filt_saap_df.loc[filt_saap_df['Dataset']==ds]\n",
    "    bp_list_all = ds_saap_df['BP'].to_list()\n",
    "    for i,row in ds_saap_df.iterrows():\n",
    "        bp = row['BP']\n",
    "        bp_list = [x for x in bp_list_all if x!=bp]\n",
    "        mc = list(set([x for x in bp_list if bp in x]))\n",
    "        if len(mc)>0:\n",
    "            ds_bp_mc_dict[ds][bp] = mc\n",
    "            \n",
    "plot_rows = []\n",
    "plot_cols = ['Dataset', 'BP', 'Missed cleavage BP', 'BP abundance', 'Missed cleavage BP abundance', 'AAS', 'AAS index', 'Color']\n",
    "for ds in datasets:\n",
    "    print(ds)\n",
    "    ds_bp_mc = ds_bp_mc_dict[ds]\n",
    "    ds_prec_df = filt_prec_quant_df.loc[filt_prec_quant_df['Dataset']==ds]\n",
    "    samples = samples_list[datasets.index(ds)]\n",
    "    for bp, mc_list in ds_bp_mc.items():\n",
    "        for s in samples:\n",
    "            s_df = ds_prec_df.loc[ds_prec_df['TMT/Tissue']==s]\n",
    "            for mc in mc_list:\n",
    "                if bp in s_df['BP'].to_list() and mc in s_df['BP'].to_list():\n",
    "                    bp_df = s_df.loc[s_df['BP']==bp]\n",
    "                    bp_abund = bp_df['BP abundance'].values[0]\n",
    "                    aas = bp_df['AAS'].values[0]\n",
    "                    saap = bp_df['SAAP'].values[0]\n",
    "                    raas = bp_df['RAAS'].values[0]\n",
    "                    aas_idx = [i for i,x in enumerate(saap) if bp[i]!=x][0]\n",
    "                    mc_abund = s_df.loc[s_df['BP']==mc, 'BP abundance'].values[0]\n",
    "                    if raas>0:\n",
    "                        c = 'RAAS>0'\n",
    "                    else:\n",
    "                        c = 'RAAS<0'\n",
    "                    plot_rows.append([ds, bp, mc, bp_abund, mc_abund, aas, aas_idx, c])\n",
    "                    \n",
    "plot_df = pd.DataFrame(plot_rows, columns=plot_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scatterplot of abundance of BPs with missed cleavages to abundance of BPs\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "fig,ax = plt.subplots(figsize=(3,3))\n",
    "sns.scatterplot(data=plot_df, x='BP abundance', y='Missed cleavage BP abundance', s=40, alpha=0.9, color='#AAAAAA')\n",
    "ax.tick_params('both', labelsize=13)\n",
    "plt.xlabel('BP abundance', fontsize=14)\n",
    "plt.ylabel('Missed cleavage\\nBP abundance', fontsize=14)\n",
    "plt.plot((0,8e7), (0,8e7), '--k', linewidth=1)\n",
    "plt.tight_layout()\n",
    "plt.xticks([0,2e8,4e8])\n",
    "plt.savefig(outdir+'All_missed_cleavage_BP_vs_BP_scatter.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data Figure 3e: Upset plot of SAAP identified across datasets\n",
    "\n",
    "Uses Supplemental_Data_2.SAAP_proteins.xlsx (filt_saap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import upsetplot as up\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe of the number of datasets each SAAP-BP pair is found in \n",
    "saap_bp = [row['SAAP']+':'+row['BP'] for i,row in filt_saap_df.iterrows()]\n",
    "saap_bp_counter = Counter(saap_bp)\n",
    "saap_bp_count_df = pd.DataFrame.from_dict(saap_bp_counter, columns=['N datasets'], orient='index')\n",
    "\n",
    "def get_ds(saap, bp, filt_saap_df):\n",
    "    \"\"\" function to get the list of datasets a given SAAP-BP pair is found in\"\"\"\n",
    "    saap_bp_df = filt_saap_df.loc[(filt_saap_df['SAAP']==saap) & (filt_saap_df['BP']==bp)]\n",
    "    ds_list = saap_bp_df['Dataset'].tolist()\n",
    "    return(ds_list)\n",
    "\n",
    "# addd column with the datasets each SAAP-BP pair is found in \n",
    "saap_bp_count_df['Datasets'] = ''\n",
    "for i in saap_bp_count_df.index:\n",
    "    saap = i.split(':')[0]\n",
    "    bp = i.split(':')[1]\n",
    "    ds_str = str(get_ds(saap, bp, filt_saap_df))\n",
    "    saap_bp_count_df.loc[i,'Datasets'] = ds_str\n",
    "    \n",
    "# initiate index for upset plot dataframe \n",
    "l = [False, True]\n",
    "arrays = [list(i) for i in itertools.product(l, repeat=7)]\n",
    "arrays = np.transpose(arrays)\n",
    "tuples = list(zip(*arrays))\n",
    "multiindex = pd.MultiIndex.from_tuples(tuples, names=datasets)\n",
    "\n",
    "# Create dataframe for upset plot \n",
    "saap_counts = []\n",
    "idx = multiindex[1]\n",
    "keepidx = []\n",
    "for idx in multiindex:\n",
    "    if True in idx:\n",
    "        saap_ds = [datasets[i] for i,x in enumerate(idx) if x==True]\n",
    "        n_saap_ds = len(saap_bp_count_df.loc[saap_bp_count_df['Datasets']==str(saap_ds)])\n",
    "        if n_saap_ds>0:\n",
    "            saap_counts.append(n_saap_ds)\n",
    "            keepidx.append(idx)\n",
    "keepidx = np.transpose(keepidx)\n",
    "tuples = list(zip(*keepidx))\n",
    "multiindex = pd.MultiIndex.from_tuples(tuples, names=datasets)\n",
    "upset_plot_data = pd.Series(saap_counts, index=multiindex)\n",
    "\n",
    "# plot upset plot\n",
    "up.plot(upset_plot_data, show_counts=True, min_subset_size=10)\n",
    "plt.savefig(shared_saap_outdir+'Upsetplot_n10_max_Healthy.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data Figure 3f: Percentage of samples of each dataset that SAAP identified in 6+ datasets (\"shared SAAP\") are found in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add number of datasets each SAAP-BP pair is found in to data from supplemental_data_2,3,4\n",
    "\n",
    "filt_saap_df['N datasets'] = filt_saap_df.apply(lambda x: len(get_ds(x['SAAP'], x['BP'], filt_saap_df)), axis=1)\n",
    "filt_saap_df['Datasets'] = filt_saap_df.apply(lambda x: str(get_ds(x['SAAP'], x['BP'], filt_saap_df)), axis=1)\n",
    "filt_reporter_quant_df['N datasets'] = filt_reporter_df.apply(lambda x: len(get_ds(x['SAAP'], x['BP'], filt_saap_df)), axis=1)\n",
    "filt_prec_quant_df['N datasets'] = filt_prec_df.apply(lambda x: len(get_ds(x['SAAP'], x['BP'], filt_saap_df)), axis=1)\n",
    "\n",
    "# get subsets of the dataframes for which the SAAP-BP pair is found in 6+ datasets\n",
    "n6_saap_df = filt_saap_df.loc[filt_saap_df['N datasets']>=6]\n",
    "n6_reporter_df = filt_reporter_quant_df.loc[filt_reporter_quant_df['N datasets']>=6]\n",
    "n6_prec_df = filt_prec_quant_df.loc[filt_prec_quant_df['N datasets']>=6]\n",
    "\n",
    "#  generate dataframe for heatmap showing in what percentage of samples does each shared saap come up in each dataset\n",
    "shared_saap_bp_n6 = [i for i,row in saap_bp_count_df.iterrows() if row['N datasets']>=6]\n",
    "n_samples_heatmap_df = pd.DataFrame(index=datasets, columns=shared_saap_bp_n6)\n",
    "pcnt_samples_heatmap_df = pd.DataFrame(index=datasets, columns=shared_saap_bp_n6)\n",
    "\n",
    "# dictionary with total number of samples in each dataset for computing percentages\n",
    "n_total_samples_dict = {ds:0 for ds in datasets}\n",
    "for ds in datasets:\n",
    "    if ds != 'Healthy':\n",
    "        sample_map = sample_map_list[datasets.index(ds)]\n",
    "        n_total_samples = len(sample_map['sample_name'].values)\n",
    "    else:\n",
    "        n_total_samples = len(samples_list[datasets.index(ds)])\n",
    "    n_total_samples_dict[ds] = n_total_samples\n",
    "        \n",
    "for saap_bp in shared_saap_bp_n6:\n",
    "    saap = saap_bp.split(':')[0]\n",
    "    bp = saap_bp.split(':')[1]\n",
    "    for ds in datasets:\n",
    "        if ds!='Healthy':\n",
    "            ds_reporter_df = n6_reporter_df.loc[n6_reporter_df['Dataset']==ds]\n",
    "            saap_bp_df = ds_reporter_df.loc[(ds_reporter_df['SAAP']==saap) & (ds_reporter_df['BP']==bp)]\n",
    "        else:\n",
    "            ds_prec_df = n6_prec_df.loc[n6_prec_df['Dataset']==ds]\n",
    "            saap_bp_df = ds_prec_df.loc[(ds_prec_df['SAAP']==saap) & (ds_prec_df['BP']==bp)]\n",
    "        n_samples = len(saap_bp_df)\n",
    "        pcnt_samples = 100*n_samples/n_total_samples_dict[ds]\n",
    "        n_samples_heatmap_df.loc[ds, saap_bp] = n_samples\n",
    "        pcnt_samples_heatmap_df.loc[ds, saap_bp] = pcnt_samples\n",
    "        \n",
    "# plot as a heatmap\n",
    "pcnt_samples_heatmap_df = pcnt_samples_heatmap_df.astype(float)\n",
    "c = sns.clustermap(pcnt_samples_heatmap_df, figsize=(5,5), method='ward', xticklabels=False, vmin=0, vmax=80)\n",
    "c.ax_row_dendrogram.set_visible(False)\n",
    "c.ax_heatmap.set_xlabel('SAAP in $\\geq$6 datasets', fontsize=15)\n",
    "c.ax_heatmap.set_yticklabels(c.ax_heatmap.get_ymajorticklabels(), fontsize = 14)\n",
    "c.ax_heatmap.set_facecolor('#F3F3F3')\n",
    "c.ax_heatmap.yaxis.set_ticks_position('left')\n",
    "c.ax_cbar.set_ylabel(r'% samples with SAAP', labelpad=3)\n",
    "c.ax_cbar.set_position([0.87,0.06,0.03,0.7])\n",
    "c.ax_cbar.yaxis.label.set_size(15)\n",
    "c.ax_cbar.tick_params(labelsize=13)\n",
    "c.savefig(outdir+'%_samples_all_ds_sharedSAAPn6_vmax80.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data Figure 3g: RAAS distributions for shared SAAP (found in 6+ datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,len(datasets),figsize=(len(datasets),3), sharey=True)\n",
    "plt.subplots_adjust(wspace=0.05)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "for ax in axes:\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.tick_params('x', bottom=False,labelbottom=False)\n",
    "    if ax!=axes[0]:    \n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.tick_params(left=False)\n",
    "        \n",
    "# compute medians to sort datasets by\n",
    "medians = [np.nanmedian(n6_reporter_df.loc[n6_reporter_df['Dataset']==ds,'RAAS'].values) for ds in datasets[:-1]]\n",
    "med_sort_idx = list(np.argsort(medians))\n",
    "med_sort_idx.append(max(med_sort_idx)+1)\n",
    "\n",
    "# plot violin plots\n",
    "for i,ds in enumerate(datasets):\n",
    "    ax_idx = med_sort_idx.index(i)\n",
    "    axes[ax_idx].set_xlabel(ds, fontsize=14)\n",
    "    if ds!='Healthy':\n",
    "        ratio_data = [x for x in n6_reporter_df.loc[rn6_reporter_df['Dataset']==ds,'RAAS'].values if ~np.isnan(x) and ~np.isinf(x)]\n",
    "    else:\n",
    "        ratio_data = [x for x in n6_prec_df.loc[n6_prec_df['Dataset']==ds,'RAAS'].values if ~np.isnan(x) and ~np.isinf(x)]\n",
    "    bihist(ratio_data, ratio_data, nbins=10,h=axes[ax_idx])\n",
    "    if ax_idx==0:\n",
    "        axes[ax_idx].annotate('N= ', (-0.2,1.01), xycoords='axes fraction', fontsize=13)\n",
    "\n",
    "    axes[ax_idx].annotate(str(len(ratio_data)), (0.21,1.01), xycoords='axes fraction', fontsize=13)\n",
    "        \n",
    "    axes[ax_idx].plot(axes[ax_idx].get_xlim(), (np.median(ratio_data), np.median(ratio_data)), '--r',linewidth=0.7)\n",
    "\n",
    "axes[0].set_ylabel(r'log$_{10}$ RAAS', fontsize=15)\n",
    "axes[0].tick_params('y',labelsize=13)\n",
    "axes[0].set_yticks([-6,-4,-2,0,2,4]);\n",
    "plt.savefig(outdir+'Sample_level_RAAS_allDS_SharedSAAPin6.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data Figure 3h: Boxplots of mean RAAS relative to LUAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initate dataframe for plot\n",
    "\n",
    "plot_rows = []\n",
    "plot_cols = ['LUAD RAAS', 'Other RAAS', 'SAAP','BP', 'LUAD-Other', 'Dataset']\n",
    "for ds in datasets:\n",
    "    print(ds)\n",
    "    if ds != 'LUAD' and ds!='Healthy':\n",
    "        luad_ds_rows = [i for i,row in filt_saap_df.iterrows() if 'LUAD' in row['Datasets'] and ds in row['Datasets']]\n",
    "        luad_ds_df = filt_saap_df.loc[luad_ds_rows]\n",
    "        saap_list = luad_ds_df['SAAP'].values\n",
    "        bp_list = luad_ds_df['BP'].values\n",
    "        \n",
    "        saap_bp_list = [[saap_list[i], bp_list[i]] for i in range(len(saap_list))]\n",
    "        for sb in saap_bp_list:\n",
    "            saap = sb[0]\n",
    "            bp = sb[1]\n",
    "            sb_df = luad_ds_df.loc[(luad_ds_df['SAAP']==saap) & (luad_ds_df['BP']==bp)]\n",
    "            ds_raas = sb_df.loc[sb_df['Dataset']==ds, 'Mean reporter RAAS'].values[0]\n",
    "            luad_raas = sb_df.loc[sb_df['Dataset']=='LUAD', 'Mean reporter RAAS'].values[0]\n",
    "            ds_luad_raas = ds_raas - luad_raas \n",
    "            plot_rows.append([luad_raas, ds_raas, saap, bp, ds_luad_raas, ds])\n",
    "plot_df = pd.DataFrame(plot_rows, columns=plot_cols)\n",
    "\n",
    "# plot data \n",
    "fig,ax = plt.subplots(figsize=(6,3))\n",
    "sns.boxplot(data=plot_df, x='Dataset', y='LUAD-Other', color='#CACACA', order=['LSCC','UCEC','BRCA','PDAC','CCRCC'], fliersize=0.8)\n",
    "plt.tick_params('y', labelsize=13)\n",
    "plt.tick_params('x', labelsize=14)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Other - LUAD log$_{10}$(RAAS)', fontsize=14)\n",
    "plt.ylim([-2,2.5])\n",
    "plt.savefig(outdir+'Shared_SAAP_Rel2LUAD_boxplots.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2e: Relative RAAS computed for shared SAAP between 2 patient samples\n",
    "Analysis limited to CPTAC datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a matrix with median  of relative RAAS computed for shared peptides between each pair of patients \n",
    "\n",
    "all_ds_matrices = {}\n",
    "ds_report_df = filt_reporter_quant_df.loc[filt_quant_reporter_df['Sample type']=='Tumor']\n",
    "ds_report_df.sort_values('RAAS', inplace=True)\n",
    "set_samples = list(set(ds_report_df['Sample name'].values))\n",
    "ds_matrix_rowcol = pd.DataFrame(index=set_samples, columns=set_samples)\n",
    "\n",
    "for sample1 in set_samples:\n",
    "    sample1_df = ds_report_df.loc[ds_report_df['Sample name']==sample1]\n",
    "    sample1_saap_bp = [sample1_df['SAAP'].to_list()[i]+':'+sample1_df['BP'].to_list()[i] for i in range(len(sample1_df))]\n",
    "\n",
    "    other_samples = set_samples[set_samples.index(sample1):]\n",
    "    for sample2 in other_samples:\n",
    "        sample2_df = ds_report_df.loc[ds_report_df['Sample name']==sample2]\n",
    "        sample2_saap_bp = [sample2_df['SAAP'].to_list()[i]+':'+sample2_df['BP'].to_list()[i] for i in range(len(sample2_df))]\n",
    "        shared_saap_bp = [x for x in sample1_saap_bp if x in sample2_saap_bp]\n",
    "        row_shared_raas_ratios = []\n",
    "        col_shared_raas_ratios = []\n",
    "        \n",
    "        # for each SAAP shared between 2 patients, compute relative RAAS on log2 scale\n",
    "        for sb, saap_bp in enumerate(shared_saap_bp):\n",
    "            saap = saap_bp.split(':')[0]\n",
    "            bp = saap_bp.split(':')[1]\n",
    "            raas1 = sample1_df.loc[(sample1_df['SAAP']==saap) & (sample1_df['BP']==bp), 'RAAS'].values[0]\n",
    "            raas2 = sample2_df.loc[(sample2_df['SAAP']==saap) & (sample2_df['BP']==bp), 'RAAS'].values[0]\n",
    "            if ~np.isnan(raas1) and ~np.isnan(raas2) and ~np.isinf(raas1) and ~np.isinf(raas2):\n",
    "                raas_ratio = raas1 - raas2\n",
    "                raas_ratio = np.log2(10**raas_ratio)\n",
    "                col_raas_ratio = raas2 - raas1\n",
    "                col_raas_ratio = np.log2(10**col_raas_ratio)\n",
    "                row_shared_raas_ratios.append(raas_ratio)\n",
    "                col_shared_raas_ratios.append(col_raas_ratio)\n",
    "        ds_matrix_rowcol.loc[sample1, sample2] = np.nanmedian(row_shared_raas_ratios)\n",
    "        ds_matrix_rowcol.loc[sample2, sample1] = np.nanmedian(col_shared_raas_ratios)\n",
    "\n",
    "all_ds_matrices['All_data'] = {'Row_col':ds_matrix_rowcol}\n",
    "\n",
    "# Add N SAAP per comparison to all_data matrix\n",
    "ds_report_df = filt_reporter_quant_df.loc[filt_reporter_quant_df['Sample type']=='Tumor']\n",
    "ds_report_df.sort_values('RAAS', inplace=True)\n",
    "set_samples = list(set(ds_report_df['Sample name'].values))\n",
    "\n",
    "ds_matrix_rowcol = pd.DataFrame(index=set_samples, columns=set_samples)\n",
    "for i,sample1 in enumerate(set_samples):\n",
    "    if i%100==0:\n",
    "        print(i)\n",
    "    sample1_df = ds_report_df.loc[ds_report_df['Sample name']==sample1]\n",
    "    sample1_saap_bp = [sample1_df['SAAP'].to_list()[i]+':'+sample1_df['BP'].to_list()[i] for i in range(len(sample1_df))]\n",
    "    other_samples = set_samples[set_samples.index(sample1):]\n",
    "    for sample2 in other_samples:\n",
    "        sample2_df = ds_report_df.loc[ds_report_df['Sample name']==sample2]\n",
    "        sample2_saap_bp = [sample2_df['SAAP'].to_list()[i]+':'+sample2_df['BP'].to_list()[i] for i in range(len(sample2_df))]\n",
    "        shared_saap_bp = [x for x in sample1_saap_bp if x in sample2_saap_bp]\n",
    "        ds_matrix_rowcol.loc[sample1, sample2] = len(shared_saap_bp)\n",
    "        ds_matrix_rowcol.loc[sample2, sample1] = len(shared_saap_bp)\n",
    "\n",
    "all_ds_matrices['All_data']['N_shared_saap'] = ds_matrix_rowcol\n",
    "\n",
    "pickle.dump(all_ds_matrices, open(outdir+'All_pairwise_sample_RAAS_ratio_matrices_log2.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot heatmnap sorted by row/col median \n",
    "ds = 'All_data'\n",
    "\n",
    "ds_matrix = all_ds_matrices[ds]['Row_col'].astype(float)\n",
    "medians = [np.median([x for x in row.values if ~np.isnan(x)]) for i,row in ds_matrix.iterrows()]\n",
    "srt_idx = np.argsort(medians)\n",
    "col_medians = [np.median([x for x in ds_matrix[col].to_list() if ~np.isnan(x)]) for col in ds_matrix.columns]\n",
    "col_srt_idx = np.argsort(col_medians)\n",
    "plot_matrix = ds_matrix.iloc[srt_idx, col_srt_idx]\n",
    "\n",
    "c = sns.clustermap(plot_matrix, row_cluster=False, col_cluster=False, cmap='RdBu_r', center=0, robust=True, \n",
    "                   yticklabels=False, xticklabels=False, figsize=(3,3))#, cbar_kws={'ticklocation':'left'})\n",
    "c.ax_cbar.set_visible(False)\n",
    "c.ax_heatmap.set_xlabel('Patient samples', fontsize=14)\n",
    "c.ax_heatmap.set_ylabel('Patient samples', fontsize=14)\n",
    "c.ax_heatmap.yaxis.set_label_position('left')\n",
    "c.ax_heatmap.set_title('1068 cancer patients', fontsize=14)\n",
    "\n",
    "c.savefig(outdir+ds+'_Paired_RAAS_ratios_btwn_samples_median_sorted_rowcol_log2_nocbar.pdf', bbox_inches='tight')\n",
    "c.savefig(outdir+ds+'_Paired_RAAS_ratios_btwn_samples_median_sorted_rowcol_log2_nocbar.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "medians = [np.median([x for x in row.values if ~np.isnan(x)]) for i,row in ds_matrix.iterrows()]\n",
    "\n",
    "# barplot of patient medians\n",
    "srt_medians = [medians[i] for i in srt_idx]\n",
    "str_srt_idx = [str(x) for x in srt_idx]\n",
    "plot_df = pd.DataFrame(zip(str_srt_idx, srt_medians), columns=['Index','Median log$_{10}$(RAAS) ratio'])\n",
    "\n",
    "sns.set_style('ticks')\n",
    "fig,ax = plt.subplots(figsize=(1,3))\n",
    "sns.barplot(data=plot_df, x='Median log$_{10}$(RAAS) ratio', y='Index', palette='RdBu_r', saturation=1,linewidth=0)\n",
    "ax.set_ylabel(None)\n",
    "ax.set_yticks([]);\n",
    "ax.tick_params('x', labelsize=13)\n",
    "plt.ylabel('Median log$_{2}$(relative RAAS)', fontsize=14)\n",
    "plt.xlabel('')\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.set_xticks([-2,0,2]);\n",
    "ax.yaxis.set_label_position('right')\n",
    "plt.savefig(outdir+ds+'_Paired_RAAS_ratios_btwn_samples_median_barplot_log2.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2f: weighted means of relative RAAS for each patient in each dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot weighted mean \n",
    "\n",
    "def weighted_mean(vals, ns):\n",
    "    \"\"\" function to get mean weighted by the number of shared SAAP \"\"\"\n",
    "    wmean = np.sum([vals[i]*ns[i] for i in range(len(vals))])/np.sum(ns)\n",
    "    return(wmean)\n",
    "\n",
    "all_ds_matrix = all_ds_matrices['All_data']['Row_col'].astype(float)\n",
    "all_ds_n_matrix = all_ds_matrices['All_data']['N_shared_saap'].astype(float)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "fig,axes = plt.subplots(1, 6, figsize=(4.5,3), sharey=True)\n",
    "plt.subplots_adjust(wspace=0)\n",
    "\n",
    "# get medians for sorting datasets in plot\n",
    "medians = []\n",
    "for i,ds in enumerate(datasets[:-1]):\n",
    "    ds_sample_map = sample_map_list[datasets.index(ds)]\n",
    "    ds_samples = list(set(ds_sample_map['sample_name'].to_list()))\n",
    "    ds_matrix = all_ds_matrix.loc[[r for r,row in all_ds_matrix.iterrows() if r in ds_samples]]#, [c for c in all_ds_matrix.columns if c in ds_samples]]\n",
    "    n_matrix = all_ds_n_matrix.loc[[r for r,row in all_ds_n_matrix.iterrows() if r in ds_samples]]\n",
    "    weighted_means = [weighted_mean(ds_matrix.loc[r], row) for r,row in n_matrix.iterrows()]\n",
    "    vals = [x for x in weighted_means  if ~np.isnan(x)]\n",
    "    medians.append(np.median(vals))\n",
    "srt_idx = np.argsort(medians)\n",
    "ds_sorted = [datasets[:-1][i] for i in srt_idx]\n",
    "\n",
    "# plot weighted means \n",
    "for i,ds in enumerate(ds_sorted):\n",
    "    ax = axes[i]\n",
    "    ds_sample_map = sample_map_list[datasets.index(ds)]\n",
    "    ds_samples = list(set(ds_sample_map['sample_name'].to_list()))\n",
    "    ds_matrix = all_ds_matrix.loc[[r for r,row in all_ds_matrix.iterrows() if r in ds_samples]]#, [c for c in all_ds_matrix.columns if c in ds_samples]]\n",
    "    n_matrix = all_ds_n_matrix.loc[[r for r,row in all_ds_n_matrix.iterrows() if r in ds_samples]]\n",
    "    \n",
    "    weighted_means = [weighted_mean(ds_matrix.loc[r], row) for r,row in n_matrix.iterrows()]\n",
    "    vals = weighted_means\n",
    "    srt_idx = np.argsort(vals)\n",
    "    srt_vals = [vals[s] for s in srt_idx]\n",
    "    plot_df = pd.DataFrame(zip(list(range(len(vals))), srt_vals), columns=['Rank', 'RAAS ratio'])\n",
    "\n",
    "    sns.scatterplot(data=plot_df, y='RAAS ratio', x='Rank', ax=ax, linewidth=0, s=15, color='#AAAAAA')\n",
    "    ax.set_xlabel(ds, fontsize=12)\n",
    "    ax.set_xticks([])\n",
    "    n = len(srt_vals)\n",
    "    if i == 0:\n",
    "        ax.annotate('N = '+str(int(np.round(n, 0))), xy=(0.8,1.01), xycoords='axes fraction', ha='right', fontsize=11)\n",
    "    else:\n",
    "        ax.annotate(str(int(np.round(n, 0))), xy=(0.5,1.01), xycoords='axes fraction', ha='center', fontsize=11)\n",
    "    median = np.median([x for x in vals if ~np.isnan(x)])\n",
    "    ax.plot(ax.get_xlim(), (median,median), '--r', linewidth=0.8)\n",
    "    \n",
    "axes[0].set_yticks([-1, 0, 1])\n",
    "axes[0].tick_params('y', labelsize=13)\n",
    "axes[0].set_ylabel('log$_{2}$(relative RAAS)', fontsize=14, labelpad=-0.5)\n",
    "\n",
    "plt.savefig(outdir+'All_Paired_RAAS_ratios_btwn_samples_ranksort_allVals_log2_ds_numerator_allotherds_denom_weighted_mean.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2h. SAAP  copy number estimates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the abundance of core histone proteins using precursor ion intensity summed over isoforms mapping to each core histone\n",
    "\n",
    "histone_prot_abund_dict = {}\n",
    "for ds in datasets:\n",
    "    print(ds)\n",
    "    data_dir = data_dir_list[datasets.index(ds)]\n",
    "    \n",
    "    # prot_dict and blast_map are computed as downstream part of decode pipeline. Provided in Google Drive. \n",
    "    prot_dict = pickle.load(open(data_dir+'Allprot_normalized_abundance_dict.p', 'rb'))\n",
    "    blast_map = pd.read_excel(data_dir+'blast_map_w_gene.xlsx', index_col=0)\n",
    "    samples = samples_list[datasets.index(ds)]\n",
    "\n",
    "    histone1_protein_rows = [i for i,row in blast_map.iterrows() if re.search('histone H1', row['Blast protein'])]\n",
    "    histone1_proteins = blast_map.loc[histone1_protein_rows, 'Protein name'].to_list()\n",
    "    histone2_protein_rows = [i for i,row in blast_map.iterrows() if re.search('histone H2', row['Blast protein'])]\n",
    "    histone2_proteins = blast_map.loc[histone2_protein_rows, 'Protein name'].to_list()\n",
    "    histone3_protein_rows = [i for i,row in blast_map.iterrows() if re.search('histone H3', row['Blast protein'])]\n",
    "    histone3_proteins = blast_map.loc[histone3_protein_rows, 'Protein name'].to_list()\n",
    "    histone4_protein_rows = [i for i,row in blast_map.iterrows() if re.search('histone H4', row['Blast protein'])]\n",
    "    histone4_proteins = blast_map.loc[histone4_protein_rows, 'Protein name'].to_list()\n",
    "\n",
    "    # dict of total histone protein abundance in each patient sample\n",
    "    histone_prot_abund_dict[ds] = {}\n",
    "    for s in samples:\n",
    "        prot_df = prot_dict[s]\n",
    "        histone1_prots = prot_df.loc[[x for x in histone1_proteins if x in prot_df.index], 'Precursor intensity'].sum()\n",
    "        histone2_prots = prot_df.loc[[x for x in histone2_proteins if x in prot_df.index], 'Precursor intensity'].sum()\n",
    "        histone3_prots = prot_df.loc[[x for x in histone3_proteins if x in prot_df.index], 'Precursor intensity'].sum()\n",
    "        histone4_prots = prot_df.loc[[x for x in histone4_proteins if x in prot_df.index], 'Precursor intensity'].sum()\n",
    "        histone_prot_abund_dict[ds][s] = np.median([histone1_prots, histone2_prots, histone3_prots, histone4_prots])\n",
    "\n",
    "pickle.dump(histone_prot_abund_dict, open(outdir+'Histone_prot_median_precursor_abundance_dict_sumsubtypes.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute copy number estimates for SAAP based on their protein abundances and histone abundances\n",
    "# uses \"histone ruler\" method assuming 30e6 copy number for histone proteins\n",
    "\n",
    "plot_rows = []\n",
    "plot_cols = ['Dataset', 'SAAP', 'Sample name', 'SAAP abundance', 'Histone abundance', 'SAAP/Histone']\n",
    "for ds in datasets:\n",
    "    print(ds)\n",
    "    ds_quant_df = filt_prec_quant_df.loc[filt_prec_quant_df['Dataset']==ds]\n",
    "    saaps = list(set(ds_quant_df['SAAP'].values))\n",
    "    samples = list(set(ds_quant_df['TMT/Tissue'].values))\n",
    "    samples = [x for x in samples if x!='tonsil']\n",
    "\n",
    "    for sample in samples:\n",
    "        histone_abund = histone_prot_abund_dict[ds][sample]\n",
    "        for saap in saaps:\n",
    "            saap_abund = ds_quant_df.loc[(ds_quant_df['SAAP']==saap) & (ds_quant_df['TMT/Tissue']==sample), 'SAAP abundance'].values\n",
    "            if len(saap_abund)>0: # not all SAAP in every sample\n",
    "                saap_abund = saap_abund[0]\n",
    "                saap_histone = saap_abund/histone_abund\n",
    "                plot_rows.append([ds, saap, sample, saap_abund, histone_abund, saap_histone])\n",
    "\n",
    "plot_df = pd.DataFrame(plot_rows, columns=plot_cols)\n",
    "plot_df['SAAP copies'] = plot_df.apply(lambda x: np.round(30e6*x['SAAP/Histone']), axis=1)\n",
    "plot_df.to_excel(outdir+'SAAP_copy_estimate_by_median_histone_sumsubtypes_precursors.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot median and max SAAP copy numbers in rank sorted order, highlighting substituted proteins of interest\n",
    "prec_saap_copy_number_df = plot_df\n",
    "\n",
    "# combine peptides across all datasets with median and max\n",
    "rows = []\n",
    "cols = ['SAAP', 'Median SAAP copies', 'Genes','Pfam', 'RefProt', 'Max SAAP copies']\n",
    "ds_df = prec_saap_copy_number_df.loc[prec_saap_copy_number_df['Dataset']!='Healthy']\n",
    "ds_saap = list(set(ds_df['SAAP'].to_list()))\n",
    "for saap in ds_saap:\n",
    "    saap_df = ds_df.loc[ds_df['SAAP']==saap]\n",
    "    median_copies = saap_df['SAAP copies'].median()\n",
    "    max_copies = saap_df['SAAP copies'].max()\n",
    "    genes = saap_df['Genes'].to_list()[0]\n",
    "    pfam = saap_df['Pfam'].to_list()[0]\n",
    "    refprot = saap_df['RefProt'].to_list()[0]\n",
    "    rows.append([saap, median_copies, genes, pfam, refprot, max_copies]) \n",
    "median_prec_saap_copy_number_df = pd.DataFrame(rows, columns=cols)\n",
    "\n",
    "# generate plot \n",
    "rank_df = median_prec_saap_copy_number_df.loc[median_prec_saap_copy_number_df['Median SAAP copies']>=10, ['SAAP','Median SAAP copies', 'Max SAAP copies']]\n",
    "\n",
    "sns.set_style('ticks')\n",
    "fig,ax = plt.subplots(figsize=(3,3))\n",
    "rank_df.sort_values('Max SAAP copies', ascending=False, inplace=True)\n",
    "rank_df.reset_index(inplace=True, drop=True)\n",
    "rank_df['Rank'] = rank_df.index\n",
    "sns.scatterplot(data=rank_df, x='Rank', y='Max SAAP copies', color='#AAAAAA', linewidth=0, s=80, marker='.', alpha=0.5)\n",
    "\n",
    "rank_df.sort_values('Median SAAP copies', ascending=False, inplace=True)\n",
    "rank_df.reset_index(inplace=True, drop=True)\n",
    "rank_df['Rank'] = rank_df.index\n",
    "\n",
    "sns.scatterplot(data=rank_df, x='Rank', y='Median SAAP copies', color='#555555', linewidth=0, s=80, marker='.', alpha=0.5)\n",
    "sns.scatterplot(data=rank_df.loc[rank_df['SAAP']=='ADNTLVAYK'], x='Rank', y='Median SAAP copies', color=colors[2], linewidth=0.5, s=100)#, label='FES')\n",
    "sns.scatterplot(data=rank_df.loc[rank_df['SAAP']=='LIDLLESGK'], x='Rank', y='Median SAAP copies', color=colors[1], linewidth=0.5, s=100)#, label='DDX17')\n",
    "sns.scatterplot(data=rank_df.loc[rank_df['SAAP']=='VLAVNQEHEQLMEDYEK'], x='Rank', y='Median SAAP copies', color=colors[4], linewidth=0.5, s=100)#, label='DDX17')\n",
    "sns.scatterplot(data=rank_df.loc[rank_df['SAAP']=='IIHLGGK'], x='Rank', y='Median SAAP copies', color='k', linewidth=0.5, s=100)#, label='DDX17')\n",
    "sns.scatterplot(data=rank_df.loc[rank_df['SAAP']=='AGSELAAHQK'], x='Rank', y='Median SAAP copies', color=colors[0], linewidth=0.5, s=100)#, label='PSMA1')\n",
    "\n",
    "saap2plot = ['ADNTLVAYK', 'LIDLLESGK', 'VLAVNQEHEQLMEDYEK', 'IIHLGGK', 'AGSELAAHQK']\n",
    "ranks2plot = [rank_df.loc[rank_df['SAAP']==saap, 'Rank'].values[0] for saap in saap2plot]\n",
    "texts2plot = ['FES','DDX17', 'ACTN1', 'ZNF845', 'PSMA1']\n",
    "colors2plot = [colors[2], colors[1], colors[4], 'black', colors[0]]\n",
    "for i,rank in enumerate(ranks2plot):\n",
    "    txt = texts2plot[i]\n",
    "    y = rank_df.loc[rank_df['Rank']==rank,'Median SAAP copies']\n",
    "    if txt=='DDX17' or txt=='PSMA1':\n",
    "        ax.annotate(txt, xy=(rank,y), xytext=(rank+250,y+10), xycoords='data', textcoords='data', va='center',\n",
    "                arrowprops=dict(facecolor='k', headwidth=5,width=1, linewidth=0), color=colors2plot[i], fontsize=11)\n",
    "    elif txt=='ZNF845':\n",
    "        ax.annotate(txt, xy=(rank,y), xytext=(rank+500,y+2000), xycoords='data', textcoords='data', va='center',\n",
    "            arrowprops=dict(facecolor='k', headwidth=5,width=1, linewidth=0), color=colors2plot[i], fontsize=11)\n",
    "    elif txt=='ACTN1':\n",
    "        ax.annotate(txt, xy=(rank,y), xytext=(rank+1000,y+600), xycoords='data', textcoords='data', va='center',\n",
    "                arrowprops=dict(facecolor='k', headwidth=5,width=1, linewidth=0), color=colors2plot[i], fontsize=11)\n",
    "    elif txt=='FES':\n",
    "        ax.annotate(txt, xy=(rank,y), xytext=(rank+300,y-300), xycoords='data', textcoords='data', va='center',\n",
    "                arrowprops=dict(facecolor='k', headwidth=5,width=1, linewidth=0), color=colors2plot[i], fontsize=11)\n",
    "        \n",
    "plt.ylim([10,1e5])\n",
    "plt.yscale('log')\n",
    "ax.tick_params('both', labelsize=13)\n",
    "plt.ylabel('SAAP copies/cell', fontsize=14)\n",
    "plt.xlabel('Protein rank', fontsize=14)\n",
    "handles = [Line2D([0],[0], marker='o', color='w', label='Median', markerfacecolor='#555555'),\n",
    "          Line2D([0],[0], marker='o', color='w', label='Maximum', markerfacecolor='#AAAAAA')]\n",
    "plt.legend(handles=handles, fontsize=12, handletextpad=0, markerscale=1.2, frameon=True)\n",
    "plt.savefig(outdir+'SAAP_copies_median_histone_sumsubtypes_rankplot_ticks_gr10copies_noHealthy_PSMA1_w_max.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 3: Ratios by AAS\n",
    "\n",
    "#### Incl. Extended Data Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom colormap\n",
    "# this colormap is used for all RAAS dotplots \n",
    "\n",
    "import matplotlib\n",
    "from matplotlib.cm import get_cmap\n",
    "inferno_cmap = get_cmap('inferno')\n",
    "viridis_cmap = get_cmap('viridis')\n",
    "\n",
    "inferno_colors = inferno_cmap.colors\n",
    "viridis_colors = viridis_cmap.colors\n",
    "\n",
    "inferno_colors[-1] = viridis_colors[-1]\n",
    "custom_cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", inferno_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data Figure 5b: Distributions of median RAAS for each substitution type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all substitution types found in data\n",
    "AASs = list(set(filt_prec_quant_df['AAS'].values))\n",
    "\n",
    "# generate dictionary with RAAS values organized by substitution type\n",
    "ratios_by_aas = {}\n",
    "for i,ds in enumerate(datasets):\n",
    "    print(ds)\n",
    "    ds_prec_df = filt_prec_quant_df.loc[filt_prec_quant_df['Dataset']==ds]\n",
    "    ds_report_df = filt_reporter_quant_df.loc[filt_reporter_quant_df['Dataset']==ds]\n",
    "    aas_prec_ratio_df = ds_prec_df.loc[:, ['AAS', 'RAAS']]\n",
    "    aas_prec_ratio_df.replace(np.inf, np.nan, inplace=True)\n",
    "    aas_prec_ratio_df.replace(-np.inf, np.nan, inplace=True)\n",
    "    aas_prec_ratio_df.dropna(how='any', axis=0, inplace=True)\n",
    "    \n",
    "    prec_subs_in_plot = [x for x in AASs if x in set(aas_prec_ratio_df['AAS'])]\n",
    "    prec_medians = [np.nanmedian([x for x in aas_prec_ratio_df.loc[aas_prec_ratio_df['AAS']==sub,'RAAS'].values]) for sub in prec_subs_in_plot]\n",
    "    prec_sorted_idx = np.argsort(prec_medians)\n",
    "    prec_sorted_medians = [prec_medians[i] for i in prec_sorted_idx]\n",
    "    prec_sorted_subs = [prec_subs_in_plot[i] for i in prec_sorted_idx]\n",
    "    \n",
    "    if ds !='Healthy':\n",
    "        aas_ratio_df = ds_report_df.loc[:, ['AAS', 'RAAS']]\n",
    "        aas_ratio_df.replace(np.inf, np.nan, inplace=True)\n",
    "        aas_ratio_df.replace(-np.inf, np.nan, inplace=True)\n",
    "        aas_ratio_df.dropna(how='any', axis=0, inplace=True)\n",
    "        subs_in_plot = [x for x in AASs if x in set(aas_ratio_df['AAS'])]\n",
    "        #medians = [np.nanmedian([x for x in aas_ratio_df.loc[aas_ratio_df['AAS']==sub,'Substitution ratio'].values]) for sub in subs_in_plot]\n",
    "        medians = [np.nanmedian([x for x in aas_ratio_df.loc[aas_ratio_df['AAS']==sub,'RAAS'].values]) for sub in subs_in_plot]\n",
    "        sorted_idx = np.argsort(medians)\n",
    "        sorted_medians = [medians[i] for i in sorted_idx]\n",
    "        sorted_subs = [subs_in_plot[i] for i in sorted_idx]\n",
    "        ratios_by_aas[ds] = {'Precursor_ratio_df': aas_prec_ratio_df, 'prec_AAS_sorted':prec_sorted_subs, 'prec_medians_sorted':prec_sorted_medians, \n",
    "                             'Reporter_ratio_df': aas_ratio_df, 'AAS_sorted':sorted_subs, 'medians_sorted':sorted_medians}\n",
    "    else:\n",
    "        ratios_by_aas[ds] = {'Precursor_ratio_df': aas_prec_ratio_df, 'prec_AAS_sorted':prec_sorted_subs, 'prec_medians_sorted':prec_sorted_medians}\n",
    "pickle.dump(ratios_by_aas, open(outdir+'Ratios_by_AAS.p', 'wb'))\n",
    "\n",
    "# get median RAAS for each AAS type\n",
    "median_aas_ratios = {ds:{} for ds in datasets}\n",
    "for ds in datasets:\n",
    "    ds_aas_df = ratios_by_aas[ds]['Precursor_ratio_df']\n",
    "    aas = list(set(ds_aas_df['AAS'].values))\n",
    "    aas_medians = {aa:np.median([x for x in ds_aas_df.loc[ds_aas_df['AAS']==aa,'RAAS'].values if ~np.isnan(x) and ~np.isinf(x)]) for aa in aas}\n",
    "    median_aas_ratios[ds] = aas_medians\n",
    "\n",
    "\n",
    "# plot distributions of median RAAS across AAS types\n",
    "fig,axes = plt.subplots(1,len(datasets),figsize=(len(datasets),3), sharey=True)\n",
    "sns.set_style('whitegrid')\n",
    "for ax in axes:\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.tick_params('x', bottom=False,labelbottom=False)\n",
    "    if ax!=axes[0]:    \n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.tick_params(left=False)\n",
    "\n",
    "# get medians of each dataset to sort datasets for visualization\n",
    "medians = [np.nanmedian(list(median_aas_ratios[ds].values())) for ds in datasets if ds!='Healthy']\n",
    "med_sort_idx = list(np.argsort(medians))\n",
    "med_sort_idx.append(max(med_sort_idx)+1)\n",
    "\n",
    "for i,ds in enumerate(datasets):\n",
    "    ax_idx = med_sort_idx.index(i)\n",
    "    axes[ax_idx].set_xlabel(ds, fontsize=14)\n",
    "    ratio_data = list(median_aas_ratios[ds].values())\n",
    "    bihist(ratio_data, ratio_data, nbins=30,h=axes[ax_idx])\n",
    "    if ax_idx==0:\n",
    "        axes[ax_idx].annotate('N = ', (-0.2,1), xycoords='axes fraction', fontsize=12)\n",
    "    axes[ax_idx].annotate('{:,}'.format((len(ratio_data))), (0.3,1), xycoords='axes fraction', fontsize=12)\n",
    "    axes[ax_idx].plot(axes[ax_idx].get_xlim(), (np.nanmedian(ratio_data), np.nanmedian(ratio_data)), '--r',linewidth=1)\n",
    "axes[0].set_ylabel(r'log$_{10}$(RAAS)', fontsize=14)\n",
    "axes[0].tick_params('y', labelsize=12)\n",
    "plt.suptitle('Distribution of median RAAS across substitution types', fontsize=14)\n",
    "plt.savefig(outdir+'MedianRAAS_byAAStype_hist.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3d: weighted correlation of median RAAS for AAS types across datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_corr(x, y, w):\n",
    "    \"\"\"\n",
    "    Calculates the weighted Pearson correlation coefficient between two vectors.\n",
    "\n",
    "    Args:\n",
    "      x (np.ndarray): First vector.\n",
    "      y (np.ndarray): Second vector.\n",
    "      w (np.ndarray): Weights vector (same length as x and y).\n",
    "\n",
    "    Returns:\n",
    "      float: Weighted Pearson correlation coefficient between x and y.\n",
    "    \"\"\"\n",
    "    cov = weighted_cov(x, y, w)\n",
    "    std_x = np.sqrt(weighted_cov(x, x, w))\n",
    "    std_y = np.sqrt(weighted_cov(y, y, w))\n",
    "    if std_x * std_y == 0:\n",
    "        return 0.0  # Avoid division by zero\n",
    "    return(cov / (std_x * std_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a heatmap with the median precursor RAAS for each AAS type in each dataset \n",
    "prec_heatmap_data = pd.DataFrame(index=AASs, columns=datasets)\n",
    "for i, row in prec_heatmap_data.iterrows():\n",
    "    for ds in datasets:\n",
    "        ds_ratios = ratios_by_aas[ds]\n",
    "        medians = ds_ratios['prec_medians_sorted']\n",
    "        aas = ds_ratios['prec_AAS_sorted']\n",
    "        for i,aa in enumerate(aas):\n",
    "            prec_heatmap_data.loc[aa,ds] = medians[i]\n",
    "prec_heatmap_data.dropna(how='all', inplace=True)\n",
    "prec_heatmap_data.to_excel(outdir+'Precursor_RAAS_byAAS_alldatasets.xlsx')\n",
    "\n",
    "# compute correlations of median RAAS by AAS vectors across datasets\n",
    "prec_heatmap_data.replace(np.inf, np.nan, inplace=True)\n",
    "heatmap_df_4corr = prec_heatmap_data.dropna(how='any')\n",
    "corr_heatmap = pd.DataFrame(index=datasets, columns=datasets)\n",
    "for ds1 in datasets:\n",
    "    for ds2 in datasets:\n",
    "        x = heatmap_df_4corr[ds1].to_list()\n",
    "        y = heatmap_df_4corr[ds2].to_list()\n",
    "        w = [raas_by_aas_stats[ds1][aas]['N_peptides']+raas_by_aas_stats[ds2][aas]['N_peptides'] for aas in heatmap_df_4corr.index]\n",
    "        corr = weighted_corr(x, y, w)\n",
    "        corr_heatmap.loc[ds1,ds2] = corr\n",
    "\n",
    "# plot correlation heatmap\n",
    "corr_heatmap = corr_heatmap.astype(float)\n",
    "s= sns.clustermap(corr_heatmap, figsize=(5,5), annot=np.round(corr_heatmap, 2), cmap='Reds', cbar_kws={'label':'Pearson correlation', 'pad':1}, annot_kws={\"fontsize\":12},\n",
    "                 vmax=1, vmin=0)\n",
    "\n",
    "s.ax_heatmap.tick_params(right=False, left=True, labelright=False, labelleft=True, labelbottom=True, bottom=True)\n",
    "plt.setp(s.ax_heatmap.xaxis.get_majorticklabels(), rotation=90, fontsize=13)\n",
    "plt.setp(s.ax_heatmap.yaxis.get_majorticklabels(), fontsize=13)\n",
    "x0, y0, w, h = s.cbar_pos\n",
    "s.ax_cbar.set_position([0.87,0.26,0.05,0.5])\n",
    "s.ax_cbar.yaxis.label.set_size(14)\n",
    "s.ax_cbar.set_yticklabels([0,0.2,0.4,0.6,0.8, 1], fontsize=13)\n",
    "s.ax_row_dendrogram.set_visible(False)\n",
    "s.ax_col_dendrogram.set_visible(False)\n",
    "s.ax_heatmap.set_title('AAS type median RAAS correlation', position=(0.5,1), fontsize=14)\n",
    "plt.savefig(outdir+'Correlation_heatmap_AAStype_PrecRatios_weighted_clustered_noNan.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data Figure 5d,e: AAS types with high and low variance in RAAS across datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a heatmap with the median reporter RAAS (precursor for healthy data) for each AAS type in each dataset \n",
    "heatmap_data = pd.DataFrame(index=AASs, columns=datasets)\n",
    "for i, row in heatmap_data.iterrows():\n",
    "    for ds in datasets:\n",
    "        ds_ratios = ratios_by_aas[ds]\n",
    "        if ds!='Healthy':\n",
    "            medians = ds_ratios['medians_sorted']\n",
    "            aas = ds_ratios['AAS_sorted']\n",
    "        else:\n",
    "            medians = ds_ratios['prec_medians_sorted']\n",
    "            aas = ds_ratios['prec_AAS_sorted']\n",
    "        for i,aa in enumerate(aas):\n",
    "            heatmap_data.loc[aa,ds] = medians[i]\n",
    "heatmap_df = heatmap_data.loc[:,['PDAC', 'BRCA', 'CCRCC', 'UCEC','LUAD', 'LSCC', 'Healthy']]\n",
    "heatmap_df.dropna(how='any', axis=0, inplace=True)\n",
    "heatmap_df = heatmap_df.astype(float)\n",
    "heatmap_df.replace(np.inf, np.nan, inplace=True)\n",
    "heatmap_data.to_excel(outdir+'Reporter_RAAS_byAAS_alldatasets.xlsx')\n",
    "\n",
    "# compute variance across datasets for each AAS type\n",
    "var = []\n",
    "for i,row in heatmap_df.iterrows():\n",
    "    var.append(np.var(row.values))\n",
    "# these thresholds were determined by plotting histogram of var values\n",
    "high_var_idx = [i for i,x in enumerate(var) if x>=0.5]\n",
    "low_var_idx = [i for i,x in enumerate(var) if x<=0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot heatmap of median RAAS for AAS types with high variance across datasets (Ext. Data Fig. 5e)\n",
    "\n",
    "high_var_heatmap_df = heatmap_df.iloc[high_var_idx]\n",
    "c = sns.clustermap(data=high_var_heatmap_df, figsize=(3,4), yticklabels=True, method='ward', xticklabels=True,\n",
    "                   col_cluster=False, cmap=custom_cmap, vmax=v_max, vmin=v_min)#, robust=True)\n",
    "c.ax_heatmap.set_xticklabels(c.ax_heatmap.get_xmajorticklabels(), fontsize = 12)\n",
    "c.ax_heatmap.set_yticklabels(c.ax_heatmap.get_ymajorticklabels(), fontsize = 12)\n",
    "c.ax_heatmap.set_facecolor('#DDDDDD')\n",
    "c.ax_cbar.set_ylabel(r'Median log$_{10}$(RAAS)')\n",
    "c.ax_cbar.set_position([1,.25,0.05,0.5])\n",
    "c.ax_cbar.yaxis.label.set_size(14)\n",
    "c.ax_cbar.tick_params(labelsize=13)\n",
    "c.ax_heatmap.set_title('AAS types with high variance', position=(0.5,0.5), fontsize=13)\n",
    "c.savefig(outdir+'Reporter_highvar_heatmap_df_by_AAS_heatmap.pdf', bbox_inches='tight')\n",
    "\n",
    "# plot heatmap of median RAAS for AAS types with low variance across datasets (Ext. Data Fig. 5d)\n",
    "\n",
    "low_var_heatmap_df = heatmap_df.iloc[low_var_idx]\n",
    "c = sns.clustermap(data=low_var_heatmap_df, figsize=(3,4), yticklabels=True, method='ward', xticklabels=True,\n",
    "                   col_cluster=False, cmap=custom_cmap, vmax=v_max, vmin=v_min)#, robust=True)\n",
    "c.ax_heatmap.set_xticklabels(c.ax_heatmap.get_xmajorticklabels(), fontsize = 12)\n",
    "c.ax_heatmap.set_yticklabels(c.ax_heatmap.get_ymajorticklabels(), fontsize = 12)\n",
    "c.ax_heatmap.set_facecolor('#DDDDDD')\n",
    "c.ax_cbar.set_ylabel(r'Median log$_{10}$(RAAS)')\n",
    "c.ax_cbar.set_position([1,0.25,0.05,0.5])\n",
    "c.ax_cbar.yaxis.label.set_size(14)\n",
    "c.ax_cbar.tick_params(labelsize=13)\n",
    "c.ax_heatmap.set_title('AAS types with low variance', position=(0.5,0.5), fontsize=13)\n",
    "c.savefig(outdir+'Reporter_lowvar_heatmap_df_by_AAS_heatmap.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3a: Ranked bar plot of median RAAS for AAS types, highlighting specific AAS types in violin plot, with barplot showing # SAAP detected for each AAS type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add percentile stats for RAAS of each AAS type to Ratios_by_AAS dictionary \n",
    "\n",
    "pcntile_list = [90, 75, 25, 10, 'max', 'min']\n",
    "\n",
    "for ds in datasets:\n",
    "    print(ds)\n",
    "    aas_ratio_df = ratios_by_aas[ds]['Precursor_ratio_df']\n",
    "    aas_in_plot = list(set(aas_ratio_df['AAS'].values))\n",
    "    \n",
    "    for pcntile in pcntile_list:\n",
    "        title_str = pcntile if isinstance(pcntile,str) else str(pcntile)+'percentile'\n",
    "        if isinstance(pcntile,int):\n",
    "            prec_percentiles = [np.percentile([x for x in aas_ratio_df.loc[aas_ratio_df['AAS']==aas,'RAAS'].values], pcntile) for aas in aas_in_plot]\n",
    "        elif pcntile=='max':\n",
    "            prec_percentiles = [np.max([x for x in aas_ratio_df.loc[aas_ratio_df['AAS']==aas,'RAAS'].values]) for aas in aas_in_plot]\n",
    "        else:\n",
    "            prec_percentiles = [np.min([x for x in aas_ratio_df.loc[aas_ratio_df['AAS']==aas,'RAAS'].values]) for aas in aas_in_plot]\n",
    "        prec_sorted_idx = np.argsort(prec_percentiles)\n",
    "        prec_sorted_percentiles = [prec_percentiles[i] for i in prec_sorted_idx]\n",
    "        prec_sorted_subs = [aas_in_plot[i] for i in prec_sorted_idx]\n",
    "\n",
    "        if ds !='Healthy':\n",
    "            aas_ratio_df = ratios_by_aas[ds]['Reporter_ratio_df']\n",
    "            if isinstance(pcntile,int):\n",
    "                reporter_percentiles = [np.percentile([x for x in aas_ratio_df.loc[aas_ratio_df['AAS']==aas,'RAAS'].values], pcntile) for aas in aas_in_plot]\n",
    "            elif pcntile=='max':\n",
    "                reporter_percentiles = [np.max([x for x in aas_ratio_df.loc[aas_ratio_df['AAS']==aas,'RAAS'].values]) for aas in aas_in_plot]\n",
    "            else:\n",
    "                reporter_percentiles = [np.min([x for x in aas_ratio_df.loc[aas_ratio_df['AAS']==aas,'RAAS'].values]) for aas in aas_in_plot]\n",
    "            reporter_sorted_idx = np.argsort(reporter_percentiles)\n",
    "            reporter_sorted_percentiles = [reporter_percentiles[i] for i in reporter_sorted_idx]\n",
    "            reporter_sorted_subs = [aas_in_plot[i] for i in reporter_sorted_idx]\n",
    "\n",
    "            ratios_by_aas[ds]['Prec_AAS_'+str(title_str)+'_sorted']=prec_sorted_subs\n",
    "            ratios_by_aas[ds]['Prec_'+str(title_str)+'_sorted']=prec_sorted_percentiles\n",
    "            ratios_by_aas[ds]['Reporter_AAS_'+str(title_str)+'_sorted']=reporter_sorted_subs\n",
    "            ratios_by_aas[ds]['Reporter_'+str(title_str)+'_sorted']=reporter_sorted_percentiles\n",
    "        else:\n",
    "            ratios_by_aas[ds]['Prec_AAS_'+str(title_str)+'_sorted']=prec_sorted_subs\n",
    "            ratios_by_aas[ds]['Prec_'+str(title_str)+'_sorted']=prec_sorted_percentiles\n",
    "            ratios_by_aas[ds]['Reporter_AAS_'+str(title_str)+'_sorted']=prec_sorted_subs\n",
    "            ratios_by_aas[ds]['Reporter_'+str(title_str)+'_sorted']=prec_sorted_percentiles\n",
    "\n",
    "# add the number of SAAP with each AAS type quantified across all datasets          \n",
    "for ds in datasets:\n",
    "    print(ds)\n",
    "    ds_ratios = ratios_by_aas[ds]\n",
    "    prec_aas = ds_ratios['Precursor_ratio_df']\n",
    "    n_prec_aas = {aas:len(prec_aas.loc[prec_aas['AAS']==aas]) for aas in set(prec_aas['AAS'].values)}\n",
    "    ds_ratios['Precursor_N_AAS'] = n_prec_aas\n",
    "    if ds!='Healthy':\n",
    "        reporter_aas = ds_ratios['Reporter_ratio_df']\n",
    "        n_reporter_aas = {aas:len(reporter_aas.loc[reporter_aas['AAS']==aas]) for aas in set(reporter_aas['AAS'].values)}\n",
    "        ds_ratios['Reporter_N_AAS'] = n_reporter_aas\n",
    "\n",
    "pickle.dump(ratios_by_aas, open(outdir+'Ratios_by_AAS.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with values needed for plot (e.g. median RAAS, 90th percentile RAAS, for each AAS type)\n",
    "\n",
    "plot_rows = []\n",
    "plot_cols = ['Dataset','AAS type','Median Log$_{10}$ RAAS', '90th percentile Log$_{10}$ RAAS', 'Max Log$_{10}$ RAAS', 'RAAS type', 'N']\n",
    "\n",
    "for ds in datasets:\n",
    "    print(ds)\n",
    "    ds_ratios = ratios_by_aas[ds]\n",
    "    prec_aas = ds_ratios['prec_AAS_sorted']\n",
    "    prec_medians = ds_ratios['prec_medians_sorted']\n",
    "    \n",
    "    prec_90th_aas_pcntile = ds_ratios['Prec_AAS_90percentile_sorted']\n",
    "    prec_90th_pcntile = ds_ratios['Prec_90percentile_sorted']\n",
    "    prec_10th_aas_pcntile = ds_ratios['Prec_AAS_10percentile_sorted']\n",
    "    prec_10th_pcntile = ds_ratios['Prec_10percentile_sorted']\n",
    "    prec_90th_pcntile = [prec_10th_pcntile[prec_10th_aas_pcntile.index(aas)] if prec_medians[i]<0 else prec_90th_pcntile[prec_90th_aas_pcntile.index(aas)] for i,aas in enumerate(prec_aas)]\n",
    "    \n",
    "    prec_aas_max= ds_ratios['Prec_AAS_max_sorted']\n",
    "    prec_max = ds_ratios['Prec_max_sorted']\n",
    "    prec_aas_min= ds_ratios['Prec_AAS_min_sorted']\n",
    "    prec_min = ds_ratios['Prec_min_sorted']\n",
    "    prec_max = [prec_min[prec_aas_min.index(aas)] if prec_medians[i]<0 else prec_max[prec_aas_max.index(aas)] for i,aas in enumerate(prec_aas)]\n",
    "    prec_n = [ds_ratios['Precursor_N_AAS'][aas] for aas in prec_aas]\n",
    "    for i in range(len(prec_aas)):\n",
    "        plot_rows.append([ds,prec_aas[i],prec_medians[i], prec_90th_pcntile[i],prec_max[i], 'Precursor', prec_n[i]])\n",
    "    \n",
    "    if ds!='Healthy':\n",
    "        reporter_aas = ds_ratios['AAS_sorted']\n",
    "        reporter_medians = ds_ratios['medians_sorted']\n",
    "        reporter_90th_aas_pcntile = ds_ratios['Reporter_AAS_90percentile_sorted']\n",
    "        reporter_90th_pcntile = ds_ratios['Reporter_90percentile_sorted']   \n",
    "        reporter_10th_aas_pcntile = ds_ratios['Reporter_AAS_10percentile_sorted']\n",
    "        reporter_10th_pcntile = ds_ratios['Reporter_10percentile_sorted']\n",
    "        reporter_medians = [reporter_medians[i] for i,x in enumerate(reporter_aas) if x in reporter_90th_aas_pcntile] \n",
    "        reporter_aas = [x for x in reporter_aas if x in reporter_90th_aas_pcntile]\n",
    "        reporter_90th_pcntile = [reporter_10th_pcntile[reporter_10th_aas_pcntile.index(aas)] if reporter_medians[i]<0 else reporter_90th_pcntile[reporter_90th_aas_pcntile.index(aas)] for i,aas in enumerate(reporter_aas)]\n",
    "        reporter_aas_max= ds_ratios['Reporter_AAS_max_sorted']\n",
    "        reporter_max = ds_ratios['Reporter_max_sorted']\n",
    "        reporter_aas_min= ds_ratios['Reporter_AAS_min_sorted']\n",
    "        reporter_min = ds_ratios['Reporter_min_sorted']\n",
    "        reporter_max = [reporter_min[reporter_aas_min.index(aas)] if reporter_medians[i]<0 else reporter_max[reporter_aas_max.index(aas)] for i,aas in enumerate(reporter_aas)]\n",
    "        reporter_n = [ds_ratios['Reporter_N_AAS'][aas] for aas in reporter_aas]\n",
    "        for i in range(len(reporter_aas)):\n",
    "            plot_rows.append([ds,reporter_aas[i],reporter_medians[i], reporter_90th_pcntile[i],reporter_max[i], 'Reporter', reporter_n[i]])\n",
    "\n",
    "all_plot_df = pd.DataFrame(plot_rows,columns=plot_cols)\n",
    "all_plot_df.to_excel(outdir+'RAAS_by_AAS_summary_stats_allDS.xlsx')\n",
    "\n",
    "\n",
    "# collapse to get data for all datasets together\n",
    "\n",
    "set_aas = list(set(all_plot_df['AAS type'].to_list()))\n",
    "all_ds_plot_rows = []\n",
    "plot_cols = ['AAS type','Median Log$_{10}$ RAAS', '90th percentile Log$_{10}$ RAAS','Max Log$_{10}$ RAAS', 'N']+['N '+ds for ds in datasets]\n",
    "for aas in set_aas:\n",
    "    aas_df = all_plot_df.loc[all_plot_df['AAS type']==aas]\n",
    "    aas_df = aas_df.loc[((aas_df['Dataset']!='Healthy') & (aas_df['RAAS type']=='Reporter')) | (aas_df['Dataset']=='Healthy')]\n",
    "    med = aas_df['Median Log$_{10}$ RAAS'].median()\n",
    "    if med < 0:\n",
    "        pcnt90 = min(aas_df['90th percentile Log$_{10}$ RAAS'])\n",
    "    else:\n",
    "        pcnt90 = np.max(aas_df['90th percentile Log$_{10}$ RAAS'])\n",
    "    if med < 0:\n",
    "        raas_max = min(aas_df['Max Log$_{10}$ RAAS'])\n",
    "    else:\n",
    "        raas_max = np.max(aas_df['Max Log$_{10}$ RAAS'])\n",
    "    n = aas_df['N'].sum()\n",
    "    ccrcc_n = aas_df.loc[aas_df['Dataset']=='CCRCC']\n",
    "    if len(ccrcc_n)>0:\n",
    "        ccrcc_n = ccrcc_n['N'].values[0]\n",
    "    else:\n",
    "        ccrcc_n = 0\n",
    "    brca_n = aas_df.loc[aas_df['Dataset']=='BRCA']\n",
    "    if len(brca_n)>0:\n",
    "        brca_n = brca_n['N'].values[0]\n",
    "    else:\n",
    "        brca_n = 0\n",
    "    ucec_n = aas_df.loc[aas_df['Dataset']=='UCEC']\n",
    "    if len(ucec_n)>0:\n",
    "        ucec_n = ucec_n['N'].values[0]\n",
    "    else:\n",
    "        ucec_n = 0\n",
    "    luad_n = aas_df.loc[aas_df['Dataset']=='LUAD']\n",
    "    if len(luad_n)>0:\n",
    "        luad_n = luad_n['N'].values[0]\n",
    "    else:\n",
    "        luad_n = 0\n",
    "    pdac_n = aas_df.loc[aas_df['Dataset']=='PDAC']\n",
    "    if len(pdac_n)>0:\n",
    "        pdac_n = pdac_n['N'].values[0]\n",
    "    else:\n",
    "        pdac_n = 0\n",
    "    lscc_n = aas_df.loc[aas_df['Dataset']=='LSCC']\n",
    "    if len(lscc_n)>0:\n",
    "        lscc_n = lscc_n['N'].values[0]\n",
    "    else:\n",
    "        lscc_n = 0\n",
    "    healthy_n = aas_df.loc[aas_df['Dataset']=='Healthy']\n",
    "    if len(healthy_n)>0:\n",
    "        healthy_n = healthy_n['N'].values[0]\n",
    "    else:\n",
    "        healthy_n = 0\n",
    "    all_ds_plot_rows.append([aas, med, pcnt90, raas_max, n, ccrcc_n, ucec_n, brca_n, luad_n, pdac_n, lscc_n, healthy_n])\n",
    "\n",
    "all_ds_plot_df = pd.DataFrame(all_ds_plot_rows, columns=plot_cols)\n",
    "all_ds_plot_df.to_excel(outdir+'Reporter_RAAS_by_AAS_data_for_allDS_plot.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot barplots with # SAAP with each AAS and median/90th percentile RAAS for each AAS type \n",
    "\n",
    "# these AAS are highlighted with red lines and in the volcano plot\n",
    "aas2plot= ['H to Q', 'H to D', 'E to D', 'T to S', 'Q to G', 'S to G']\n",
    "\n",
    "plot_df = all_ds_plot_df\n",
    "subs_in_plot = list(set(plot_df['AAS type']))\n",
    "medians = [np.mean([x for x in plot_df.loc[plot_df['AAS type']==sub,'Median Log$_{10}$ RAAS'].values]) for sub in subs_in_plot]\n",
    "sorted_idx = np.argsort(medians)\n",
    "sorted_medians = [medians[i] for i in sorted_idx]\n",
    "sorted_subs = [subs_in_plot[i] for i in sorted_idx]\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "f = plt.figure()\n",
    "gs = gridspec.GridSpec(2,1,height_ratios=[1,2], hspace=0.05)\n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax1 = plt.subplot(gs[1])\n",
    "\n",
    "sns.barplot(data=plot_df,x='AAS type', y='90th percentile Log$_{10}$ RAAS', color='#aaaaaa', order=sorted_subs, linewidth=0.05, errorbar=None, ax=ax1, label='90th percentile')#, errwidth=0.1)\n",
    "sns.barplot(data=plot_df,x='AAS type', y='Median Log$_{10}$ RAAS', color='#555555', order=sorted_subs, linewidth=0.05, errorbar=None, ax=ax1, label='Median')#, errwidth=0.1)\n",
    "ax1.set_xticks([]);\n",
    "ax1.set_ylabel(r'log$_{10}$(RAAS)', fontsize=14)\n",
    "ax1.set_xlabel('Substitution type', fontsize=14)\n",
    "ax1.tick_params('y', labelsize=13)\n",
    "\n",
    "sns.barplot(data=plot_df,x='AAS type', y='N', color='black', order=sorted_subs, linewidth=0.0, errorbar=None, ax=ax0)#, errwidth=0.1)\n",
    "for aas in aas2plot:\n",
    "    aas_df = plot_df.loc[plot_df['AAS type']==aas]\n",
    "    max_raas = aas_df['90th percentile Log$_{10}$ RAAS'].values[0]\n",
    "    n = aas_df['N'].values[0]\n",
    "    idx = sorted_subs.index(aas)\n",
    "    plt.plot((idx,idx), (max_raas, 0), '-r', linewidth=2)\n",
    "    ax0.plot((idx,idx), (1, n), '-r', linewidth=2)\n",
    "\n",
    "ax0.set_xticks([]);\n",
    "ax0.set_xlabel('')\n",
    "ax0.set_yscale('log')#, basey=2)\n",
    "ax0.grid(which='major', visible=True)\n",
    "#ax0.set_title(ds, fontsize=14)\n",
    "ax0.set_ylabel('log$_{10}$(# SAAP)', fontsize=14, labelpad=12)\n",
    "ax0.set_yticks([10,100, 1000])\n",
    "ax0.set_yticklabels(['1','2','3'])\n",
    "ax1.set_yticks([-4,-2,0, 2])\n",
    "ax0.tick_params('y',labelsize=13)\n",
    "ax1.legend(bbox_to_anchor=(0.38,0.95), fontsize=11, frameon=False, labelspacing=0.3)#, loc='upper left')\n",
    "ax1.yaxis.set_major_locator(FixedLocator([-6,-4,-2,0, 2]))\n",
    "ax0.margins(x=0)\n",
    "ax1.margins(x=0)\n",
    "plt.savefig(outdir+'All_data_reporterRAAS_by_AAS_mean_90th_barplot.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the volcano plot highlighting AAS with large N across range of RAAS distributions\n",
    "\n",
    "fig,axes = plt.subplots(1, len(aas2plot), figsize=(7,2), sharey=True)\n",
    "plt.subplots_adjust(wspace=0)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "quant_df = filt_reporter_quant_df\n",
    "for i,aas in enumerate(aas2plot):\n",
    "    print(aas)\n",
    "    ax = axes[i]\n",
    "    ax.set_xlabel(aas, fontsize=15)\n",
    "    ax.set_xticks([])    \n",
    "    aas_raas_data = quant_df.loc[quant_df['AAS']==aas, 'RAAS'].values\n",
    "    aas_raas_data = [x for x in aas_raas_data if ~np.isnan(x) and ~np.isinf(x)]\n",
    "    \n",
    "    bihist(aas_raas_data, aas_raas_data, nbins=30, h=ax)\n",
    "    if i>0:\n",
    "        ax.spines['left'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    if ax==axes[-1]:\n",
    "        ax.spines['right'].set_visible(False)\n",
    "    if ax==axes[0]:\n",
    "        ax.annotate('N= ', (0,1.01), xycoords='axes fraction', fontsize=13)\n",
    "    ax.annotate('{:,}'.format((len(aas_raas_data))), (0.3,1.01), xycoords='axes fraction', fontsize=13)\n",
    "axes[0].set_yticks([-4,-2,0,2])\n",
    "axes[0].set_ylabel(r'log$_{10}$(RAAS)', fontsize=16)\n",
    "axes[0].tick_params('y', labelsize=15)\n",
    "plt.savefig(outdir+'All_DS_example_AAStype_RAASdistributions_bihist.pdf', bbox_inches='tight')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data Figure 5g: Median RAAS for Encoded and Incoporated AAS types correlations across datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add median precursor and reporter ion RAAS across all peptides identified with each base (encoded) or incorporated AA to ratios_by_aas dictionary\n",
    "\n",
    "aa_list = sorted(list(set(x[0] for x in AASs)))\n",
    "\n",
    "# add median precursor RAAS across all peptides with each base AA\n",
    "for ds in datasets: \n",
    "    print(ds)\n",
    "    aa_ratio_rows = []\n",
    "    aa_ratio_cols = ['Base AA', 'RAAS']\n",
    "    ds_ratio_df = ratios_by_aas[ds]['Precursor_ratio_df']\n",
    "    for aa in aa_list:\n",
    "        aa_idx = [i for i,row in ds_ratio_df.iterrows() if row['AAS'][0]==aa]\n",
    "        if len(aa_idx)>0:\n",
    "            aa_df = ds_ratio_df.loc[aa_idx]\n",
    "            for j, row in aa_df.iterrows():\n",
    "                aa_ratio_rows.append([aa, row['RAAS']])\n",
    "    ds_aa_df = pd.DataFrame(aa_ratio_rows, columns = aa_ratio_cols)  \n",
    "    aa_medians = [np.nanmedian([x for x in ds_aa_df.loc[ds_aa_df['Base AA']==aa,'RAAS'].values]) for aa in aa_list]\n",
    "    aa_sorted_idx = np.argsort(aa_medians)\n",
    "    aa_sorted_medians = [aa_medians[i] for i in aa_sorted_idx]\n",
    "    aa_sorted_subs = [aa_list[i] for i in aa_sorted_idx]\n",
    "    ratios_by_aas[ds]['Base_prec_AA_RAAS_df'] = ds_aa_df\n",
    "    ratios_by_aas[ds]['Base_prec_AAS_sorted'] = aa_sorted_subs\n",
    "    ratios_by_aas[ds]['Base_prec_medians_sorted'] = aa_sorted_medians\n",
    "\n",
    "# add median reporter RAAS across all peptides with each base AA\n",
    "for ds in datasets: \n",
    "    print(ds)\n",
    "    if ds!='Healthy':\n",
    "        aa_ratio_rows = []\n",
    "        aa_ratio_cols = ['Base AA', 'RAAS']\n",
    "        ds_ratio_df = ratios_by_aas[ds]['Reporter_ratio_df']\n",
    "        for aa in aa_list:\n",
    "            aa_idx = [i for i,row in ds_ratio_df.iterrows() if row['AAS'][0]==aa]\n",
    "            if len(aa_idx)>0:\n",
    "                aa_df = ds_ratio_df.loc[aa_idx]\n",
    "                for j, row in aa_df.iterrows():\n",
    "                    aa_ratio_rows.append([aa, row['RAAS']])\n",
    "        ds_aa_df = pd.DataFrame(aa_ratio_rows, columns = aa_ratio_cols)  \n",
    "        aa_medians = [np.nanmedian([x for x in ds_aa_df.loc[ds_aa_df['Base AA']==aa,'RAAS'].values]) for aa in aa_list]\n",
    "        aa_sorted_idx = np.argsort(aa_medians)\n",
    "        aa_sorted_medians = [aa_medians[i] for i in aa_sorted_idx]\n",
    "        aa_sorted_subs = [aa_list[i] for i in aa_sorted_idx]\n",
    "        ratios_by_aas[ds]['Base_reporter_AA_RAAS_df'] = ds_aa_df\n",
    "        ratios_by_aas[ds]['Base_reporter_AAS_sorted'] = aa_sorted_subs\n",
    "        ratios_by_aas[ds]['Base_reporter_medians_sorted'] = aa_sorted_medians\n",
    "        \n",
    "# add median precursor RAAS across all peptides with each susbtituted/destination AA  \n",
    "for ds in datasets: \n",
    "    print(ds)\n",
    "    aa_ratio_rows = []\n",
    "    aa_ratio_cols = ['Sub AA', 'RAAS']\n",
    "    ds_ratio_df = ratios_by_aas[ds]['Precursor_ratio_df']\n",
    "    for aa in aa_list:\n",
    "        aa_idx = [i for i,row in ds_ratio_df.iterrows() if row['AAS'][-1]==aa]\n",
    "        if len(aa_idx)>0:\n",
    "            aa_df = ds_ratio_df.loc[aa_idx]\n",
    "            for j, row in aa_df.iterrows():\n",
    "                aa_ratio_rows.append([aa, row['RAAS']])\n",
    "    ds_aa_df = pd.DataFrame(aa_ratio_rows, columns = aa_ratio_cols)  \n",
    "    aa_medians = [np.nanmedian([x for x in ds_aa_df.loc[ds_aa_df['Sub AA']==aa,'RAAS'].values]) for aa in aa_list]\n",
    "    aa_sorted_idx = np.argsort(aa_medians)\n",
    "    aa_sorted_medians = [aa_medians[i] for i in aa_sorted_idx]\n",
    "    aa_sorted_subs = [aa_list[i] for i in aa_sorted_idx]\n",
    "    ratios_by_aas[ds]['Sub_AA_RAAS_df'] = ds_aa_df\n",
    "    ratios_by_aas[ds]['Sub_AAS_sorted'] = aa_sorted_subs\n",
    "    ratios_by_aas[ds]['Sub_medians_sorted'] = aa_sorted_medians\n",
    "\n",
    "# add median reporter RAAS across all peptides with each susbtituted/destination AA  \n",
    "for ds in datasets: \n",
    "    print(ds)\n",
    "    if ds!='Healthy':\n",
    "        aa_ratio_rows = []\n",
    "        aa_ratio_cols = ['Sub AA', 'RAAS']\n",
    "        ds_ratio_df = ratios_by_aas[ds]['Reporter_ratio_df']\n",
    "        for aa in aa_list:\n",
    "            aa_idx = [i for i,row in ds_ratio_df.iterrows() if row['AAS'][-1]==aa]\n",
    "            if len(aa_idx)>0:\n",
    "                aa_df = ds_ratio_df.loc[aa_idx]\n",
    "                for j, row in aa_df.iterrows():\n",
    "                    aa_ratio_rows.append([aa, row['RAAS']])\n",
    "        ds_aa_df = pd.DataFrame(aa_ratio_rows, columns = aa_ratio_cols)  \n",
    "        aa_medians = [np.nanmedian([x for x in ds_aa_df.loc[ds_aa_df['Sub AA']==aa,'RAAS'].values]) for aa in aa_list]\n",
    "        aa_sorted_idx = np.argsort(aa_medians)\n",
    "        aa_sorted_medians = [aa_medians[i] for i in aa_sorted_idx]\n",
    "        aa_sorted_subs = [aa_list[i] for i in aa_sorted_idx]\n",
    "        ratios_by_aas[ds]['Sub_reporter_AA_RAAS_df'] = ds_aa_df\n",
    "        ratios_by_aas[ds]['Sub_reporter_AAS_sorted'] = aa_sorted_subs\n",
    "        ratios_by_aas[ds]['Sub_reporter_medians_sorted'] = aa_sorted_medians\n",
    "    \n",
    "pickle.dump(ratios_by_aas, open(outdir+'Ratios_by_AAS.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate heatmap dataframe that will be used to compute correlations of Base AA RAAS across datasets\n",
    "heatmap_data = pd.DataFrame(index=aa_list, columns=datasets)\n",
    "for i, row in heatmap_data.iterrows():\n",
    "    for ds in datasets:\n",
    "        if ds!='Healthy':\n",
    "            medians = ratios_by_aas[ds]['Base_reporter_medians_sorted']\n",
    "            aas = ratios_by_aas[ds]['Base_reporter_AAS_sorted']\n",
    "        else:\n",
    "        medians = ratios_by_aas[ds]['Base_prec_medians_sorted']\n",
    "        aas = ratios_by_aas[ds]['Base_prec_AAS_sorted']\n",
    "        for i,aa in enumerate(aa_list):\n",
    "            heatmap_data.loc[aa,ds] = medians[aas.index(aa)]\n",
    "\n",
    "# compute correlations of vectors of Base AA median RAAS across datasets \n",
    "heatmap_df_4corr = heatmap_df.dropna(how='any')\n",
    "corr_heatmap = pd.DataFrame(index=datasets, columns=datasets)\n",
    "for ds1 in datasets:\n",
    "    for ds2 in datasets:\n",
    "        corr = sp.stats.pearsonr(heatmap_df_4corr[ds1].values, heatmap_df_4corr[ds2].values)[0]\n",
    "        corr_heatmap.loc[ds1,ds2] = corr\n",
    "corr_heatmap = corr_heatmap.astype(float)\n",
    "\n",
    "# plot the correlation heatmap for base AA RAAS across datasets \n",
    "s= sns.clustermap(corr_heatmap, figsize=(5,5), annot=np.round(corr_heatmap, 2), cmap='Reds', cbar_kws={'label':'Pearson correlation', 'pad':1}, annot_kws={\"fontsize\":12},\n",
    "                 vmax=1, vmin=0, row_cluster=False, col_cluster=False)\n",
    "\n",
    "s.ax_heatmap.tick_params(right=False, left=True, labelright=False, labelleft=True, labelbottom=True, bottom=True)\n",
    "plt.setp(s.ax_heatmap.xaxis.get_majorticklabels(), rotation=90, fontsize=13)\n",
    "plt.setp(s.ax_heatmap.yaxis.get_majorticklabels(), fontsize=13)\n",
    "s.ax_cbar.set_position([0.8,0.26,0.05,0.5])\n",
    "s.ax_cbar.yaxis.label.set_size(14)\n",
    "s.ax_cbar.set_yticklabels([0,0.2,0.4,0.6,0.8, 1], fontsize=13)\n",
    "s.ax_row_dendrogram.set_visible(False)\n",
    "s.ax_col_dendrogram.set_visible(False)\n",
    "plt.savefig(outdir+'Correlation_heatmap_BaseAA_reporterRatios_unclustered.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate heatmap dataframe that will be used to compute correlations of substituted AA RAAS across datasets\n",
    "heatmap_data = pd.DataFrame(index=aa_list, columns=datasets)\n",
    "for i, row in heatmap_data.iterrows():\n",
    "    for ds in datasets:\n",
    "        if ds!='Healthy':\n",
    "            medians = ratios_by_aas[ds]['Sub_reporter_medians_sorted']\n",
    "            aas = ratios_by_aas[ds]['Sub_reporter_AAS_sorted']\n",
    "        else:\n",
    "        medians = ratios_by_aas[ds]['Sub_prec_medians_sorted']\n",
    "        aas = ratios_by_aas[ds]['Sub_prec_AAS_sorted']\n",
    "        for i,aa in enumerate(aa_list):\n",
    "            heatmap_data.loc[aa,ds] = medians[aas.index(aa)]\n",
    "\n",
    "# compute correlations of vectors of Substituted AA median RAAS across datasets \n",
    "heatmap_df_4corr = heatmap_df.dropna(how='any')\n",
    "corr_heatmap = pd.DataFrame(index=datasets, columns=datasets)\n",
    "for ds1 in datasets:\n",
    "    for ds2 in datasets:\n",
    "        corr = sp.stats.pearsonr(heatmap_df_4corr[ds1].values, heatmap_df_4corr[ds2].values)[0]\n",
    "        corr_heatmap.loc[ds1,ds2] = corr\n",
    "corr_heatmap = corr_heatmap.astype(float)\n",
    "\n",
    "# plot the correlation heatmap for substituted AA RAAS across datasets \n",
    "s= sns.clustermap(corr_heatmap, figsize=(5,5), annot=np.round(corr_heatmap, 2), cmap='Reds', cbar_kws={'label':'Pearson correlation', 'pad':1}, annot_kws={\"fontsize\":12},\n",
    "                 vmax=1, vmin=0, row_cluster=False, col_cluster=False)\n",
    "\n",
    "s.ax_heatmap.tick_params(right=False, left=True, labelright=False, labelleft=True, labelbottom=True, bottom=True)\n",
    "plt.setp(s.ax_heatmap.xaxis.get_majorticklabels(), rotation=90, fontsize=13)\n",
    "plt.setp(s.ax_heatmap.yaxis.get_majorticklabels(), fontsize=13)\n",
    "s.ax_cbar.set_position([0.8,0.26,0.05,0.5])\n",
    "s.ax_cbar.yaxis.label.set_size(14)\n",
    "s.ax_cbar.set_yticklabels([0,0.2,0.4,0.6,0.8, 1], fontsize=13)\n",
    "s.ax_row_dendrogram.set_visible(False)\n",
    "s.ax_col_dendrogram.set_visible(False)\n",
    "plt.savefig(outdir+'Correlation_heatmap_SubstitutedAA_reporterRatios_unclustered.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3f: ANOVA of RAAS variance by data type, AAS type, tissue type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe for ANOVA analysis\n",
    "\n",
    "# list of tissues each CPTAC dataset represents, in same order as dataset_list \n",
    "cptac_tissue_list = ['kidney', 'endometrium', 'breast', 'lung', 'pancreas', 'lung']\n",
    "\n",
    "anova_rows = []\n",
    "anova_cols = ['SAAP', 'BP', 'AAS', 'RAAS', 'Tissue', 'Dataset', 'Data_type'] # data type will be TMT or label-free\n",
    "for i,row in filt_reporter_quant_df.iterrows():\n",
    "    ds = row['Dataset']\n",
    "    anova_rows.append([row['SAAP'], row['BP'], row['AAS'], row['RAAS'], cptac_tissue_list[datasets.index(ds)], ds, 'TMT-labeled'])\n",
    "healthy_df = filt_prec_quant_df.loc[filt_prec_quant_df['Dataset']=='Healthy']\n",
    "for i,row in healthy_df.iterrows():\n",
    "    anova_rows.append([row['SAAP'], row['BP'], row['AAS'], row['RAAS'], row['TMT/Tissue'], 'Healthy', 'Label-free'])\n",
    "\n",
    "    anova_df = pd.DataFrame(anova_rows, columns=anova_cols)\n",
    "anova_df.replace(np.inf, np.nan, inplace=True)\n",
    "anova_df.replace(-np.inf, np.nan, inplace=True)\n",
    "anova_df.dropna(how='any', inplace=True)\n",
    "\n",
    "anova_df['Encoded'] = [x.split(' to ')[0] for x in anova_df.AAS.to_list()]\n",
    "anova_df['Incorporated'] = [x.split(' to ')[1] for x in anova_df.AAS.to_list()]\n",
    "anova_df.to_excel(outdir+'ANOVA_AAS_tissue_df.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate ordinary least squares model with variables of interest (tissue type, data type, AAS type, etc)\n",
    "model = ols('RAAS ~ C(AAS) + C(Encoded) + C(Incorporated) + C(Tissue) + C(Data_type)', data=anova_df).fit()\n",
    "df = sm.stats.anova_lm(model, typ=3)\n",
    "df.reset_index(inplace=True)\n",
    "df.columns = ['Variable']+df.columns.to_list()[1:]\n",
    "\n",
    "# plot results\n",
    "plot_df = df.loc[1:5, ['Variable', 'F', 'PR(>F)']]\n",
    "plot_df = df.loc[1:5, ['Variable', 'F', 'PR(>F)']]\n",
    "plot_df['PR(>F)'] = ['{:.2e}'.format(x) for x in plot_df['PR(>F)']]\n",
    "plot_df['Variable'] = ['Substitution\\ntype', 'Encoded\\namino acid', 'Incorporated\\namino acid', 'Tissue', 'Data type']\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "fig,ax = plt.subplots(figsize=(5,4))\n",
    "sns.barplot(data=plot_df, x='Variable', y='F', hue='PR(>F)', dodge=False, palette='Greys',\n",
    "           order=['Data type', 'Incorporated\\namino acid', 'Encoded\\namino acid', 'Tissue','Substitution\\ntype'])\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles=handles, labels=['p$<10^{-100}$', 'p$<10^{-51}$', 'p$<10^{-23}$', 'p$<10^{-8}$'], loc='upper left', fontsize=13)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('ANOVA F statistic', fontsize=15)\n",
    "ax.tick_params('both', labelsize=14)\n",
    "ax.tick_params('x', rotation=90)\n",
    "plt.savefig(outdir+'ANOVA_tissue_AAS_results_extended.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data Figure 5h,i:  AAS type enrichment in tissue types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of all AAS types\n",
    "aas_list = list(set(filt_saap_df['AAS'].to_list()))\n",
    "\n",
    "# get index of rows in precursor quant data (Extended_Data_2) corresponding to tissue types represented by CPTAC and healthy datasets \n",
    "kidney_rows = [i for i,row in filt_prec_quant_df.iterrows() if row['Dataset']=='CCRCC' or row['TMT/Tissue']=='kidney']\n",
    "lung_rows = [i for i,row in filt_prec_quant_df.iterrows() if row['Dataset']=='LUAD' or row['Dataset']=='LSCC' or row['TMT/Tissue']=='lung']\n",
    "pancreas_rows = [i for i,row in filt_prec_quant_df.iterrows() if row['Dataset']=='PDAC' or row['TMT/Tissue']=='pancreas']\n",
    "endometrium_rows = [i for i,row in filt_prec_quant_df.iterrows() if row['Dataset']=='UCEC' or row['TMT/Tissue']=='endometrium']\n",
    "\n",
    "\n",
    "def get_aas_fc_alt(aas, tissue_rows):\n",
    "    \"\"\"\n",
    "    Function to get the log2 fold change and pvalue between RAAS for peptides with an AAS type in a given tissue vs RAAS for peptides with that AAS type in all other tissues\n",
    "    Input: AAS type, index in precursor quant df of tissues of interest (extracted above)\n",
    "    Output: Log2FC and Pvalue of RAAS comparison for AAS across tissues\n",
    "    Requires at least 10 peptides with AAS in tissue type and other tissue types for comparison\n",
    "    \"\"\"\n",
    "    tissue_df = filt_prec_quant_df.loc[tissue_rows]\n",
    "    tissue_raas = [x for x in tissue_df.loc[tissue_df['AAS']==aas, 'RAAS'].to_list() if ~np.isnan(x) and ~np.isinf(x)]\n",
    "    other_rows = [i for i in filt_prec_quant_df.index if i not in tissue_rows]\n",
    "    other_df = filt_prec_quant_df.loc[other_rows]\n",
    "    other_raas = [x for x in other_df.loc[other_df['AAS']==aas, 'RAAS'].to_list() if ~np.isnan(x) and ~np.isinf(x)]   \n",
    "    if len(tissue_raas)>10 and len(other_raas)>10:\n",
    "        l2fc = np.log2(10**(np.mean(tissue_raas)-np.mean(other_raas)))\n",
    "        pval = sp.stats.ttest_ind(tissue_raas, other_raas)[1]\n",
    "    else:\n",
    "        l2fc = np.nan\n",
    "        pval = np.nan\n",
    "    return(l2fc, pval)\n",
    "\n",
    "# get dataframe with fold change and pvalues for AAS type RAAS in given tissue vs all other tissues \n",
    "aas_fc_rows = []\n",
    "aas_fc_cols = ['AAS', 'Tissue', 'RAAS FC', 'pvalue']\n",
    "for aas in aas_list:\n",
    "    kidney_fc, kidney_pval = get_aas_fc_alt(aas, kidney_rows)\n",
    "    lung_fc, lung_pval = get_aas_fc_alt(aas, lung_rows)\n",
    "    pancreas_fc, pancreas_pval = get_aas_fc_alt(aas, pancreas_rows)\n",
    "    endometrium_fc, endometrium_pval = get_aas_fc_alt(aas, endometrium_rows)\n",
    "    aas_fc_rows.append([aas, 'Kidney', kidney_fc, kidney_pval])\n",
    "    aas_fc_rows.append([aas, 'Lung', lung_fc, lung_pval])\n",
    "    aas_fc_rows.append([aas, 'Pancreas', pancreas_fc, pancreas_pval])\n",
    "    aas_fc_rows.append([aas, 'Endometrium', endometrium_fc, endometrium_pval])\n",
    "aas_fc_df_alt = pd.DataFrame(aas_fc_rows, columns=aas_fc_cols)\n",
    "aas_fc_df_alt.dropna(how='any', axis=0, inplace=True)\n",
    "\n",
    "# adjust pvalues for multiple testing\n",
    "aas_fc_df_alt['padj'] = multipletests(aas_fc_df_alt['pvalue'].to_list(), method='fdr_bh')[1]\n",
    "aas_fc_df_alt['-log q'] = [-1*np.log10(x) for x in aas_fc_df_alt['padj']]\n",
    "aas_fc_df_alt['Significant'] = ['Significant' if row['padj']<=0.01 and np.abs(row['RAAS FC']>=1) else 'Not significant' for i,row in aas_fc_df_alt.iterrows()]\n",
    "aas_fc_df.to_excel(outdir+'AAS_RAAS_tissue_FC_n10.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot volcano plot of tissue type RAAS significance for AAS types (Ext. Data Fig. 5h)\n",
    "\n",
    "sns.set_style('ticks')\n",
    "fig,ax = plt.subplots(figsize=(3,3))\n",
    "sns.scatterplot(data=aas_fc_df_alt, y='-log q', x='RAAS FC', hue='Hue', palette=['#aaaaaa']+colors)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles=handles, labels=labels, title='', fontsize=11, handletextpad=0, bbox_to_anchor=(0.48,1.08), ncol=2, frameon=False, loc='center', columnspacing=0.2)\n",
    "\n",
    "plt.ylabel('-log$_{10}$(q)', fontsize=14)\n",
    "plt.xlabel('log$_{2}$(RAAS$_{tissue}/$RAAS$_{other}$)', fontsize=14)\n",
    "ax.tick_params('both', labelsize=13)\n",
    "plt.plot((-1,-1), ax.get_ylim(), '--k' , linewidth=0.5)\n",
    "plt.plot((1,1), ax.get_ylim(), '--k' , linewidth=0.5)\n",
    "plt.plot(ax.get_xlim(), (2,2), '--k' , linewidth=0.5)\n",
    "\n",
    "sig_df = aas_fc_df_alt.loc[aas_fc_df_alt['Significant']=='Significant']\n",
    "texts = []\n",
    "for i,row in sig_df.iterrows():\n",
    "    x=row['RAAS FC']\n",
    "    y=row['-log q']\n",
    "    s=row['AAS'][0]+r'$\\rightarrow$'+row['AAS'][-1]\n",
    "    if x>0:\n",
    "        texts.append(ax.text(x,y,s,fontsize=11))\n",
    "adjust_text(texts, expand_points=(1,1), expand_text=(1,2), ax=fig.axes[0],\n",
    "            arrowprops=dict(arrowstyle='->', color='#555555', lw=1), force_text=0.3)\n",
    "\n",
    "plt.savefig(outdir+'Tissue_AAS_highRAAS_volcano.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with RAAS values and number of peptides for AAS types with significantly high RAAS in given tissue\n",
    "\n",
    "plot_rows = []\n",
    "plot_cols = ['Tissue', 'RAAS', 'Type', 'N', 'AAS']\n",
    "sig_df = aas_fc_df_alt.loc[aas_fc_df_alt['Significant']=='Significant']\n",
    "sig_df = sig_df.loc[sig_df['RAAS FC']>0]\n",
    "sig_df.sort_values('Tissue', inplace=True)\n",
    "for i,row in sig_df.iterrows():\n",
    "    aas = row['AAS']\n",
    "    aas_str = aas[0]+r'$\\rightarrow$'+aas[-1]\n",
    "    tissue = row['Tissue']\n",
    "    print(aas, tissue)\n",
    "    if tissue == 'Kidney':\n",
    "        tissue_rows = kidney_rows\n",
    "    elif tissue =='Lung':\n",
    "        tissue_rows = lung_rows\n",
    "    elif tissue == 'Pancreas':\n",
    "        tissue_rows = pancreas_rows\n",
    "    elif tissue == 'Endometrium':\n",
    "        tissue_rows = endometrium_rows\n",
    "    tissue_df = filt_prec_quant_df.loc[tissue_rows]\n",
    "    tissue_raas = [x for x in tissue_df.loc[tissue_df['AAS']==aas, 'RAAS'].to_list() if ~np.isnan(x) and ~np.isinf(x)]\n",
    "    n_tissue = len(tissue_raas)\n",
    "    other_rows = [i for i in filt_prec_quant_df.index if i not in tissue_rows]\n",
    "    other_df = filt_prec_quant_df.loc[other_rows]\n",
    "    other_raas = [x for x in other_df.loc[other_df['AAS']==aas, 'RAAS'].to_list() if ~np.isnan(x) and ~np.isinf(x)]   \n",
    "    n_other = len(other_raas)\n",
    "    for raas in tissue_raas:\n",
    "        plot_rows.append([tissue, raas, 'Significant tissue', n_tissue, aas_str])#+'\\n'+tissue])\n",
    "    for raas in other_raas:\n",
    "        plot_rows.append([tissue, raas, 'Other tissues', n_other, aas_str])#+'\\n'+tissue])\n",
    "\n",
    "plot_df = pd.DataFrame(plot_rows, columns=plot_cols)\n",
    "order = [r'L$\\rightarrow$S', r'G$\\rightarrow$S', r'G$\\rightarrow$Q', r'T$\\rightarrow$V', r'A$\\rightarrow$T', r'N$\\rightarrow$S',r'S$\\rightarrow$Q', r'T$\\rightarrow$S',  r'C$\\rightarrow$S', r'Q$\\rightarrow$G']\n",
    "\n",
    "\n",
    "# plot boxplots of RAAS distributions for AAS types with significantly high RAAS in a specific tissue (Ext. Data Fig. 5i)\n",
    "# plot barplot of number of SAAP with AAS type in specific tissue and all other tissues \n",
    "sns.set_style('whitegrid')\n",
    "fig,axes = plt.subplots(1,2,figsize=(3,3), gridspec_kw={'width_ratios':[3,1]}, sharey=True)\n",
    "plt.subplots_adjust(wspace=0.01)\n",
    "bx = sns.boxplot(data=plot_df, y='AAS', x='RAAS', hue='Type', palette=[colors[0], '#AAAAAA'], \n",
    "                 fliersize=0.5, linewidth=1, ax=axes[0], order=order)\n",
    "axes[0].tick_params('both', labelsize=13)\n",
    "axes[0].legend().remove()\n",
    "axes[0].set_ylabel('')\n",
    "axes[0].set_xlabel('log$_{10}$(RAAS)', fontsize=14)\n",
    "\n",
    "br = sns.barplot(data=plot_df, y='AAS', x='N', hue='Type', palette=[colors[0], '#AAAAAA'], ax=axes[1], order=order)\n",
    "axes[1].legend().remove()\n",
    "axes[1].tick_params('both', labelsize=13)\n",
    "axes[1].set_ylabel('')\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].set_xlabel('# SAAP', fontsize=14)\n",
    "\n",
    "g = '#AAAAAA'\n",
    "custom_colors = [colors[0]]*2+[colors[0],g]+ [colors[1], g]*6+[colors[2], g]*3\n",
    "for i, patch in enumerate(bx.patches):\n",
    "    patch.set_facecolor(custom_colors[i % len(custom_colors)])\n",
    "    patch.set_alpha(0.8)\n",
    "\n",
    "custom_br_colors = [colors[0]]+[colors[1]]*6+[colors[2]]*3+[g]*10\n",
    "for i, patch in enumerate(br.patches):\n",
    "    patch.set_facecolor(custom_br_colors[i % len(custom_colors)])\n",
    "    patch.set_alpha(1)\n",
    "\n",
    "plt.savefig(outdir+'Sig_tissue_AAS_highRAAS_boxplots_orderedbyFC.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 4. Tumor vs. Normal analysis\n",
    "\n",
    "#### Incl. Extended Data Figure 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data Figure 6a: Distribution of RAAS fold changes between tumor and normal samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary with fold changes for each SAAP's RAAS computed between normal and tumor samples from same patient\n",
    "# uses saap_protein_df, i.e. Supplemental_Data_2.SAAP_proteins.xlsx (read in earlier in script)\n",
    "# uses reporter_quant_df, i.e. Supplemental_Data_4.SAAP_reporter_quant.xlsx (read in earlier in script)\n",
    "\n",
    "all_saap_protein_df = pd.read_excel(proj_dir+'Supplemental_Data_2.SAAP_proteins.xlsx', index_col=0)\n",
    "reporter_quant_df = pd.read_excel(proj_dir+'Supplemental_Data_4.SAAP_reporter_quant.xlsx', index_col=0)\n",
    "tvn_datasets = [x for x in datasets if x!='BRCA' and x!='Healthy'] # BRCA not included because only tumor data\n",
    "reporter_quant_df['Patient ID'] = [x.split('_')[0] for x in reporter_quant_df['Sample name'].values]\n",
    "\n",
    "\n",
    "patient_level_tvn_dict = {ds:{} for ds in tvn_datasets}\n",
    "for ds in tvn_datasets: \n",
    "    print(ds)\n",
    "    ds_saap_df = all_saap_protein_df.loc[all_saap_protein_df['Dataset']==ds]\n",
    "    ds_quant_df = reporter_quant_df.loc[reporter_quant_df['Dataset']==ds]\n",
    "    set_patients = list(set(reporter_quant_df['Patient ID'].values))\n",
    "    patient_level_tvn_rows = []\n",
    "    patient_level_tvn_cols = ['Dataset', 'SAAP', 'BP','Patient ID', 'Tumor TMT set', 'Normal TMT set', 'Tumor SAAP', 'Normal SAAP','Log$_2$Tumor/Normal SAAP', 'Tumor BP', 'Normal BP','Log$_2$Tumor/Normal BP', 'Tumor RAAS', 'Normal RAAS', 'Log$_2$Tumor/Normal RAAS']\n",
    "\n",
    "    for i,row in ds_saap_df.iterrows():\n",
    "        saap = row['SAAP']\n",
    "        bp = row['BP']\n",
    "        saap_df = ds_quant_df.loc[(ds_quant_df['SAAP']==saap) & (ds_quant_df['BP']==bp)]\n",
    "        for patient in set_patients:\n",
    "            patient_df = saap_df.loc[saap_df['Patient ID']==patient]\n",
    "            if 'Tumor' in patient_df['Sample type'].values and 'Normal' in patient_df['Sample type'].values:\n",
    "                t_row = patient_df.loc[patient_df['Sample type']=='Tumor']\n",
    "                n_row = patient_df.loc[patient_df['Sample type']=='Normal']\n",
    "\n",
    "                t_saap = t_row['SAAP abundance'].values[0]\n",
    "                t_bp = t_row['BP abundance'].values[0]\n",
    "                t_raas = t_row['RAAS'].values[0]\n",
    "                t_tmt = t_row['TMT set'].values[0]\n",
    "\n",
    "                n_saap = n_row['SAAP abundance'].values[0]\n",
    "                n_bp = n_row['BP abundance'].values[0]\n",
    "                n_raas = n_row['RAAS'].values[0]\n",
    "                n_tmt = n_row['TMT set'].values[0]    \n",
    "\n",
    "                saap_fc = np.log2(t_saap/n_saap)\n",
    "                bp_fc = np.log2(t_bp/n_bp)\n",
    "                raas_fc = np.log2((10**t_raas)/(10**n_raas))\n",
    "\n",
    "                patient_level_tvn_rows.append([ds, saap, bp, patient, t_tmt, n_tmt,\n",
    "                                              t_saap, n_saap, saap_fc, t_bp, n_bp, bp_fc, t_raas, n_raas, raas_fc])\n",
    "    patient_level_tvn_df = pd.DataFrame(patient_level_tvn_rows, columns=patient_level_tvn_cols)\n",
    "    patient_level_tvn_dict[ds] = patient_level_tvn_df\n",
    "pickle.dump(patient_level_tvn_dict, open(outdir+'Patient_level_Tumor_v_Normal_data.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot overall distribution of tumor vs normal RAAS value for each SAAP. Computed with matched patient samples\n",
    "\n",
    "tvn_dict = patient_level_tvn_dict\n",
    "\n",
    "col2plot = 'Log$_2$Tumor/Normal RAAS'\n",
    "fig,axes = plt.subplots(1,len(tvn_datasets),figsize=(5,2.5), sharey=True)\n",
    "sns.set_style('whitegrid')\n",
    "plt.subplots_adjust(wspace=0)\n",
    "for ax in axes:\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.tick_params('x', bottom=False,labelbottom=False)\n",
    "    if ax!=axes[0]:    \n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.tick_params(left=False)\n",
    "\n",
    "# sort datasets in plot by median of distribution \n",
    "medians = []\n",
    "for ds in tvn_datasets:\n",
    "    ds_df = tvn_dict[ds]\n",
    "    data = [x for x in ds_df[col2plot].values if ~np.isnan(x) and ~np.isinf(x)]\n",
    "    medians.append(np.median(data))\n",
    "med_sort_idx = list(np.argsort(medians))\n",
    "\n",
    "for i,ds in enumerate(tvn_datasets):\n",
    "    print(ds)\n",
    "    ax_idx = med_sort_idx.index(i)\n",
    "    axes[ax_idx].set_xlabel(ds, fontsize=13)\n",
    "    ds_df = tvn_dict[ds]\n",
    "    data = [x for x in ds_df[col2plot].values if ~np.isnan(x) and ~np.isinf(x)]\n",
    "    bihist(data, data, nbins=70,h=axes[ax_idx])\n",
    "    if ax_idx==0:\n",
    "        axes[ax_idx].annotate('N = '+str(len(data)),(0.05,1), xycoords='axes fraction', fontsize=12)\n",
    "    else:\n",
    "        axes[ax_idx].annotate(str(len(data)), (0.25,1), xycoords='axes fraction', fontsize=12)\n",
    "    axes[ax_idx].plot((axes[ax_idx].get_xlim()), (np.median(data), np.median(data)), '--r',linewidth=0.7)\n",
    "axes[0].set_ylabel('log$_2$(Tumor/Normal RAAS)', fontsize=14)\n",
    "axes[0].tick_params('both', labelsize=13)\n",
    "plt.ylim([-5,5])\n",
    "plt.savefig(outdir+'patient_level_Tv_RAAS_bihist.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data Figure 6c: Tumor vs Normal RAAS in patients for PSMA1 SAAP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "saap = 'AGSELAAHQK'\n",
    "\n",
    "# get data for plot from tvn_dict\n",
    "saap_df_list = []\n",
    "for ds in tvn_datasets:\n",
    "    ds_df = tvn_dict[ds]\n",
    "    saap_df = ds_df.loc[ds_df['SAAP']==saap]\n",
    "    saap_df_list.append(saap_df)\n",
    "all_ds_saap_df = pd.concat(saap_df_list)\n",
    "all_ds_saap_df = all_ds_saap_df.loc[:,['Dataset','Patient ID','Tumor RAAS','Normal RAAS']]\n",
    "all_ds_saap_df.replace(np.inf, np.nan, inplace=True)\n",
    "all_ds_saap_df.replace(-np.inf, np.nan, inplace=True)\n",
    "all_ds_saap_df.dropna(inplace=True, how='any')\n",
    "\n",
    "# plot scatterplot of tumor vs normal RAAS for datasets \n",
    "plot_ds_saap_df = all_ds_saap_df.loc[all_ds_saap_df['Dataset'].isin(['LUAD','PDAC',])]\n",
    "sns.set_style('whitegrid')\n",
    "fig,ax = plt.subplots(figsize=(2.5,2.5))\n",
    "sns.scatterplot(data = plot_ds_saap_df, x='Normal RAAS', y='Tumor RAAS',hue='Dataset', s=35, alpha=0.5)\n",
    "plt.title(saap[0]+r'$\\bf(Q$'+r'$\\rightarrow$'+r'$\\bfG)$'+saap[2:]+'\\nProteasome subunit A, type 1', fontsize=14)\n",
    "ax.tick_params('both', labelsize=13)\n",
    "plt.ylabel('Tumor log$_{10}$(RAAS)', fontsize=14)\n",
    "plt.xlabel('Normal log$_{10}$(RAAS)', fontsize=14)\n",
    "plt.xlim([-1.5, 1.5])\n",
    "plt.ylim(plt.xlim())\n",
    "plt.xticks([-1,0,1]);\n",
    "plt.plot(plt.ylim(), plt.ylim(), '--k', linewidth=0.8)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "# pvalues used in legend are computed below \n",
    "plt.legend(handles = handles, labels = ['LUAD, q$<$10$^{-14}$', 'PDAC, q$<$10$^{-3}$'], \n",
    "           title='', loc='center', handletextpad=0, labelspacing=0, bbox_to_anchor=(0.8,0.15))\n",
    "plt.savefig(outdir+saap+'_TRAAS_vs_NRAAS_allDS_PSMA1_PDAC_LUAD_trim.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing pvalues between tumor and normal RAAS in patients for PSMA1 SAAP in each dataset\n",
    "# used in plot annotation \n",
    "\n",
    "ps = []\n",
    "for ds in tvn_datasets:\n",
    "    print(ds)\n",
    "    ds_df = all_ds_saap_df.loc[all_ds_saap_df['Dataset']==ds]\n",
    "    print(sp.stats.ttest_rel(ds_df['Normal RAAS'].values, ds_df['Tumor RAAS'].values, alternative='less'))\n",
    "    ps.append(sp.stats.ttest_rel(ds_df['Normal RAAS'].values, ds_df['Tumor RAAS'].values, alternative='less')[1])\n",
    "adj_ps = multipletests(ps, method='fdr_bh')[1]\n",
    "for i,ds in enumerate(tvn_datasets):\n",
    "    print(ds, adj_ps[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 4b: Distribution of RAAS for PSMA1 SAAP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of RAAS for this PSMA1 SAAP in the CPTAC datasets\n",
    "cptac_datasets = datasets[:-1]\n",
    "\n",
    "filt_reporter_df = filt_reporter_quant_df\n",
    "proteasome_saap = 'AGSELAAHQK'\n",
    "saap_df = filt_reporter_df.loc[filt_reporter_df['SAAP']==proteasome_saap]\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "col2plot = 'RAAS'\n",
    "fig,axes = plt.subplots(1,len(cptac_datasets),figsize=(4.2,2.5), sharey=True)\n",
    "sns.set_style('whitegrid')\n",
    "plt.subplots_adjust(wspace=0.1)\n",
    "for ax in axes:\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.tick_params('x', bottom=False,labelbottom=False)\n",
    "    if ax!=axes[0]:    \n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.tick_params(left=False)\n",
    "\n",
    "# sort order of datasets in plot by median RAAS of distribution \n",
    "medians = []\n",
    "for ds in cptac_datasets:\n",
    "    ds_df = saap_df.loc[saap_df['Dataset']==ds]\n",
    "    data = [x for x in ds_df[col2plot].values if ~np.isnan(x) and ~np.isinf(x)]\n",
    "    medians.append(np.median(data))\n",
    "med_sort_idx = list(np.argsort(medians))\n",
    "\n",
    "for i,ds in enumerate(cptac_datasets):\n",
    "    print(ds)\n",
    "    ax_idx = med_sort_idx.index(i)\n",
    "    axes[ax_idx].set_xlabel(ds, fontsize=12.5)\n",
    "    ds_df = saap_df.loc[saap_df['Dataset']==ds]\n",
    "    data = [x for x in ds_df[col2plot].values if ~np.isnan(x) and ~np.isinf(x)]\n",
    "    bihist(data, data, nbins=20,h=axes[ax_idx])\n",
    "    if ax_idx==0:\n",
    "        axes[ax_idx].annotate('N$=$'+str(len(data)),(-0.1,1.01), xycoords='axes fraction', fontsize=12)\n",
    "    else:\n",
    "        axes[ax_idx].annotate(str(len(data)), (0.25,1.01), xycoords='axes fraction', fontsize=12)\n",
    "    axes[ax_idx].plot((axes[ax_idx].get_xlim()), (np.median(data), np.median(data)), '--r',linewidth=0.7)\n",
    "axes[0].set_ylabel('log$_{10}$(RAAS)', fontsize=14)\n",
    "axes[0].tick_params('both', labelsize=13)\n",
    "fig.text(0.5, 1, r'PSMA1: Proteasome subunit $\\alpha$ type-1; Q$\\rightarrow$G', ha='center', fontsize=13)\n",
    "plt.ylim([-2,2])\n",
    "plt.savefig(outdir+'PSMA1_RAAS_bihist.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 4a: Tumor vs Normal RAAS in patients for LaminA SAAP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saap = 'AGNTWGCGNSLR'\n",
    "\n",
    "# get data for plot from tvn_dict\n",
    "saap_df_list = []\n",
    "for ds in tvn_datasets:\n",
    "    ds_df = tvn_dict[ds]\n",
    "    saap_df = ds_df.loc[ds_df['SAAP']==saap]\n",
    "    saap_df_list.append(saap_df)\n",
    "all_ds_saap_df = pd.concat(saap_df_list)\n",
    "all_ds_saap_df = all_ds_saap_df.loc[:,['Dataset','Patient ID','Tumor RAAS','Normal RAAS']]\n",
    "all_ds_saap_df.replace(np.inf, np.nan, inplace=True)\n",
    "all_ds_saap_df.replace(-np.inf, np.nan, inplace=True)\n",
    "all_ds_saap_df.dropna(inplace=True, how='any')\n",
    "\n",
    "# plot scatterplot of tumor vs normal RAAS for datasets \n",
    "plot_ds_saap_df = all_ds_saap_df.loc[all_ds_saap_df['Dataset'].isin(['LUAD','LSCC', 'UCEC'])]\n",
    "sns.set_style('whitegrid')\n",
    "fig,ax = plt.subplots(figsize=(2.5,2.5))\n",
    "sns.scatterplot(data = plot_ds_saap_df, x='Normal RAAS', y='Tumor RAAS',hue='Dataset', s=40, alpha=0.7)\n",
    "plt.plot(plt.ylim(), plt.ylim(), '--r')\n",
    "plt.title(saap[0]+r'$\\bf(Q$'+r'$\\rightarrow$'+r'$\\bfG)$'+saap[2:]+'\\nLamin isoform A', fontsize=15)\n",
    "ax.tick_params('both', labelsize=14)\n",
    "plt.ylabel('Tumor log$_{10}$(RAAS)', fontsize=15)\n",
    "plt.xlabel('Normal log$_{10}$(RAAS)', fontsize=15)\n",
    "plt.xticks([-3, -2.5, -2, -1.5])\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "# pvalues used in legend are computed below \n",
    "plt.legend(handles = handles, labels = ['UCEC, q$<$10$^{-3}$', 'LUAD, q$<$10$^{-7}$', 'LSCC, q$<$10$^{-6}$'],\n",
    "           title='', loc='center', handletextpad=-0.1, labelspacing=0, bbox_to_anchor=(0.85,0.2))\n",
    "plt.savefig(outdir+saap+'_TRAAS_vs_NRAAS_allDS.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing pvalues between tumor and normal RAAS in patients for LaminA SAAP in each dataset\n",
    "# used in plot annotation \n",
    "\n",
    "ps = []\n",
    "for ds in tvn_datasets:\n",
    "    print(ds)\n",
    "    ds_df = all_ds_saap_df.loc[all_ds_saap_df['Dataset']==ds]\n",
    "    print(sp.stats.ttest_rel(ds_df['Normal RAAS'].values, ds_df['Tumor RAAS'].values, alternative='less'))\n",
    "    ps.append(sp.stats.ttest_rel(ds_df['Normal RAAS'].values, ds_df['Tumor RAAS'].values, alternative='less')[1])\n",
    "\n",
    "ps = [x if ~np.isnan(x) else 1 for x in ps]\n",
    "adj_ps = multipletests(ps, method='fdr_bh')[1]\n",
    "for i,ds in enumerate(tvn_datasets):\n",
    "    print(ds, adj_ps[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data Figure 6b: RAAS vs. tumor stage\n",
    "\n",
    "Requires clinical data provided as supplemental files in CPTAC publications - available in the google drive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in clinical data \n",
    "ccrcc_clin_data = pd.read_excel(ccrcc_proj_dir+'Publication/CPTAC_ccRCC_metadata/S044_CPTAC_CCRCC_Discovery_Cohort_Clinical_Data_r2_Jan2019.xlsx', skiprows=2)\n",
    "lscc_clin_data = pd.read_excel(lscc_proj_dir+'Publication/S063_S058_CPTAC_LSCC_Discovery_Cohort_Clinical_Data_r2_July2021.xlsx', sheet_name='Patient_Clinical_Attributes')\n",
    "pdac_clin_data = pd.read_excel(pdac_proj_dir+'Publication/S061_CPTAC_PDA_Discovery_Cohort_Clinical_Data_r1_Feb2021.xlsx', sheet_name='Patient_Clinical_Attributes')\n",
    "ucec_clin_data = pd.read_excel(ucec_proj_dir+'Publication/S053_S043_CPTAC_UCEC_Discovery_Cohort_Clinical_Data_r2_Feb2020.xlsx', sheet_name='Patient_Clinical_Attributes')\n",
    "luad_clin_data = pd.read_excel(luad_proj_dir+'Publication/mmc1_metadata.xlsx', sheet_name='Annotions_S1A')\n",
    "brca_clin_data = pd.read_excel(brca_proj_dir+'Publication/Krug_metaData.xlsx', sheet_name='A) Metadata')\n",
    "\n",
    "# create lists in same order as dataset_list\n",
    "# list of clinical data for each dataset\n",
    "clin_data_list = [ccrcc_clin_data, ucec_clin_data, brca_clin_data, luad_clin_data, pdac_clin_data, lscc_clin_data]\n",
    "# list of column name indicating sample ID in clinical data for each dataset\n",
    "patient_col_list = ['Case_ID', 'case_id', 'Sample.ID', 'Participant', 'case_id', 'case_id']\n",
    "# list of column name indicating tumor stage in clinical data for each dataset\n",
    "tumor_stage_col_list = ['Tumor_Stage_Pathological', 'tumor_stage_pathological', 'Tumor.Stage', 'Stage', 'tumor_stage_pathological', 'tumor_stage_pathological']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_stage(stage):\n",
    "    \"\"\" function to get Stage I, II, or III from stage subsets\n",
    "        Streamlines annotation of tumor stage across datasets\n",
    "    \"\"\"\n",
    "    if (stage=='Stage IA') or (stage=='Stage IB') or (stage=='Stage IA3') or (stage=='1A') or (stage==1) or (stage=='1B'):\n",
    "        stage = 'Stage I'\n",
    "    elif (stage=='Stage IIA') or (stage=='Stage IIB') or (stage=='2A') or (stage=='2B'):\n",
    "        stage = 'Stage II'\n",
    "    elif (stage=='Stage IIIA') or (stage=='Stage IIIB') or (stage=='Stage IIIC') or (stage=='3A'):\n",
    "        stage = 'Stage III'\n",
    "    return(stage)\n",
    "\n",
    "\n",
    "def get_tumor_stage(ds, patient):\n",
    "    \"\"\" function to get clinical tumor stage for a patient sample in a dataset \"\"\"\n",
    "    clin_data = clin_data_list[datasets.index(ds)]\n",
    "    case_col = patient_col_list[datasets.index(ds)]\n",
    "    tumor_stage_col = tumor_stage_col_list[datasets.index(ds)]\n",
    "    if ds!='LUAD':\n",
    "        stage = clin_data.loc[clin_data[case_col]==patient, tumor_stage_col].values[0]\n",
    "    else:\n",
    "        stage = clin_data.loc[(clin_data[case_col]==patient) & (clin_data['Type']=='Tumor'), tumor_stage_col].values[0]\n",
    "    stage = reduce_stage(stage)\n",
    "    return(stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot boxplots of median RAAS per patient, stratified by patient tumor stage \n",
    "\n",
    "plot_df  = filt_reporter_quant_df.loc[filt_reporter_quant_df['Sample type']=='Tumor']\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "fig,ax = plt.subplots(figsize=(5,2.5))\n",
    "sns.boxplot(data=plot_df, y='RAAS', x='Dataset', hue='Tumor stage', hue_order=stages, fliersize=0.75, linewidth=0.8)#, color='#AAAAAA')\n",
    "plt.ylabel('log$_{10}$(RAAS)', fontsize=14)\n",
    "plt.xlabel('')\n",
    "ax.tick_params('both', labelsize=13)\n",
    "plt.rcParams['legend.handlelength'] = 1\n",
    "plt.rcParams['legend.handleheight'] = 1.125\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles = handles, labels=['I', 'II', 'III','IV','unknown'], ncol=5, bbox_to_anchor=(0.5,1.15), fontsize=11, \n",
    "plt.savefig(outdir+'RAAS_vs_TumorStage_SAAPupinT_boxplot_byDataset.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Data Figure 9a: Pfam domain enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in Supplemental_Data_2.SAAP_proteins.xlsx\n",
    "filt_saap_df = pd.read_excel(proj_dir+'Supplemental_Data_2.SAAP_proteins.xlsx', index_col=0)\n",
    "\n",
    "# convert columns with Pfam domain information to lists \n",
    "filt_saap_df['Pfam domains'] = [x.split(';') if isinstance(x,str) else x for x in filt_saap_df['Pfam domains'].values]\n",
    "filt_saap_df['SAAP in Pfam domains'] = [x.split(';') if isinstance(x,str) else x in filt_saap_df['SAAP in Pfam domains'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with p-values for significance of RAAS in Pfam domains\n",
    "# pvalues are computed by comparing the RAAS for all peptides mapping to a given domain relative to random set of 5000 RAAS using KS test\n",
    "\n",
    "ds_saap_df = filt_saap_df\n",
    "domain_list = []\n",
    "raas_list = []\n",
    "for i,row in ds_saap_df.iterrows():\n",
    "    doms = row['Pfam domains']\n",
    "    if ds =='Healthy':\n",
    "        raas = row['Mean precursor RAAS']\n",
    "    else:\n",
    "        raas = row['Mean reporter RAAS']\n",
    "    saap_in_doms = row['SAAP in Pfam domains']\n",
    "    if len(doms)>0:\n",
    "        keep_doms = []\n",
    "        for dl, dom_list in enumerate(doms):\n",
    "            for d, dom in enumerate(dom_list):\n",
    "                if saap_in_doms[dl][d]==True and dom not in keep_doms:\n",
    "                    keep_doms.append(dom)\n",
    "        for dom in keep_doms:\n",
    "            domain_list.append(dom)\n",
    "            raas_list.append(raas)\n",
    "    else:\n",
    "        domain_list.append('Unidentified domain')\n",
    "        raas_list.append(raas)\n",
    "set_pfam_domains = list(set([i for j in [x for y in list(ds_saap_df['Pfam domains'].values) for x in y] for i in j]))\n",
    "set_pfam_domains.append('Unidentified domain')\n",
    "pfam_raas_df = pd.DataFrame(zip([ds]*len(domain_list), domain_list, raas_list), columns=['Dataset','Domain', 'Mean RAAS'])\n",
    "pfam_raas_df.to_excel(data_dir+'Pfam_RAAS_df_allDS.xlsx')\n",
    "\n",
    "# get random domain RAAS\n",
    "random_domain_raas_assignments = {dom:{'Random RAAS':[]} for dom in set_pfam_domains}\n",
    "raas_mean = np.mean([x for x in raas_list if ~np.isnan(x)])\n",
    "raas_std = np.std([x for x in raas_list if ~np.isnan(x)])\n",
    "ct=0\n",
    "while ct<5000:\n",
    "    for domain in set_pfam_domains:\n",
    "        random_domain_raas_assignments[domain]['Random RAAS'].append(np.random.normal(raas_mean, raas_std, 1))\n",
    "    ct+=1\n",
    "domain_raas_dict = {domain:{'RAAS list':list(pfam_raas_df.loc[pfam_raas_df['Domain']==domain, 'Mean RAAS'].values)} for domain in set_pfam_domains}\n",
    "if ds == 'Healthy':\n",
    "    all_raas = [x for x in ds_saap_df['Mean precursor RAAS'] if ~np.isnan(x)]\n",
    "else:\n",
    "    all_raas = [x for x in ds_saap_df['Mean reporter RAAS'] if ~np.isnan(x)]\n",
    "\n",
    "# compute significance of RAAS in each domain using KS test\n",
    "domain_sig_rows = []\n",
    "domain_sig_cols = ['Domain', 'N peptides', 'Median RAAS', 'Mean RAAS','p_median_greater','p_median_less', 'p_mean_greater','p_mean_less', 'p_MW', 'p_KS']\n",
    "for domain, domain_dict in domain_raas_dict.items():\n",
    "        domain_raas_list = [x for x in domain_dict['RAAS list'] if ~np.isnan(x)]\n",
    "        n_peps = len(domain_raas_list)\n",
    "        if n_peps>0:\n",
    "            domain_median_raas = np.median(domain_raas_list)\n",
    "            domain_mean_raas = np.mean(domain_raas_list)\n",
    "            domain_random_raas_list = random_domain_raas_assignments[domain]['Random RAAS']\n",
    "            ks_p = sp.stats.ks_2samp(domain_raas_list, all_raas)[1]\n",
    "            domain_sig_rows.append([domain, n_peps, domain_median_raas, domain_mean_raas, p_median_greater, p_median_less, p_mean_greater, p_mean_less, mw_p, ks_p])\n",
    "            domain_raas_dict[domain]['N peptides'] = n_peps\n",
    "            domain_raas_dict[domain]['Median RAAS'] =  domain_median_raas\n",
    "            domain_raas_dict[domain]['Mean RAAS'] = domain_mean_raas\n",
    "            domain_raas_dict[domain]['p_KS'] = ks_p\n",
    "domain_sig_df = pd.DataFrame(domain_sig_rows, columns=domain_sig_cols)\n",
    "\n",
    "# adjust pvalues\n",
    "ks_pvals = domain_sig_df['p_KS'].values\n",
    "ks_pvals_adj = multipletests(ks_pvals, method='fdr_bh')[1]\n",
    "domain_sig_df['p_KS_adj'] = ks_pvals_adj\n",
    "\n",
    "domain_sig_df.to_excel(data_dir+'Pfam_domain_RAAS_significance_allDS.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read in file which has pvalues for each dataset\n",
    "all_ds_dom_dicts = pickle.load(open(proj_dir+'pipeline_output/analysis_dependencies/All_DS_Pfam_dom_dict.p', 'rb'))\n",
    "\n",
    "# add dataset specific pvalues to Pfam domain dataframe\n",
    "domain_sig_df['CCRCC_p'] = np.nan\n",
    "domain_sig_df['UCEC_p'] = np.nan\n",
    "domain_sig_df['BRCA_p'] = np.nan\n",
    "domain_sig_df['LUAD_p'] = np.nan\n",
    "domain_sig_df['PDAC_p'] = np.nan\n",
    "domain_sig_df['LSCC_p'] = np.nan\n",
    "domain_sig_df['N sig'] = np.nan\n",
    "\n",
    "for i,row in domain_sig_df.iterrows():\n",
    "    dom = row['Domain']\n",
    "    ps = []\n",
    "    for ds in datasets[:-1]:\n",
    "        dom_dict = all_ds_dom_dicts[ds]\n",
    "        if dom in dom_dict:\n",
    "            dom_dict = dom_dict[dom]\n",
    "            p = dom_dict['p-value']\n",
    "            ps.append(p)\n",
    "            domain_sig_df.loc[i, ds+'_p'] = p\n",
    "    n_sig = len([x for x in ps if x<0.05])\n",
    "    domain_sig_df.loc[i, 'N sig'] = n_sig\n",
    "domain_sig_df.to_excel(outdir+'Pfam_domain_RAAS_significance_allDS_.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract domains to plot - those that have significant pvalues in at least 4 datasets \n",
    "doms2plot = domain_sig_df.loc[domain_sig_df['N sig']>=4, 'Domain'].to_list()\n",
    "raas = domain_sig_df.loc[domain_sig_df['N sig']>=4, 'Median RAAS'].to_list()\n",
    "sorted_idx = np.argsort(raas)\n",
    "sorted_domains = [doms2plot[i] for i in sorted_idx]\n",
    "\n",
    "x_labels = datasets\n",
    "y_labels = sorted_domains\n",
    "\n",
    "# get data for plot - color data = RAAS, size data = N peptides with domain \n",
    "color_data = pd.DataFrame(index=y_labels, columns=datasets)\n",
    "size_data = pd.DataFrame(index=y_labels, columns=datasets)\n",
    "for i in x_labels:\n",
    "    data_dir = data_dir_list[datasets.index(i)]\n",
    "    domain_ds_df = pd.read_excel(data_dir+'Pfam_domain_RAAS_significance_26May24.xlsx')\n",
    "    for j in y_labels:\n",
    "        dom_ds_row = domain_ds_df.loc[(domain_ds_df['Domain']==j)]\n",
    "        if len(dom_ds_row)>0:\n",
    "            color_data.loc[j,i] = dom_ds_row['Median RAAS'].values[0]\n",
    "            n =  dom_ds_row['N peptides'].values[0]\n",
    "            size_data.loc[j,i] =n\n",
    "\n",
    "color_data = color_data.astype(float)\n",
    "size_data = size_data.astype(float)\n",
    "\n",
    "color_data.to_excel(outdir+'Pfam_Domains_RAAS_SigIn4.xlsx')\n",
    "size_data.to_excel(outdir+'Pfam_Domains_Npeps_SigIn4.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined repetitive domains manually \n",
    "\n",
    "color_data = pd.read_excel(outdir+'Pfam_Domains_RAAS_SigIn4.xlsx', index_col=0)\n",
    "size_data = pd.read_excel(outdir+'Pfam_Domains_Npeps_SigIn4.xlsx', index_col=0)\n",
    "\n",
    "\n",
    "# pathway order - high mean raas on top \n",
    "doms2plot = list(set(color_data.index))\n",
    "medians = [np.nanmean(row.values) for i, row in color_data.iterrows()]\n",
    "sorted_idx = np.argsort(medians)\n",
    "sorted_domains = [color_data.index.to_list()[i] for i in sorted_idx]\n",
    "color_data = color_data.loc[sorted_domains]\n",
    "size_data = size_data.loc[sorted_domains]\n",
    "\n",
    "# adjust sizes for visualization purposes \n",
    "import copy\n",
    "size_data2plot = copy.deepcopy(size_data)\n",
    "for i,row in size_data2plot.iterrows():\n",
    "    for col in size_data2plot.columns:\n",
    "        if size_data.loc[i,col]<5:\n",
    "            size_data2plot.loc[i,col] = 0.3\n",
    "        elif size_data.loc[i,col]<50:\n",
    "            size_data2plot.loc[i,col] = 0.4\n",
    "        else:\n",
    "            size_data2plot.loc[i,col] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot dotplot of domains with significantly high RAAS \n",
    "\n",
    "M=len(datasets)\n",
    "N=len(sorted_domains)\n",
    "x, y = np.meshgrid(np.arange(M), np.arange(N))\n",
    "\n",
    "x_labels = datasets\n",
    "y_labels = sorted_domains\n",
    "\n",
    "sns.set_style('ticks')\n",
    "fig, ax = plt.subplots(figsize=(13,6))\n",
    "s = size_data2plot.values\n",
    "c = color_data.\n",
    "R = s\n",
    "\n",
    "circles = [plt.Circle((j,i), radius=r) for r, j, i in zip(R.flat, x.flat, y.flat)]\n",
    "col = PatchCollection(circles, array=c.flatten(), cmap=custom_cmap)\n",
    "ax.add_collection(col)\n",
    "ax.set_aspect('equal')\n",
    "ax.set(xticks=np.arange(M), yticks=np.arange(N),\n",
    "       xticklabels=x_labels, yticklabels=y_labels)\n",
    "ax.tick_params('both', labelsize=12)\n",
    "ax.set_xticks(np.arange(M+1)-0.5, minor=True)\n",
    "ax.set_yticks(np.arange(N+1)-0.5, minor=True)\n",
    "ax.tick_params('x', rotation=90)\n",
    "cb = fig.colorbar(col, shrink=0.75, anchor=(-0.3,1))\n",
    "cb.ax.tick_params(labelsize=12)\n",
    "cb.ax.set_ylabel('Mean log$_{10}$(RAAS)', fontsize=14)\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label='$<$5',markerfacecolor='#AAAAAA', markersize=8),\n",
    "                  Line2D([0], [0], marker='o', color='w', label='[5,50)',markerfacecolor='#AAAAAA', markersize=12),\n",
    "                  Line2D([0], [0], marker='o', color='w', label='$\\geq$50',markerfacecolor='#AAAAAA', markersize=15)]\n",
    "\n",
    "plt.legend(handles=legend_elements, handletextpad=0, title='# SAAP', bbox_to_anchor=(1.85,.25), frameon=False, fontsize=12, title_fontsize=14)\n",
    "plt.savefig(outdir+'pfamdomains_sigin4_dotplot.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 5: Conservation of SAAP to mouse tissues\n",
    "\n",
    "#### Incl. Extended Data Figure 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data Figure 10d. Upset plot of intersection of mouse and human SAAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_dir = proj_dir+'pipeline_output/Mouse/'\n",
    "mtp_dict = pickle.load(open(mouse_dir+'AA_subs_pipeline/MTP_dict.p', 'rb'))\n",
    "\n",
    "# get list of SAAP identified in mouse data \n",
    "samples = list(mtp_dict.keys())\n",
    "all_mouse_saap = [x for y in [list(mtp_dict[s]['mistranslated sequence'].values()) for s in samples] for x in y]\n",
    "all_mouse_saap = list(set([x for y in all_mouse_saap for x in y]))\n",
    "\n",
    "# get list of SAAP identified in CPTAC/human label-free data\n",
    "filt_saap_peptides = list(set(filt_saap_df['SAAP'].to_list()))\n",
    "\n",
    "# Add list of datasets each saap is found in to filt_saap_df (Supplemental_Data_2). \n",
    "# Was also computed above in analysis for Extended 3e.\n",
    "# get_ds fxn defined above\n",
    "filt_saap_df['Datasets'] = filt_saap_df.apply(lambda x: str(get_ds(x['SAAP'], x['BP'], filt_saap_df)), axis=1)\n",
    "\n",
    "# get intersection of mouse and human SAAP\n",
    "filt_overlap = [x for x in filt_saap_peptides if x in all_mouse_saap]\n",
    "overlap_saap_df = filt_saap_df.loc[filt_saap_df['SAAP'].isin(filt_overlap)]\n",
    "\n",
    "# add mouse to list of datasets intersected SAAP is found in\n",
    "ds_list_mouse = []\n",
    "for i,row in overlap_saap_df.iterrows():\n",
    "    ds_list = row['Datasets']\n",
    "    ds_list.append('Mouse')\n",
    "    ds_list_mouse.append(str(ds_list))\n",
    "overlap_saap_df['Datasets_w_mouse'] = ds_list_mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataframe for upset plot\n",
    "data4upset = []\n",
    "data4upset_cols = ['SAAP','BP','Datasets']\n",
    "saap_bp = [row['SAAP']+':'+row['BP'] for i,row in overlap_saap_df.iterrows()]\n",
    "saap_bp = list(set(saap_bp))\n",
    "for sb in saap_bp:\n",
    "    saap = sb.split(':')[0]\n",
    "    bp = sb.split(':')[1]\n",
    "    overlap_rows = [i for i,row in overlap_saap_df.iterrows() if row['SAAP']==saap and row['BP']==bp]\n",
    "    datasets = overlap_saap_df.loc[overlap_rows, 'Dataset'].to_list()\n",
    "    datasets.append('Mouse')\n",
    "    data4upset.append([saap, bp, str(datasets)])\n",
    "upset_plot_df = pd.DataFrame(data4upset, columns=data4upset_cols)\n",
    "\n",
    "# prepare index for upset plot\n",
    "datasets = ['CCRCC','UCEC','BRCA','LUAD','PDAC','LSCC','Healthy', 'Mouse']\n",
    "l = [False, True]\n",
    "arrays = [list(i) for i in itertools.product(l, repeat=8)]\n",
    "arrays = np.transpose(arrays)\n",
    "tuples = list(zip(*arrays))\n",
    "multiindex = pd.MultiIndex.from_tuples(tuples, names=datasets)\n",
    "\n",
    "# format data and index into multiindex dataframe for upset plot\n",
    "saap_counts = []\n",
    "idx = multiindex[1]\n",
    "keepidx = []\n",
    "for idx in multiindex:\n",
    "    if True in idx:\n",
    "        saap_ds = [datasets[i] for i,x in enumerate(idx) if x==True]\n",
    "        n_saap_ds = len(upset_plot_df.loc[upset_plot_df['Datasets']==str(saap_ds)])\n",
    "        if n_saap_ds>0:\n",
    "            saap_counts.append(n_saap_ds)\n",
    "            keepidx.append(idx)  \n",
    "keepidx = np.transpose(keepidx)\n",
    "tuples = list(zip(*keepidx))\n",
    "multiindex = pd.MultiIndex.from_tuples(tuples, names=datasets)\n",
    "upset_plot_data = pd.Series(saap_counts, index=multiindex)\n",
    "\n",
    "# plot upset plot\n",
    "fig = plt.figure(figsize=(6,3))\n",
    "up.plot(upset_plot_data, show_counts=True, fig=fig, element_size=20)\n",
    "plt.savefig(outdir + 'Upsetplot_only_overlap.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 5e: Correlation of RAAS values for SAAP intersected between human and mouse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_ev_dict = pickle.load(open(mouse_dir+'AA_subs_pipeline/DP_search_evidence_dict.p','rb'))\n",
    "\n",
    "# extract RAAS values for intersected SAAP into dataframe\n",
    "plot_rows = []\n",
    "plot_cols = ['Mouse tissue', 'SAAP', 'BP', 'SAAP intensity', 'BP intensity', 'Mouse RAAS', 'Human RAAS','Dataset']\n",
    "for s in mtp_dict.keys():\n",
    "    s_mtp = mtp_dict[s]\n",
    "    s_ev = dp_ev_dict[s]\n",
    "    for saap in filt_overlap:\n",
    "        saap_keys = [k for k,v in s_mtp['mistranslated sequence'].items() if saap in v]\n",
    "        saap_int = np.sum([s_mtp['Intensity'][k] for k in saap_keys])\n",
    "        bps = [s_mtp['DP Base Sequence'][k] for k in saap_keys]\n",
    "        for bp in bps:\n",
    "            bp_int = s_ev.loc[s_ev['Sequence']==bp, 'Intensity'].sum()\n",
    "            mouse_raas = np.log10(saap_int/bp_int)\n",
    "            human_data = overlap_saap_df.loc[(overlap_saap_df['SAAP']==saap) & (overlap_saap_df['BP']==bp)]\n",
    "            for i,row in human_data.iterrows():\n",
    "                ds = row['Dataset']\n",
    "                human_raas = row['Mean precursor RAAS']\n",
    "                plot_rows.append([s, saap, bp, saap_int, bp_int, mouse_raas, human_raas, ds])\n",
    "\n",
    "plot_df = pd.DataFrame(plot_rows, columns=plot_cols)\n",
    "plot_df.drop_duplicates(inplace=True)\n",
    "plot_df.dropna(how='any', inplace=True)\n",
    "\n",
    "# plot scatterplot of mouse vs human RAAS colored by tissue\n",
    "sns.set_style('whitegrid')\n",
    "fig,ax = plt.subplots(figsize=(2.5,2.5))\n",
    "sns.scatterplot(data=plot_df, x='Human RAAS', y='Mouse RAAS', hue='Mouse tissue', alpha=0.6, s=40)\n",
    "plt.legend(bbox_to_anchor=(0.5,1.1), fontsize=12, title='Mouse tissue', loc='center', \n",
    "           ncol=3, frameon=False, title_fontsize=12, handletextpad=-0.5, columnspacing=0.3)\n",
    "ax.tick_params('both', labelsize=13)\n",
    "plt.ylabel('Mouse log$_{10}$(RAAS)', fontsize=14)\n",
    "plt.xlabel('Human log$_{10}$(RAAS)', fontsize=14)\n",
    "\n",
    "r,p = sp.stats.pearsonr(plot_df['Human RAAS'].values, plot_df['Mouse RAAS'].values)\n",
    "ax.text(0.85, -3.2, 'r='+str(np.round(r,2)), fontsize=12)\n",
    "ax.text(0.85,-4.1, 'p$<$10$^{-10}$', fontsize=12)\n",
    "plt.plot((-4.8,4), (-4.8,4), '--k', linewidth=0.8)\n",
    "plt.xlim(plt.ylim())\n",
    "plt.xticks([-4,-2,0,2,4]);\n",
    "plt.savefig('Mouse_human_RAAS_correlation_allPepquant.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 5f: ANOVA to attribute variance in RAAS to species, tissue type, and AAS type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_prec_df = pd.read_excel(proj_dir + 'Supplemental_Data_3.SAAP_precursor_quant.xlsx', index_col=0)\n",
    "\n",
    "# tissue type that each CPTAC dataset represents\n",
    "cptac_tissue_dict = {'CCRCC':'kidney', 'PDAC':'pancreas', 'BRCA':'breast','UCEC':'endometrium','LSCC':'lung','LUAD':'lung'}\n",
    "\n",
    "# prepare dataframe for ANOVA \n",
    "plot_rows = []\n",
    "plot_cols = ['SAAP', 'BP', 'AAS', 'RAAS', 'Dataset', 'Tissue', 'Species','Dataset_type']\n",
    "for s in mtp_dict.keys():\n",
    "    s_mtp = mtp_dict[s]\n",
    "    s_ev = dp_ev_dict[s]\n",
    "    for saap in filt_overlap:\n",
    "        saap_keys = [k for k,v in s_mtp['mistranslated sequence'].items() if saap in v]\n",
    "        saap_int = np.sum([s_mtp['Intensity'][k] for k in saap_keys])\n",
    "        bps = [s_mtp['DP Base Sequence'][k] for k in saap_keys]\n",
    "        for bp in bps:\n",
    "            bp_int = s_ev.loc[s_ev['Sequence']==bp, 'Intensity'].sum()\n",
    "            mouse_raas = np.log10(saap_int/bp_int)\n",
    "            mouse_tissue = s\n",
    "            human_data = overlap_saap_df.loc[(overlap_saap_df['SAAP']==saap) & (overlap_saap_df['BP']==bp)]\n",
    "            for i,row in human_data.iterrows():\n",
    "                ds = row['Dataset']\n",
    "                prec_df = filt_prec_df.loc[(filt_prec_df['Dataset']==ds) & (filt_prec_df['SAAP']==saap) & (filt_prec_df['BP']==bp)]\n",
    "                for i,row in prec_df.iterrows():\n",
    "                    raas = row['RAAS']\n",
    "                    aas = row['AAS']\n",
    "                    if ds=='Healthy':\n",
    "                        tissue = row['TMT/Tissue']\n",
    "                        ds_type = 'Label-free'\n",
    "                    else:\n",
    "                        tissue = cptac_tissue_dict[ds]\n",
    "                        ds_type = 'TMT'\n",
    "                    plot_rows.append([saap, bp, aas, raas, ds, tissue, 'Human', ds_type])\n",
    "            plot_rows.append([saap, bp, aas, mouse_raas, 'Kuster_mouse', mouse_tissue, 'Mouse', 'Label-free'])\n",
    "plot_df = pd.DataFrame(plot_rows, columns=plot_cols)\n",
    "\n",
    "anova_df = plot_df\n",
    "anova_df.replace(np.inf, np.nan, inplace=True)\n",
    "anova_df.replace(-np.inf, np.nan, inplace=True)\n",
    "anova_df.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate ANOVA model with independent variables of interest and RAAS dependent variable\n",
    "model = ols('RAAS ~ C(Tissue) + C(AAS) + C(Species)', data=anova_df).fit()\n",
    "df = sm.stats.anova_lm(model, typ=3)\n",
    "df.reset_index(inplace=True)\n",
    "df.columns = ['Variable']+df.columns.to_list()[1:]\n",
    "\n",
    "# generate dataframe with ANOVA results to plot \n",
    "plot_df = df.loc[1:3, ['Variable', 'F', 'PR(>F)']]\n",
    "for i in plot_df.index:\n",
    "    plot_df.loc[i,'PR(>F)'] = '{:0.0e}'.format(plot_df.loc[i,'PR(>F)'])\n",
    "plot_df['Variable'] = ['Tissue','AAS','Species']\n",
    "plot_df = plot_df.loc[[1,3,2],:]\n",
    "\n",
    "# plot ANOVA results \n",
    "sns.set_style('whitegrid')\n",
    "fig,ax = plt.subplots(figsize=(4,4))\n",
    "sns.barplot(data=plot_df, x='Variable', y='F', hue='PR(>F)', dodge=False, palette='Greys',\n",
    "           order=['Tissue', 'AAS', 'Species'])#, hue_order=['Species','Data type','Tissue','AAS'])\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles = handles, labels = ['p<10$^{-24}$', 'p<10$^{-38}$', 'p<10$^{-248}$'],\n",
    "           loc='upper left', fontsize=12, title_fontsize=13, labelspacing=0.1)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('ANOVA F statistic', fontsize=14)\n",
    "ax.tick_params('both', labelsize=13)\n",
    "plt.savefig('mouse_ANOVA_tissue_AAS_result.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
